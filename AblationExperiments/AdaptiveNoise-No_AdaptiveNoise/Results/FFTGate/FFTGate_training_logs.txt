Epoch 0: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000'] | Gamma1 Grad: ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']
Epoch 1: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.22795', '2.23494', '2.23014', '2.22774', '2.22733', '2.22671', '2.22577', '2.22691', '2.22785', '2.22699', '2.22252', '2.21943', '2.20776'] | Gamma1 Grad: ['0.00933', '-0.00427', '0.00018', '-0.00439', '-0.00850', '-0.00989', '-0.00877', '-0.00363', '-0.01255', '-0.01158', '-0.00627', '-0.02307', '0.00432']
Epoch 2: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.28884', '2.29982', '2.29246', '2.28344', '2.28527', '2.28075', '2.28175', '2.28316', '2.28382', '2.28266', '2.28037', '2.28211', '2.25888'] | Gamma1 Grad: ['-0.02591', '-0.00145', '0.00414', '-0.00905', '-0.00516', '-0.00106', '-0.00231', '0.00298', '-0.00554', '-0.00431', '-0.00276', '0.01448', '-0.01988']
Epoch 3: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.30452', '2.30929', '2.30599', '2.29050', '2.29394', '2.29187', '2.28966', '2.28794', '2.28910', '2.28720', '2.28508', '2.27090', '2.26998'] | Gamma1 Grad: ['-0.00124', '0.01234', '0.00805', '0.00987', '-0.00235', '0.00098', '-0.00544', '0.00027', '-0.01430', '-0.01423', '-0.00561', '-0.03088', '-0.04595']
Epoch 4: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.30142', '2.31566', '2.30612', '2.29783', '2.29718', '2.29525', '2.29362', '2.29456', '2.29035', '2.29254', '2.29215', '2.27742', '2.27782'] | Gamma1 Grad: ['0.02010', '-0.01584', '0.00732', '-0.00592', '0.00057', '-0.00173', '-0.00359', '0.00631', '-0.00354', '-0.00451', '0.00100', '0.00979', '0.01989']
Epoch 5: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31396', '2.32951', '2.31623', '2.30199', '2.30410', '2.29932', '2.29610', '2.29563', '2.29588', '2.29123', '2.28973', '2.28172', '2.28559'] | Gamma1 Grad: ['-0.00715', '0.03196', '0.02884', '-0.00434', '-0.00035', '0.00328', '0.01173', '0.00527', '-0.00270', '0.01462', '0.00813', '-0.01765', '-0.01875']
Epoch 6: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31912', '2.31693', '2.30322', '2.29344', '2.30172', '2.29663', '2.29033', '2.29164', '2.29101', '2.29411', '2.29270', '2.28287', '2.28815'] | Gamma1 Grad: ['-0.02130', '-0.01486', '0.00909', '-0.01530', '-0.00769', '0.00322', '0.00263', '-0.00912', '0.00154', '0.00471', '0.00523', '0.01145', '0.00806']
Epoch 7: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.31611', '2.30953', '2.30621', '2.30120', '2.29471', '2.29868', '2.29516', '2.29585', '2.29454', '2.29309', '2.29558', '2.28610', '2.28851'] | Gamma1 Grad: ['-0.00238', '0.00565', '-0.00667', '0.00570', '0.00136', '0.00472', '0.00199', '-0.00137', '-0.00201', '-0.00452', '0.00170', '-0.02368', '0.10247']
Epoch 8: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.31906', '2.32422', '2.32015', '2.29657', '2.29969', '2.30031', '2.29222', '2.29704', '2.29778', '2.29779', '2.29597', '2.28510', '2.29539'] | Gamma1 Grad: ['-0.00784', '-0.01541', '0.00626', '0.02285', '0.00338', '-0.01002', '0.00616', '-0.00156', '0.01095', '0.00003', '-0.00092', '0.02153', '0.07887']
Epoch 9: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.31945', '2.31567', '2.31731', '2.29417', '2.30094', '2.29687', '2.28601', '2.29714', '2.29911', '2.29887', '2.29669', '2.27922', '2.29607'] | Gamma1 Grad: ['-0.01222', '-0.01300', '-0.01587', '-0.02295', '0.00700', '-0.00674', '0.00743', '0.00600', '-0.00267', '-0.01260', '-0.00180', '0.00868', '-0.00895']
Epoch 10: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.31593', '2.31946', '2.31958', '2.29723', '2.30439', '2.30470', '2.29356', '2.30038', '2.29461', '2.29507', '2.29851', '2.28756', '2.29678'] | Gamma1 Grad: ['-0.02378', '-0.03103', '0.00215', '-0.01518', '0.00255', '0.00728', '0.00429', '-0.00024', '0.00662', '-0.00005', '0.00565', '0.00593', '0.00921']
Epoch 11: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.31190', '2.31094', '2.32117', '2.29791', '2.30358', '2.30844', '2.28715', '2.29200', '2.29662', '2.29234', '2.29288', '2.28071', '2.30138'] | Gamma1 Grad: ['-0.00967', '0.01198', '0.01322', '-0.00865', '-0.00627', '-0.01812', '0.00522', '-0.00039', '0.00516', '0.00798', '-0.00181', '-0.00470', '0.05069']
Epoch 12: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.30581', '2.31613', '2.31299', '2.29396', '2.31024', '2.30826', '2.28510', '2.29722', '2.28825', '2.28890', '2.29048', '2.27453', '2.29948'] | Gamma1 Grad: ['-0.00411', '0.01445', '-0.00104', '0.00955', '0.01228', '-0.01129', '-0.00113', '-0.00042', '-0.00452', '0.00152', '-0.00302', '0.00117', '0.04521']
Epoch 13: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['2.32401', '2.33179', '2.30877', '2.29862', '2.30028', '2.31004', '2.29433', '2.31388', '2.30652', '2.29924', '2.28384', '2.29501', '2.30425'] | Gamma1 Grad: ['0.01317', '0.04420', '-0.05501', '0.03276', '-0.02279', '-0.00831', '0.00486', '-0.00015', '0.00730', '0.00692', '0.00479', '0.02136', '0.04560']
Epoch 14: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.31004', '2.32952', '2.31872', '2.28208', '2.31185', '2.29832', '2.28511', '2.29961', '2.29408', '2.28563', '2.28174', '2.30272', '2.29541'] | Gamma1 Grad: ['0.02175', '-0.00278', '0.00516', '-0.05175', '0.00059', '-0.00302', '-0.01966', '-0.00989', '0.00287', '0.00153', '0.00040', '0.01602', '-0.02398']
Epoch 15: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['2.30914', '2.30790', '2.30298', '2.30349', '2.30264', '2.31261', '2.29526', '2.29976', '2.30129', '2.29923', '2.29926', '2.28454', '2.29439'] | Gamma1 Grad: ['0.04509', '-0.01031', '0.02336', '-0.00153', '-0.01677', '0.01134', '-0.00453', '0.01892', '0.01282', '0.02207', '0.01272', '0.00082', '0.07534']
Epoch 16: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.30564', '2.31861', '2.31022', '2.30022', '2.30269', '2.31707', '2.29494', '2.30311', '2.28614', '2.28806', '2.29570', '2.28963', '2.30124'] | Gamma1 Grad: ['0.06745', '-0.00660', '0.01990', '-0.00870', '-0.00069', '0.01989', '0.01924', '0.00671', '0.00539', '0.00427', '0.00122', '0.02216', '-0.01129']
Epoch 17: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['2.31847', '2.31544', '2.29697', '2.30197', '2.29769', '2.31385', '2.29566', '2.30607', '2.29777', '2.29105', '2.29502', '2.28436', '2.31730'] | Gamma1 Grad: ['-0.01297', '0.00964', '0.00964', '-0.01345', '-0.00278', '-0.01047', '-0.00141', '-0.00219', '-0.00052', '-0.00223', '-0.00436', '-0.00077', '0.03937']
Epoch 18: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.31037', '2.32956', '2.28599', '2.30087', '2.31624', '2.31329', '2.29524', '2.30096', '2.29609', '2.29888', '2.29496', '2.28913', '2.31099'] | Gamma1 Grad: ['0.01783', '-0.04290', '0.01935', '0.02963', '-0.01311', '0.00796', '-0.00879', '-0.00192', '-0.00699', '-0.00139', '-0.00142', '-0.00250', '0.03150']
Epoch 19: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['2.31032', '2.32892', '2.30398', '2.28295', '2.31196', '2.29479', '2.29541', '2.30208', '2.29956', '2.29943', '2.29464', '2.28675', '2.30517'] | Gamma1 Grad: ['0.00095', '0.03513', '-0.03057', '-0.00982', '0.00083', '-0.00720', '0.00224', '0.00244', '-0.00100', '0.00435', '0.00468', '-0.01442', '-0.02521']
Epoch 20: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31049', '2.31326', '2.28951', '2.29833', '2.30943', '2.30552', '2.29914', '2.29825', '2.29199', '2.29254', '2.28868', '2.28510', '2.30239'] | Gamma1 Grad: ['0.01844', '-0.03893', '0.02050', '0.00215', '-0.04958', '-0.04229', '-0.00461', '0.00830', '0.00922', '0.01524', '0.00358', '-0.03336', '-0.01744']
Epoch 21: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['2.30037', '2.31205', '2.30213', '2.29877', '2.30422', '2.30516', '2.29559', '2.29973', '2.29533', '2.29436', '2.29850', '2.29097', '2.30310'] | Gamma1 Grad: ['0.02825', '0.04476', '0.06778', '-0.00691', '0.02241', '0.01790', '-0.01412', '-0.00069', '-0.00634', '0.00171', '0.00599', '0.01950', '-0.01695']
Epoch 22: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31166', '2.30365', '2.30151', '2.29231', '2.30498', '2.29780', '2.29297', '2.30700', '2.29725', '2.29379', '2.29177', '2.28818', '2.30336'] | Gamma1 Grad: ['0.02584', '-0.02835', '0.04616', '-0.01460', '-0.01118', '0.02200', '0.00065', '-0.00839', '-0.01570', '-0.01098', '-0.00790', '0.01017', '0.02394']
Epoch 23: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['2.30211', '2.30726', '2.30204', '2.28808', '2.31075', '2.30821', '2.29629', '2.30564', '2.29625', '2.29486', '2.29474', '2.28691', '2.30840'] | Gamma1 Grad: ['-0.00633', '0.01475', '-0.09762', '-0.00574', '0.00910', '-0.02231', '0.01183', '-0.01242', '-0.00331', '-0.00061', '-0.01316', '0.00772', '0.04727']
Epoch 24: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.30420', '2.30468', '2.30533', '2.29444', '2.30506', '2.30430', '2.29695', '2.29759', '2.30131', '2.29623', '2.29641', '2.29246', '2.30512'] | Gamma1 Grad: ['-0.02510', '0.03043', '-0.01714', '0.04024', '-0.00212', '-0.02404', '0.02546', '-0.00962', '0.00565', '0.00147', '0.00186', '0.00397', '-0.02210']
Epoch 25: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['2.31103', '2.31088', '2.30369', '2.30801', '2.30529', '2.30251', '2.29268', '2.29987', '2.29262', '2.28783', '2.28688', '2.29439', '2.30652'] | Gamma1 Grad: ['-0.05887', '-0.01094', '0.00660', '-0.02780', '-0.02295', '-0.01470', '-0.00120', '0.00144', '-0.00401', '0.01066', '0.00203', '-0.00090', '-0.03916']
Epoch 26: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.30619', '2.31288', '2.31550', '2.30280', '2.30522', '2.32320', '2.30702', '2.30778', '2.30328', '2.29067', '2.28958', '2.28458', '2.29510'] | Gamma1 Grad: ['-0.02997', '-0.05745', '0.04713', '-0.02904', '-0.06871', '0.02420', '-0.01388', '-0.00333', '-0.00009', '-0.00318', '-0.00721', '0.01732', '-0.00159']
Epoch 27: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['2.29980', '2.30539', '2.29408', '2.30093', '2.28873', '2.31132', '2.30126', '2.31227', '2.29830', '2.29575', '2.29603', '2.29509', '2.29895'] | Gamma1 Grad: ['0.03326', '-0.00073', '-0.00284', '-0.00221', '-0.05428', '0.01585', '0.00727', '0.00091', '-0.01219', '0.01133', '0.01576', '0.00395', '0.05335']
Epoch 28: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.30225', '2.31114', '2.30496', '2.30849', '2.31341', '2.31424', '2.29846', '2.30955', '2.29880', '2.28700', '2.29377', '2.28857', '2.31441'] | Gamma1 Grad: ['0.01762', '-0.01127', '0.02500', '-0.03139', '-0.01136', '-0.01503', '0.01458', '0.00787', '0.01495', '0.00391', '-0.00074', '0.03163', '0.00202']
Epoch 29: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['2.29399', '2.30939', '2.29871', '2.29137', '2.30815', '2.30572', '2.29890', '2.30738', '2.29868', '2.29348', '2.29563', '2.28682', '2.30013'] | Gamma1 Grad: ['0.01718', '0.04184', '-0.01097', '0.04712', '0.00798', '-0.03138', '-0.00123', '-0.00932', '-0.00205', '-0.00969', '0.00961', '-0.01879', '0.06159']
Epoch 30: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30053', '2.30639', '2.30145', '2.30143', '2.29704', '2.30827', '2.30422', '2.31090', '2.29751', '2.29049', '2.29120', '2.28593', '2.30441'] | Gamma1 Grad: ['-0.01115', '0.00721', '-0.05039', '0.00081', '0.02189', '-0.00127', '-0.00800', '0.00167', '-0.00108', '-0.01838', '-0.00371', '0.03136', '-0.04273']
Epoch 31: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30787', '2.30620', '2.31357', '2.30855', '2.30167', '2.30574', '2.30234', '2.31594', '2.29918', '2.29436', '2.29986', '2.28933', '2.30054'] | Gamma1 Grad: ['0.03543', '0.02835', '-0.00693', '0.00629', '-0.00009', '-0.00480', '-0.01227', '-0.00535', '0.00508', '0.01494', '0.01862', '-0.00722', '-0.06868']
Epoch 32: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.30563', '2.32110', '2.29620', '2.31170', '2.32114', '2.29578', '2.29463', '2.30017', '2.30099', '2.29373', '2.29658', '2.28690', '2.30512'] | Gamma1 Grad: ['-0.01921', '-0.01659', '0.00871', '-0.04182', '0.00728', '0.00099', '-0.01096', '0.00318', '-0.01110', '-0.00031', '-0.00601', '-0.00687', '-0.04899']
Epoch 33: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['2.30116', '2.30638', '2.31348', '2.28157', '2.29849', '2.29889', '2.29647', '2.30649', '2.30909', '2.29734', '2.30143', '2.29431', '2.30533'] | Gamma1 Grad: ['-0.02952', '0.00581', '-0.02508', '0.00063', '-0.01702', '0.00286', '-0.02662', '-0.00173', '-0.01450', '-0.00526', '-0.00049', '-0.01027', '0.01532']
Epoch 34: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.29684', '2.30900', '2.29522', '2.29152', '2.29214', '2.29255', '2.28540', '2.29955', '2.30722', '2.29928', '2.30120', '2.28447', '2.29603'] | Gamma1 Grad: ['0.00435', '-0.02679', '0.01786', '-0.02411', '0.02450', '-0.00993', '-0.01590', '0.00811', '-0.01688', '-0.00088', '0.00763', '0.00373', '0.03015']
Epoch 35: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00144 | Gamma1: ['2.30346', '2.30798', '2.30574', '2.29176', '2.31671', '2.31965', '2.31154', '2.31481', '2.28413', '2.29299', '2.29218', '2.28023', '2.30122'] | Gamma1 Grad: ['0.02114', '-0.03370', '0.06468', '0.00472', '0.04061', '0.04749', '0.02221', '-0.01823', '0.00328', '-0.00817', '0.00797', '-0.01596', '0.01042']
Epoch 36: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['2.29638', '2.29516', '2.31436', '2.30472', '2.29736', '2.31207', '2.28910', '2.31738', '2.30263', '2.30244', '2.30044', '2.29578', '2.29071'] | Gamma1 Grad: ['0.01429', '-0.00684', '0.03460', '-0.00764', '0.07634', '0.01890', '-0.00724', '0.00722', '-0.01386', '-0.00519', '-0.00602', '-0.03155', '0.03015']
Epoch 37: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00139 | Gamma1: ['2.29286', '2.29701', '2.29723', '2.28168', '2.27767', '2.32766', '2.29768', '2.29706', '2.30966', '2.28996', '2.29128', '2.29787', '2.31462'] | Gamma1 Grad: ['0.09329', '-0.00571', '-0.06483', '-0.01963', '0.04862', '0.02063', '-0.02712', '-0.00979', '-0.00873', '0.00123', '0.00064', '0.00862', '0.01211']
Epoch 38: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.30101', '2.29198', '2.29097', '2.30455', '2.30658', '2.31612', '2.30655', '2.30876', '2.29968', '2.29188', '2.28613', '2.28475', '2.30401'] | Gamma1 Grad: ['0.01968', '0.02063', '-0.03940', '0.08943', '0.00307', '-0.07245', '0.01661', '-0.01017', '-0.01626', '-0.00643', '-0.00875', '0.01506', '0.07420']
Epoch 39: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00133 | Gamma1: ['2.30842', '2.30202', '2.31289', '2.28890', '2.29348', '2.30453', '2.29817', '2.31163', '2.29049', '2.29596', '2.30102', '2.28868', '2.30029'] | Gamma1 Grad: ['-0.01481', '0.04445', '0.03337', '-0.00448', '0.08127', '0.01119', '0.00341', '0.01130', '-0.00389', '0.00800', '-0.00556', '-0.02109', '0.02605']
Epoch 40: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['2.32785', '2.36822', '2.31433', '2.28462', '2.31788', '2.33005', '2.35005', '2.35369', '2.32211', '2.28662', '2.30023', '2.27841', '2.32194'] | Gamma1 Grad: ['0.00032', '0.01784', '-0.06867', '-0.03452', '0.03407', '0.00536', '-0.00858', '-0.01249', '-0.00228', '0.00971', '0.00581', '-0.03398', '-0.03253']
Epoch 41: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00125 | Gamma1: ['2.34143', '2.33211', '2.33722', '2.28635', '2.32009', '2.33485', '2.33890', '2.35634', '2.32191', '2.29827', '2.29917', '2.28185', '2.31432'] | Gamma1 Grad: ['-0.01402', '0.02721', '0.03543', '0.04717', '-0.15081', '0.03516', '-0.00721', '-0.03300', '0.02834', '0.00754', '-0.00015', '0.01789', '-0.01119']
Epoch 42: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.32835', '2.33760', '2.33140', '2.28733', '2.29475', '2.34208', '2.36179', '2.35933', '2.33239', '2.30886', '2.29830', '2.28068', '2.33531'] | Gamma1 Grad: ['0.03216', '0.03165', '0.01330', '0.01951', '0.00737', '-0.01866', '-0.00582', '0.02822', '-0.00638', '-0.01089', '0.00210', '-0.05803', '0.00725']
Epoch 43: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00115 | Gamma1: ['2.32324', '2.35429', '2.32464', '2.27976', '2.31951', '2.33318', '2.36206', '2.35228', '2.33344', '2.30167', '2.31275', '2.27694', '2.33379'] | Gamma1 Grad: ['0.00835', '0.01879', '0.05146', '0.01075', '0.13559', '0.01229', '-0.01995', '0.02683', '-0.02680', '0.00476', '-0.00351', '0.00234', '0.01268']
Epoch 44: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['2.34228', '2.32350', '2.34506', '2.30113', '2.31506', '2.33301', '2.35903', '2.36016', '2.34560', '2.30351', '2.30616', '2.28567', '2.31515'] | Gamma1 Grad: ['0.07265', '-0.08264', '0.01510', '0.03667', '-0.09264', '-0.02275', '-0.03931', '0.04520', '0.01565', '0.01342', '0.00915', '-0.01865', '-0.06844']
Epoch 45: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00105 | Gamma1: ['2.33963', '2.32586', '2.33009', '2.33215', '2.27518', '2.36003', '2.36726', '2.36048', '2.32935', '2.31248', '2.31396', '2.28825', '2.32400'] | Gamma1 Grad: ['0.03402', '-0.06075', '0.03854', '-0.02643', '0.01486', '-0.02041', '0.01935', '-0.05366', '0.02361', '0.00272', '-0.01101', '0.00831', '0.03021']
Epoch 46: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.33753', '2.34579', '2.31915', '2.29751', '2.29250', '2.32082', '2.35770', '2.36222', '2.32687', '2.31010', '2.30820', '2.30021', '2.31168'] | Gamma1 Grad: ['-0.05758', '-0.01232', '0.03409', '0.02060', '-0.05752', '0.01996', '-0.02736', '0.01137', '-0.01410', '0.00081', '0.00924', '-0.00918', '0.01042']
Epoch 47: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00094 | Gamma1: ['2.32553', '2.33847', '2.29180', '2.28050', '2.29037', '2.32413', '2.36038', '2.35702', '2.33670', '2.30453', '2.30507', '2.27260', '2.30436'] | Gamma1 Grad: ['-0.06606', '0.01653', '0.03017', '-0.05834', '-0.03008', '0.00904', '-0.01204', '0.01683', '-0.00205', '0.00052', '0.00378', '0.02822', '-0.00414']
Epoch 48: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['2.32138', '2.33499', '2.30376', '2.26477', '2.26786', '2.33342', '2.36116', '2.37256', '2.33531', '2.30154', '2.29788', '2.28516', '2.31655'] | Gamma1 Grad: ['-0.05498', '-0.02548', '0.02084', '-0.00101', '0.06548', '0.03397', '-0.02062', '-0.01467', '0.02277', '0.00347', '0.01572', '-0.10981', '0.11022']
Epoch 49: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00083 | Gamma1: ['2.29691', '2.32208', '2.30020', '2.27401', '2.27825', '2.32554', '2.34648', '2.37954', '2.34359', '2.30782', '2.30356', '2.29514', '2.30897'] | Gamma1 Grad: ['-0.01040', '-0.06467', '-0.04596', '0.03871', '-0.05584', '0.01186', '0.00643', '0.02114', '0.02310', '0.00209', '0.01064', '0.00412', '0.00670']
Epoch 50: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31461', '2.32789', '2.31209', '2.28250', '2.28071', '2.31760', '2.34165', '2.35604', '2.32118', '2.30860', '2.30018', '2.30198', '2.30937'] | Gamma1 Grad: ['0.02545', '-0.02947', '-0.02771', '0.08208', '-0.04242', '0.05901', '-0.03606', '-0.03510', '0.00545', '-0.00028', '0.01006', '0.00831', '-0.05324']
Epoch 51: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00072 | Gamma1: ['2.32663', '2.32864', '2.30062', '2.29923', '2.27513', '2.32794', '2.35331', '2.35596', '2.30585', '2.30892', '2.29592', '2.28718', '2.30641'] | Gamma1 Grad: ['-0.03192', '-0.04269', '0.02709', '0.00187', '0.00798', '0.01857', '-0.00516', '-0.00023', '0.01589', '-0.01309', '-0.00053', '0.00593', '-0.04175']
Epoch 52: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['2.29634', '2.32743', '2.29585', '2.29789', '2.26978', '2.32551', '2.34226', '2.34813', '2.30228', '2.29604', '2.29895', '2.28281', '2.29632'] | Gamma1 Grad: ['-0.02660', '-0.02216', '-0.01027', '-0.00503', '0.00267', '-0.04602', '0.00739', '0.02053', '0.00018', '0.00162', '0.00294', '0.01653', '0.00480']
Epoch 53: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00061 | Gamma1: ['2.31240', '2.31674', '2.31604', '2.28683', '2.28493', '2.30685', '2.33367', '2.34113', '2.32368', '2.29190', '2.29850', '2.27682', '2.28451'] | Gamma1 Grad: ['-0.02222', '-0.01150', '0.08557', '0.01777', '-0.00301', '-0.02631', '0.00151', '0.02533', '0.01461', '0.00057', '-0.00301', '0.00573', '-0.02653']
Epoch 54: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31577', '2.33190', '2.29870', '2.28745', '2.26112', '2.31182', '2.31171', '2.35149', '2.32976', '2.30513', '2.30688', '2.29171', '2.30499'] | Gamma1 Grad: ['-0.05887', '-0.03329', '-0.09713', '0.01856', '0.04816', '-0.02257', '-0.00326', '0.02730', '-0.00841', '-0.01670', '-0.00007', '-0.01630', '-0.00733']
Epoch 55: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00050 | Gamma1: ['2.31751', '2.33232', '2.30012', '2.30114', '2.25457', '2.31276', '2.33954', '2.35472', '2.32510', '2.31072', '2.31443', '2.27154', '2.30376'] | Gamma1 Grad: ['0.02584', '-0.05522', '-0.00816', '-0.01114', '0.06369', '-0.00408', '0.00621', '0.08233', '-0.01952', '-0.01376', '0.00753', '-0.00769', '0.04694']
Epoch 56: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['2.31412', '2.31191', '2.30164', '2.27282', '2.27666', '2.32437', '2.33954', '2.34987', '2.32004', '2.29939', '2.30497', '2.28879', '2.28856'] | Gamma1 Grad: ['-0.03206', '-0.02980', '0.07105', '-0.06343', '0.06642', '-0.08576', '-0.00836', '-0.01040', '-0.01128', '0.00174', '-0.00192', '-0.00293', '0.08919']
Epoch 57: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00040 | Gamma1: ['2.30827', '2.32922', '2.29781', '2.27285', '2.25605', '2.29529', '2.33771', '2.33566', '2.32158', '2.30728', '2.29315', '2.28417', '2.29862'] | Gamma1 Grad: ['-0.01862', '0.00254', '-0.00558', '-0.04941', '-0.00642', '0.02671', '-0.00839', '0.00180', '-0.00462', '0.00326', '0.01949', '-0.00011', '0.03511']
Epoch 58: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.32330', '2.35502', '2.27941', '2.28458', '2.26532', '2.28424', '2.34468', '2.34790', '2.31294', '2.30009', '2.27546', '2.27826', '2.30824'] | Gamma1 Grad: ['-0.00353', '0.02084', '0.03487', '0.04673', '0.08303', '0.04752', '-0.08589', '0.05354', '0.01901', '0.00303', '0.00096', '0.01191', '0.00540']
Epoch 59: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00030 | Gamma1: ['2.32017', '2.33495', '2.27126', '2.30242', '2.26533', '2.27025', '2.33169', '2.33808', '2.32075', '2.30328', '2.28637', '2.28977', '2.30088'] | Gamma1 Grad: ['-0.02856', '0.00343', '-0.03381', '0.04590', '0.06816', '-0.07149', '-0.03488', '0.01188', '-0.00098', '0.00184', '-0.00303', '-0.01587', '-0.00711']
Epoch 60: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['2.32366', '2.33767', '2.30877', '2.29204', '2.27655', '2.30698', '2.33319', '2.37093', '2.32922', '2.29688', '2.29179', '2.27849', '2.29681'] | Gamma1 Grad: ['-0.01442', '0.05586', '0.02540', '0.00354', '-0.01882', '0.02335', '-0.02084', '-0.00941', '0.00179', '-0.00065', '-0.00403', '0.01688', '-0.00585']
Epoch 61: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00022 | Gamma1: ['2.31214', '2.35786', '2.31387', '2.28299', '2.26038', '2.29458', '2.35422', '2.37564', '2.34422', '2.29315', '2.29212', '2.26714', '2.29525'] | Gamma1 Grad: ['-0.01269', '0.00394', '-0.00183', '0.03078', '-0.00840', '-0.02128', '-0.01373', '0.01746', '-0.00119', '0.00304', '-0.00203', '-0.00742', '-0.00881']
Epoch 62: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.30733', '2.34992', '2.29734', '2.27257', '2.26677', '2.28863', '2.35431', '2.37036', '2.33978', '2.28708', '2.28506', '2.26921', '2.30442'] | Gamma1 Grad: ['-0.01233', '-0.04625', '0.00490', '-0.01208', '-0.07465', '-0.04166', '-0.04191', '-0.04098', '0.01887', '-0.01018', '-0.01309', '-0.02099', '-0.02728']
Epoch 63: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00016 | Gamma1: ['2.31735', '2.35643', '2.30623', '2.27931', '2.24118', '2.29573', '2.36295', '2.37825', '2.33202', '2.29931', '2.28663', '2.27454', '2.30269'] | Gamma1 Grad: ['0.04595', '0.02136', '0.04314', '-0.07204', '-0.01258', '0.12603', '-0.10559', '0.02289', '-0.00337', '-0.01586', '-0.00793', '0.00457', '-0.04660']
Epoch 64: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['2.33156', '2.34647', '2.30499', '2.27922', '2.24472', '2.29535', '2.35059', '2.36269', '2.34327', '2.30890', '2.29122', '2.29006', '2.30228'] | Gamma1 Grad: ['0.02406', '-0.03732', '0.02188', '-0.00989', '-0.02080', '-0.02722', '-0.01480', '-0.02490', '0.00775', '-0.00429', '-0.01828', '-0.00061', '-0.04195']
Epoch 65: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00011 | Gamma1: ['2.32227', '2.35519', '2.30596', '2.27060', '2.25629', '2.29180', '2.34879', '2.36609', '2.33792', '2.31537', '2.29154', '2.28598', '2.28050'] | Gamma1 Grad: ['0.02535', '0.03320', '0.04427', '-0.05032', '0.08717', '-0.01636', '0.02757', '0.00803', '0.00167', '-0.00517', '-0.00789', '-0.00270', '-0.00459']
Epoch 66: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.33725', '2.35227', '2.30462', '2.26285', '2.24935', '2.29609', '2.34369', '2.36037', '2.35278', '2.31986', '2.29442', '2.28924', '2.28428'] | Gamma1 Grad: ['-0.00679', '0.00444', '-0.01497', '0.04543', '0.09348', '0.03477', '0.00858', '-0.05157', '-0.00519', '-0.00297', '-0.01038', '-0.00255', '0.00693']
Epoch 67: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00007 | Gamma1: ['2.33509', '2.35730', '2.31022', '2.27188', '2.24438', '2.29830', '2.34515', '2.36023', '2.34842', '2.31014', '2.30200', '2.28848', '2.28487'] | Gamma1 Grad: ['0.04067', '-0.04464', '-0.08311', '0.12738', '0.08544', '-0.01643', '0.03726', '-0.03640', '-0.00258', '0.00163', '0.01288', '0.03459', '0.02534']
Epoch 68: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['2.32476', '2.37653', '2.32494', '2.26011', '2.26288', '2.28588', '2.33861', '2.36846', '2.33326', '2.31425', '2.30226', '2.26875', '2.29782'] | Gamma1 Grad: ['0.02506', '0.01404', '0.02631', '0.00105', '0.02664', '0.02758', '-0.03338', '-0.02213', '0.00465', '-0.00441', '-0.01185', '0.02557', '0.00507']
Epoch 69: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00005 | Gamma1: ['2.34470', '2.34598', '2.30611', '2.26163', '2.22834', '2.27653', '2.34500', '2.36305', '2.32884', '2.30885', '2.30069', '2.28683', '2.29580'] | Gamma1 Grad: ['0.00015', '-0.00236', '-0.00453', '0.00918', '0.02882', '-0.06653', '0.00531', '0.01801', '-0.01023', '0.00373', '-0.00027', '0.02741', '0.00986']
Epoch 70: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.34491', '2.35330', '2.29788', '2.25754', '2.24493', '2.28630', '2.34341', '2.37523', '2.33476', '2.30952', '2.29531', '2.28659', '2.30631'] | Gamma1 Grad: ['0.00690', '0.02675', '0.07089', '0.03884', '0.02693', '-0.06396', '-0.00995', '0.00214', '-0.00440', '-0.00139', '0.01072', '0.00359', '0.02672']
Epoch 71: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30158', '2.34085', '2.31673', '2.22275', '2.25339', '2.29761', '2.36201', '2.37384', '2.34600', '2.29596', '2.29699', '2.27266', '2.31627'] | Gamma1 Grad: ['-0.01611', '-0.00490', '-0.03706', '-0.04397', '0.00430', '-0.05069', '-0.01577', '0.02991', '0.01163', '0.00649', '0.00292', '0.01206', '0.04904']
Epoch 72: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30754', '2.35840', '2.28665', '2.25950', '2.25864', '2.28301', '2.35129', '2.36239', '2.33389', '2.32413', '2.29037', '2.24530', '2.27806'] | Gamma1 Grad: ['0.00360', '-0.03032', '-0.01815', '0.03634', '0.05853', '-0.07363', '0.02225', '0.00911', '-0.00599', '0.00885', '0.00577', '0.00212', '0.03993']
Epoch 73: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.33180', '2.36185', '2.33629', '2.27415', '2.20723', '2.24903', '2.35001', '2.39918', '2.37053', '2.28660', '2.28174', '2.26277', '2.27985'] | Gamma1 Grad: ['-0.01330', '-0.01115', '-0.12844', '-0.00463', '-0.07342', '0.01261', '0.00433', '-0.02433', '-0.01914', '0.02834', '0.01346', '-0.01434', '0.05523']
Epoch 74: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.32367', '2.32031', '2.29142', '2.23873', '2.23693', '2.24120', '2.34276', '2.36137', '2.38328', '2.29961', '2.28479', '2.27354', '2.29268'] | Gamma1 Grad: ['0.00826', '-0.02992', '0.01153', '-0.00433', '0.03433', '0.01449', '-0.00702', '0.03408', '-0.01344', '0.00834', '0.00429', '-0.01289', '0.01553']
Epoch 75: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.31600', '2.32091', '2.33108', '2.26665', '2.24009', '2.29954', '2.33570', '2.36745', '2.37213', '2.30012', '2.29805', '2.29709', '2.29143'] | Gamma1 Grad: ['-0.01948', '-0.07034', '-0.02129', '-0.00576', '-0.09727', '0.11991', '-0.03286', '0.00330', '0.00091', '0.00802', '0.00761', '0.02960', '0.00225']
Epoch 76: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['2.29724', '2.31624', '2.29456', '2.25566', '2.21804', '2.27077', '2.32711', '2.36295', '2.34935', '2.30096', '2.31573', '2.28788', '2.27930'] | Gamma1 Grad: ['0.00628', '-0.00914', '-0.05219', '-0.01884', '0.04314', '-0.01112', '-0.04400', '-0.04191', '0.00298', '0.00413', '-0.01200', '-0.00588', '0.04107']
Epoch 77: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00147 | Gamma1: ['2.31859', '2.32062', '2.31444', '2.25967', '2.25297', '2.28367', '2.32668', '2.37469', '2.35359', '2.29521', '2.31363', '2.28376', '2.26234'] | Gamma1 Grad: ['0.01588', '0.02136', '0.01555', '0.00249', '0.01681', '-0.00469', '0.01443', '0.00413', '0.00479', '-0.00441', '-0.00310', '0.00243', '-0.02372']
Epoch 78: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.29015', '2.31321', '2.28226', '2.26435', '2.25808', '2.27001', '2.34248', '2.36226', '2.33710', '2.29311', '2.28534', '2.29041', '2.27112'] | Gamma1 Grad: ['-0.05418', '-0.03252', '0.03159', '-0.04010', '0.06712', '0.00437', '0.06750', '-0.04967', '-0.01202', '-0.00226', '-0.00246', '0.01268', '0.02824']
Epoch 79: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00146 | Gamma1: ['2.28864', '2.34702', '2.27613', '2.25611', '2.23600', '2.26070', '2.32402', '2.35987', '2.34741', '2.31080', '2.29102', '2.28262', '2.27828'] | Gamma1 Grad: ['0.00407', '-0.04449', '-0.00898', '-0.00371', '-0.00990', '0.04544', '0.04084', '0.06139', '-0.00200', '-0.00023', '0.00239', '0.02104', '0.03063']
Epoch 80: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00144 | Gamma1: ['2.30417', '2.33730', '2.32331', '2.27407', '2.23992', '2.27654', '2.33301', '2.34218', '2.32210', '2.32017', '2.31394', '2.29006', '2.29490'] | Gamma1 Grad: ['0.02130', '-0.02906', '-0.01559', '0.08107', '-0.15338', '-0.07458', '-0.06283', '0.08159', '-0.01882', '0.00918', '0.03426', '-0.02631', '0.02667']
Epoch 81: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00143 | Gamma1: ['2.29318', '2.32288', '2.30220', '2.25534', '2.22940', '2.26256', '2.31541', '2.32809', '2.30688', '2.32213', '2.31284', '2.29080', '2.31447'] | Gamma1 Grad: ['0.01926', '0.02245', '0.00859', '0.00849', '0.09185', '0.06715', '0.01333', '0.07012', '0.00820', '0.01277', '0.02619', '-0.00276', '0.02235']
Epoch 82: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00142 | Gamma1: ['2.28119', '2.31274', '2.27584', '2.25936', '2.23172', '2.27584', '2.29514', '2.31179', '2.31119', '2.32547', '2.32815', '2.28607', '2.32998'] | Gamma1 Grad: ['0.02765', '-0.01345', '0.04247', '0.02523', '0.05589', '-0.04861', '-0.00964', '0.02994', '-0.00484', '-0.00105', '0.00303', '-0.01361', '0.02210']
Epoch 83: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00141 | Gamma1: ['2.30821', '2.32738', '2.27453', '2.25159', '2.24162', '2.27800', '2.29268', '2.33222', '2.31709', '2.31645', '2.32683', '2.29655', '2.32058'] | Gamma1 Grad: ['0.00061', '0.00166', '0.00116', '0.00059', '-0.00017', '-0.00092', '0.00065', '0.00025', '0.00096', '0.00054', '0.00032', '0.00089', '0.00066']
Epoch 84: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00139 | Gamma1: ['2.29653', '2.29735', '2.28279', '2.25533', '2.26327', '2.28843', '2.29984', '2.34263', '2.31473', '2.30925', '2.32772', '2.29313', '2.31998'] | Gamma1 Grad: ['-0.03017', '-0.04093', '0.00411', '-0.05420', '-0.03694', '0.02634', '0.00070', '0.01017', '-0.00816', '-0.00401', '-0.00796', '0.01886', '0.01083']
Epoch 85: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00138 | Gamma1: ['2.29629', '2.31237', '2.30293', '2.26293', '2.27367', '2.27347', '2.29392', '2.33224', '2.29920', '2.31921', '2.31427', '2.30652', '2.31232'] | Gamma1 Grad: ['0.00402', '0.01473', '-0.00407', '0.00817', '-0.00549', '0.02349', '0.00068', '0.04487', '0.00070', '-0.00348', '-0.00296', '0.00333', '0.00814']
Epoch 86: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00136 | Gamma1: ['2.29597', '2.30463', '2.28530', '2.26616', '2.25899', '2.29926', '2.29496', '2.31231', '2.31856', '2.30819', '2.30959', '2.30617', '2.32475'] | Gamma1 Grad: ['0.00196', '-0.02300', '-0.01494', '0.07482', '-0.01243', '-0.01846', '0.06347', '-0.03870', '0.01099', '0.00201', '0.00260', '0.00153', '-0.03130']
Epoch 87: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00134 | Gamma1: ['2.29749', '2.29824', '2.29086', '2.25065', '2.28368', '2.25169', '2.30439', '2.29832', '2.30494', '2.31311', '2.30796', '2.30765', '2.32627'] | Gamma1 Grad: ['-0.00396', '0.01960', '0.02867', '0.01714', '0.03665', '0.03476', '0.02597', '0.04135', '0.00010', '-0.00549', '0.00463', '0.00493', '-0.00515']
Epoch 88: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00133 | Gamma1: ['2.31277', '2.30088', '2.27273', '2.24195', '2.26656', '2.26968', '2.30316', '2.31479', '2.30409', '2.29926', '2.30618', '2.30778', '2.30957'] | Gamma1 Grad: ['0.00243', '0.01055', '0.09197', '0.05522', '0.03080', '0.01869', '-0.05741', '-0.01487', '-0.00035', '0.00191', '-0.00356', '0.00773', '0.00529']
Epoch 89: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00131 | Gamma1: ['2.30001', '2.32115', '2.27406', '2.27995', '2.24621', '2.26364', '2.27927', '2.30403', '2.30582', '2.30667', '2.31938', '2.30323', '2.31542'] | Gamma1 Grad: ['0.01114', '-0.03204', '0.03298', '0.06191', '-0.01659', '-0.01916', '-0.03970', '-0.06876', '0.01022', '0.00406', '-0.01640', '0.00615', '-0.05698']
Epoch 90: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00129 | Gamma1: ['2.30298', '2.30319', '2.30070', '2.24049', '2.22439', '2.25520', '2.28519', '2.30523', '2.30465', '2.30208', '2.30872', '2.31190', '2.31946'] | Gamma1 Grad: ['-0.00476', '0.02282', '-0.05452', '-0.01850', '-0.01474', '-0.00368', '-0.01045', '-0.01895', '-0.00214', '-0.00457', '-0.00258', '0.00157', '0.00756']
Epoch 91: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00127 | Gamma1: ['2.32079', '2.29848', '2.29037', '2.22758', '2.25248', '2.27621', '2.26872', '2.30403', '2.31013', '2.30578', '2.30346', '2.29636', '2.33455'] | Gamma1 Grad: ['0.00487', '0.06229', '0.04961', '-0.03168', '0.00725', '-0.03334', '0.03590', '-0.03195', '-0.00069', '-0.00227', '-0.01148', '0.01006', '-0.00281']
Epoch 92: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00125 | Gamma1: ['2.29979', '2.29146', '2.27706', '2.24211', '2.26579', '2.27077', '2.28876', '2.29653', '2.30853', '2.29273', '2.30392', '2.29817', '2.33912'] | Gamma1 Grad: ['0.04875', '0.01486', '-0.05827', '-0.05899', '0.07268', '-0.09401', '-0.02572', '0.01715', '0.00840', '0.00709', '-0.01680', '0.04766', '-0.00214']
Epoch 93: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00122 | Gamma1: ['2.28346', '2.30092', '2.24557', '2.23393', '2.26330', '2.28493', '2.29929', '2.31113', '2.31600', '2.30860', '2.31409', '2.31241', '2.33084'] | Gamma1 Grad: ['-0.03758', '-0.01850', '-0.01265', '0.06659', '0.10705', '-0.05792', '-0.06607', '-0.03520', '-0.00517', '-0.00411', '-0.01412', '-0.00230', '0.02676']
Epoch 94: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00120 | Gamma1: ['2.29538', '2.30510', '2.29396', '2.26521', '2.24280', '2.26975', '2.28708', '2.29943', '2.30316', '2.30772', '2.30761', '2.31010', '2.32018'] | Gamma1 Grad: ['-0.00107', '-0.00427', '-0.00251', '0.01107', '0.00438', '-0.00476', '0.00134', '-0.00367', '0.00080', '0.00018', '0.00029', '0.00051', '0.00021']
Epoch 95: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00118 | Gamma1: ['2.28257', '2.27507', '2.26927', '2.25259', '2.24753', '2.27269', '2.30122', '2.32403', '2.30905', '2.29697', '2.30692', '2.30120', '2.32017'] | Gamma1 Grad: ['-0.05094', '-0.05527', '-0.03142', '-0.05033', '-0.13768', '0.00482', '0.00010', '0.02938', '0.00218', '-0.01104', '-0.01706', '0.00332', '-0.03107']
Epoch 96: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00115 | Gamma1: ['2.30329', '2.30398', '2.27765', '2.26050', '2.24023', '2.28104', '2.30242', '2.30451', '2.29644', '2.29871', '2.32207', '2.30656', '2.34179'] | Gamma1 Grad: ['-0.01444', '-0.02589', '0.00379', '0.01592', '-0.00612', '-0.00430', '-0.01277', '0.01065', '0.00696', '0.00069', '0.00624', '-0.00313', '-0.00910']
Epoch 97: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00113 | Gamma1: ['2.30469', '2.31778', '2.28175', '2.24543', '2.22182', '2.29124', '2.29664', '2.30647', '2.30359', '2.29582', '2.30856', '2.31237', '2.33535'] | Gamma1 Grad: ['-0.00171', '0.00127', '-0.00810', '-0.00858', '-0.00516', '0.00126', '0.01918', '-0.01383', '-0.00073', '-0.00060', '-0.00394', '0.00262', '-0.00559']
Epoch 98: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00110 | Gamma1: ['2.30836', '2.29961', '2.30278', '2.24619', '2.25773', '2.27141', '2.28614', '2.30147', '2.30764', '2.29936', '2.30376', '2.30602', '2.32306'] | Gamma1 Grad: ['0.02509', '0.00817', '0.04508', '0.00496', '-0.00464', '-0.04557', '0.01040', '-0.02786', '-0.00194', '-0.00445', '-0.00172', '0.00094', '-0.00317']
Epoch 99: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00108 | Gamma1: ['2.28731', '2.29999', '2.27418', '2.23760', '2.24964', '2.27236', '2.28374', '2.31769', '2.30555', '2.30132', '2.29724', '2.29810', '2.33327'] | Gamma1 Grad: ['0.01989', '0.02974', '-0.00104', '0.03572', '0.01457', '-0.01299', '0.00521', '-0.05680', '-0.00152', '0.00274', '0.00150', '0.00429', '-0.02246']
