Epoch 0: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000'] | Gamma1 Grad: ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']
Epoch 1: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.22795', '2.23494', '2.23014', '2.22774', '2.22733', '2.22671', '2.22577', '2.22691', '2.22785', '2.22699', '2.22252', '2.21943', '2.20776'] | Gamma1 Grad: ['0.00933', '-0.00427', '0.00018', '-0.00439', '-0.00850', '-0.00989', '-0.00877', '-0.00363', '-0.01255', '-0.01158', '-0.00627', '-0.02307', '0.00432']
Epoch 2: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.28884', '2.29982', '2.29246', '2.28344', '2.28527', '2.28075', '2.28175', '2.28316', '2.28382', '2.28266', '2.28037', '2.28211', '2.25888'] | Gamma1 Grad: ['-0.02591', '-0.00145', '0.00414', '-0.00905', '-0.00516', '-0.00106', '-0.00231', '0.00298', '-0.00554', '-0.00431', '-0.00276', '0.01448', '-0.01988']
Epoch 3: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.30452', '2.30929', '2.30599', '2.29050', '2.29394', '2.29187', '2.28966', '2.28794', '2.28910', '2.28720', '2.28508', '2.27090', '2.26998'] | Gamma1 Grad: ['-0.00124', '0.01234', '0.00805', '0.00987', '-0.00235', '0.00098', '-0.00544', '0.00027', '-0.01430', '-0.01423', '-0.00561', '-0.03088', '-0.04595']
Epoch 4: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.30142', '2.31566', '2.30612', '2.29783', '2.29718', '2.29525', '2.29362', '2.29456', '2.29035', '2.29254', '2.29215', '2.27742', '2.27782'] | Gamma1 Grad: ['0.02010', '-0.01584', '0.00732', '-0.00592', '0.00057', '-0.00173', '-0.00359', '0.00631', '-0.00354', '-0.00451', '0.00100', '0.00979', '0.01989']
Epoch 5: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31396', '2.32951', '2.31623', '2.30199', '2.30410', '2.29932', '2.29610', '2.29563', '2.29588', '2.29123', '2.28973', '2.28172', '2.28559'] | Gamma1 Grad: ['-0.00715', '0.03196', '0.02884', '-0.00434', '-0.00035', '0.00328', '0.01173', '0.00527', '-0.00270', '0.01462', '0.00813', '-0.01765', '-0.01875']
Epoch 6: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31912', '2.31693', '2.30322', '2.29344', '2.30172', '2.29663', '2.29033', '2.29164', '2.29101', '2.29411', '2.29270', '2.28287', '2.28815'] | Gamma1 Grad: ['-0.02130', '-0.01486', '0.00909', '-0.01530', '-0.00769', '0.00322', '0.00263', '-0.00912', '0.00154', '0.00471', '0.00523', '0.01145', '0.00806']
Epoch 7: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.31611', '2.30953', '2.30621', '2.30120', '2.29471', '2.29868', '2.29516', '2.29585', '2.29454', '2.29309', '2.29558', '2.28610', '2.28851'] | Gamma1 Grad: ['-0.00238', '0.00565', '-0.00667', '0.00570', '0.00136', '0.00472', '0.00199', '-0.00137', '-0.00201', '-0.00452', '0.00170', '-0.02368', '0.10247']
Epoch 8: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.31906', '2.32422', '2.32015', '2.29657', '2.29969', '2.30031', '2.29222', '2.29704', '2.29778', '2.29779', '2.29597', '2.28510', '2.29539'] | Gamma1 Grad: ['-0.00784', '-0.01541', '0.00626', '0.02285', '0.00338', '-0.01002', '0.00616', '-0.00156', '0.01095', '0.00003', '-0.00092', '0.02153', '0.07887']
Epoch 9: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.31945', '2.31567', '2.31731', '2.29417', '2.30094', '2.29687', '2.28601', '2.29714', '2.29911', '2.29887', '2.29669', '2.27922', '2.29607'] | Gamma1 Grad: ['-0.01222', '-0.01300', '-0.01587', '-0.02295', '0.00700', '-0.00674', '0.00743', '0.00600', '-0.00267', '-0.01260', '-0.00180', '0.00868', '-0.00895']
Epoch 10: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.31593', '2.31946', '2.31958', '2.29723', '2.30439', '2.30470', '2.29356', '2.30038', '2.29461', '2.29507', '2.29851', '2.28756', '2.29678'] | Gamma1 Grad: ['-0.02378', '-0.03103', '0.00215', '-0.01518', '0.00255', '0.00728', '0.00429', '-0.00024', '0.00662', '-0.00005', '0.00565', '0.00593', '0.00921']
Epoch 11: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.31190', '2.31094', '2.32117', '2.29791', '2.30358', '2.30844', '2.28715', '2.29200', '2.29662', '2.29234', '2.29288', '2.28071', '2.30138'] | Gamma1 Grad: ['-0.00967', '0.01198', '0.01322', '-0.00865', '-0.00627', '-0.01812', '0.00522', '-0.00039', '0.00516', '0.00798', '-0.00181', '-0.00470', '0.05069']
Epoch 12: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.30581', '2.31613', '2.31299', '2.29396', '2.31024', '2.30826', '2.28510', '2.29722', '2.28825', '2.28890', '2.29048', '2.27453', '2.29948'] | Gamma1 Grad: ['-0.00411', '0.01445', '-0.00104', '0.00955', '0.01228', '-0.01129', '-0.00113', '-0.00042', '-0.00452', '0.00152', '-0.00302', '0.00117', '0.04521']
Epoch 13: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['2.32401', '2.33179', '2.30877', '2.29862', '2.30028', '2.31004', '2.29433', '2.31388', '2.30652', '2.29924', '2.28384', '2.29501', '2.30425'] | Gamma1 Grad: ['0.01317', '0.04420', '-0.05501', '0.03276', '-0.02279', '-0.00831', '0.00486', '-0.00015', '0.00730', '0.00692', '0.00479', '0.02136', '0.04560']
Epoch 14: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.31004', '2.32952', '2.31872', '2.28208', '2.31185', '2.29832', '2.28511', '2.29961', '2.29408', '2.28563', '2.28174', '2.30272', '2.29541'] | Gamma1 Grad: ['0.02175', '-0.00278', '0.00516', '-0.05175', '0.00059', '-0.00302', '-0.01966', '-0.00989', '0.00287', '0.00153', '0.00040', '0.01602', '-0.02398']
Epoch 15: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['2.30914', '2.30790', '2.30298', '2.30349', '2.30264', '2.31261', '2.29526', '2.29976', '2.30129', '2.29923', '2.29926', '2.28454', '2.29439'] | Gamma1 Grad: ['0.04509', '-0.01031', '0.02336', '-0.00153', '-0.01677', '0.01134', '-0.00453', '0.01892', '0.01282', '0.02207', '0.01272', '0.00082', '0.07534']
Epoch 16: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.30564', '2.31861', '2.31022', '2.30022', '2.30269', '2.31707', '2.29494', '2.30311', '2.28614', '2.28806', '2.29570', '2.28963', '2.30124'] | Gamma1 Grad: ['0.06745', '-0.00660', '0.01990', '-0.00870', '-0.00069', '0.01989', '0.01924', '0.00671', '0.00539', '0.00427', '0.00122', '0.02216', '-0.01129']
Epoch 17: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['2.31847', '2.31544', '2.29697', '2.30197', '2.29769', '2.31385', '2.29566', '2.30607', '2.29777', '2.29105', '2.29502', '2.28436', '2.31730'] | Gamma1 Grad: ['-0.01297', '0.00964', '0.00964', '-0.01345', '-0.00278', '-0.01047', '-0.00141', '-0.00219', '-0.00052', '-0.00223', '-0.00436', '-0.00077', '0.03937']
Epoch 18: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.31037', '2.32956', '2.28599', '2.30087', '2.31624', '2.31329', '2.29524', '2.30096', '2.29609', '2.29888', '2.29496', '2.28913', '2.31099'] | Gamma1 Grad: ['0.01783', '-0.04290', '0.01935', '0.02963', '-0.01311', '0.00796', '-0.00879', '-0.00192', '-0.00699', '-0.00139', '-0.00142', '-0.00250', '0.03150']
Epoch 19: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['2.31032', '2.32892', '2.30398', '2.28295', '2.31196', '2.29479', '2.29541', '2.30208', '2.29956', '2.29943', '2.29464', '2.28675', '2.30517'] | Gamma1 Grad: ['0.00095', '0.03513', '-0.03057', '-0.00982', '0.00083', '-0.00720', '0.00224', '0.00244', '-0.00100', '0.00435', '0.00468', '-0.01442', '-0.02521']
Epoch 20: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31049', '2.31326', '2.28951', '2.29833', '2.30943', '2.30552', '2.29914', '2.29825', '2.29199', '2.29254', '2.28868', '2.28510', '2.30239'] | Gamma1 Grad: ['0.01844', '-0.03893', '0.02050', '0.00215', '-0.04958', '-0.04229', '-0.00461', '0.00830', '0.00922', '0.01524', '0.00358', '-0.03336', '-0.01744']
Epoch 21: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['2.30037', '2.31205', '2.30213', '2.29877', '2.30422', '2.30516', '2.29559', '2.29973', '2.29533', '2.29436', '2.29850', '2.29097', '2.30310'] | Gamma1 Grad: ['0.02825', '0.04476', '0.06778', '-0.00691', '0.02241', '0.01790', '-0.01412', '-0.00069', '-0.00634', '0.00171', '0.00599', '0.01950', '-0.01695']
Epoch 22: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31166', '2.30365', '2.30151', '2.29231', '2.30498', '2.29780', '2.29297', '2.30700', '2.29725', '2.29379', '2.29177', '2.28818', '2.30336'] | Gamma1 Grad: ['0.02584', '-0.02835', '0.04616', '-0.01460', '-0.01118', '0.02200', '0.00065', '-0.00839', '-0.01570', '-0.01098', '-0.00790', '0.01017', '0.02394']
Epoch 23: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['2.30211', '2.30726', '2.30204', '2.28808', '2.31075', '2.30821', '2.29629', '2.30564', '2.29625', '2.29486', '2.29474', '2.28691', '2.30840'] | Gamma1 Grad: ['-0.00633', '0.01475', '-0.09762', '-0.00574', '0.00910', '-0.02231', '0.01183', '-0.01242', '-0.00331', '-0.00061', '-0.01316', '0.00772', '0.04727']
Epoch 24: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.30420', '2.30468', '2.30533', '2.29444', '2.30506', '2.30430', '2.29695', '2.29759', '2.30131', '2.29623', '2.29641', '2.29246', '2.30512'] | Gamma1 Grad: ['-0.02510', '0.03043', '-0.01714', '0.04024', '-0.00212', '-0.02404', '0.02546', '-0.00962', '0.00565', '0.00147', '0.00186', '0.00397', '-0.02210']
Epoch 25: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['2.31103', '2.31088', '2.30369', '2.30801', '2.30529', '2.30251', '2.29268', '2.29987', '2.29262', '2.28783', '2.28688', '2.29439', '2.30652'] | Gamma1 Grad: ['-0.05887', '-0.01094', '0.00660', '-0.02780', '-0.02295', '-0.01470', '-0.00120', '0.00144', '-0.00401', '0.01066', '0.00203', '-0.00090', '-0.03916']
Epoch 26: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.30619', '2.31288', '2.31550', '2.30280', '2.30522', '2.32320', '2.30702', '2.30778', '2.30328', '2.29067', '2.28958', '2.28458', '2.29510'] | Gamma1 Grad: ['-0.02997', '-0.05745', '0.04713', '-0.02904', '-0.06871', '0.02420', '-0.01388', '-0.00333', '-0.00009', '-0.00318', '-0.00721', '0.01732', '-0.00159']
Epoch 27: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['2.29980', '2.30539', '2.29408', '2.30093', '2.28873', '2.31132', '2.30126', '2.31227', '2.29830', '2.29575', '2.29603', '2.29509', '2.29895'] | Gamma1 Grad: ['0.03326', '-0.00073', '-0.00284', '-0.00221', '-0.05428', '0.01585', '0.00727', '0.00091', '-0.01219', '0.01133', '0.01576', '0.00395', '0.05335']
Epoch 28: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.30225', '2.31114', '2.30496', '2.30849', '2.31341', '2.31424', '2.29846', '2.30955', '2.29880', '2.28700', '2.29377', '2.28857', '2.31441'] | Gamma1 Grad: ['0.01762', '-0.01127', '0.02500', '-0.03139', '-0.01136', '-0.01503', '0.01458', '0.00787', '0.01495', '0.00391', '-0.00074', '0.03163', '0.00202']
Epoch 29: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['2.29399', '2.30939', '2.29871', '2.29137', '2.30815', '2.30572', '2.29890', '2.30738', '2.29868', '2.29348', '2.29563', '2.28682', '2.30013'] | Gamma1 Grad: ['0.01718', '0.04184', '-0.01097', '0.04712', '0.00798', '-0.03138', '-0.00123', '-0.00932', '-0.00205', '-0.00969', '0.00961', '-0.01879', '0.06159']
Epoch 30: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30053', '2.30639', '2.30145', '2.30143', '2.29704', '2.30827', '2.30422', '2.31090', '2.29751', '2.29049', '2.29120', '2.28593', '2.30441'] | Gamma1 Grad: ['-0.01115', '0.00721', '-0.05039', '0.00081', '0.02189', '-0.00127', '-0.00800', '0.00167', '-0.00108', '-0.01838', '-0.00371', '0.03136', '-0.04273']
Epoch 31: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30787', '2.30620', '2.31357', '2.30855', '2.30167', '2.30574', '2.30234', '2.31594', '2.29918', '2.29436', '2.29986', '2.28933', '2.30054'] | Gamma1 Grad: ['0.03543', '0.02835', '-0.00693', '0.00629', '-0.00009', '-0.00480', '-0.01227', '-0.00535', '0.00508', '0.01494', '0.01862', '-0.00722', '-0.06868']
Epoch 32: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.30563', '2.32110', '2.29620', '2.31170', '2.32114', '2.29578', '2.29463', '2.30017', '2.30099', '2.29373', '2.29658', '2.28690', '2.30512'] | Gamma1 Grad: ['-0.01921', '-0.01659', '0.00871', '-0.04182', '0.00728', '0.00099', '-0.01096', '0.00318', '-0.01110', '-0.00031', '-0.00601', '-0.00687', '-0.04899']
Epoch 33: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['2.30116', '2.30638', '2.31348', '2.28157', '2.29849', '2.29889', '2.29647', '2.30649', '2.30909', '2.29734', '2.30143', '2.29431', '2.30533'] | Gamma1 Grad: ['-0.02952', '0.00581', '-0.02508', '0.00063', '-0.01702', '0.00286', '-0.02662', '-0.00173', '-0.01450', '-0.00526', '-0.00049', '-0.01027', '0.01532']
Epoch 34: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.29684', '2.30900', '2.29522', '2.29152', '2.29214', '2.29255', '2.28540', '2.29955', '2.30722', '2.29928', '2.30120', '2.28447', '2.29603'] | Gamma1 Grad: ['0.00435', '-0.02679', '0.01786', '-0.02411', '0.02450', '-0.00993', '-0.01590', '0.00811', '-0.01688', '-0.00088', '0.00763', '0.00373', '0.03015']
Epoch 35: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00144 | Gamma1: ['2.30346', '2.30798', '2.30574', '2.29176', '2.31671', '2.31965', '2.31154', '2.31481', '2.28413', '2.29299', '2.29218', '2.28023', '2.30122'] | Gamma1 Grad: ['0.02114', '-0.03370', '0.06468', '0.00472', '0.04061', '0.04749', '0.02221', '-0.01823', '0.00328', '-0.00817', '0.00797', '-0.01596', '0.01042']
Epoch 36: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['2.29638', '2.29516', '2.31436', '2.30472', '2.29736', '2.31207', '2.28910', '2.31738', '2.30263', '2.30244', '2.30044', '2.29578', '2.29071'] | Gamma1 Grad: ['0.01429', '-0.00684', '0.03460', '-0.00764', '0.07634', '0.01890', '-0.00724', '0.00722', '-0.01386', '-0.00519', '-0.00602', '-0.03155', '0.03015']
Epoch 37: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00139 | Gamma1: ['2.29286', '2.29701', '2.29723', '2.28168', '2.27767', '2.32766', '2.29768', '2.29706', '2.30966', '2.28996', '2.29128', '2.29787', '2.31462'] | Gamma1 Grad: ['0.09329', '-0.00571', '-0.06483', '-0.01963', '0.04862', '0.02063', '-0.02712', '-0.00979', '-0.00873', '0.00123', '0.00064', '0.00862', '0.01211']
Epoch 38: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.30101', '2.29198', '2.29097', '2.30455', '2.30658', '2.31612', '2.30655', '2.30876', '2.29968', '2.29188', '2.28613', '2.28475', '2.30401'] | Gamma1 Grad: ['0.01968', '0.02063', '-0.03940', '0.08943', '0.00307', '-0.07245', '0.01661', '-0.01017', '-0.01626', '-0.00643', '-0.00875', '0.01506', '0.07420']
Epoch 39: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00133 | Gamma1: ['2.30842', '2.30202', '2.31289', '2.28890', '2.29348', '2.30453', '2.29817', '2.31163', '2.29049', '2.29596', '2.30102', '2.28868', '2.30029'] | Gamma1 Grad: ['-0.01481', '0.04445', '0.03337', '-0.00448', '0.08127', '0.01119', '0.00341', '0.01130', '-0.00389', '0.00800', '-0.00556', '-0.02109', '0.02605']
Epoch 40: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['2.32785', '2.36822', '2.31433', '2.28462', '2.31788', '2.33005', '2.35005', '2.35369', '2.32211', '2.28662', '2.30023', '2.27841', '2.32194'] | Gamma1 Grad: ['0.00032', '0.01784', '-0.06867', '-0.03452', '0.03407', '0.00536', '-0.00858', '-0.01249', '-0.00228', '0.00971', '0.00581', '-0.03398', '-0.03253']
Epoch 41: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00125 | Gamma1: ['2.34143', '2.33211', '2.33722', '2.28635', '2.32009', '2.33485', '2.33890', '2.35634', '2.32191', '2.29827', '2.29917', '2.28185', '2.31432'] | Gamma1 Grad: ['-0.01402', '0.02721', '0.03543', '0.04717', '-0.15081', '0.03516', '-0.00721', '-0.03300', '0.02834', '0.00754', '-0.00015', '0.01789', '-0.01119']
Epoch 42: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.32835', '2.33760', '2.33140', '2.28733', '2.29475', '2.34208', '2.36179', '2.35933', '2.33239', '2.30886', '2.29830', '2.28068', '2.33531'] | Gamma1 Grad: ['0.03216', '0.03165', '0.01330', '0.01951', '0.00737', '-0.01866', '-0.00582', '0.02822', '-0.00638', '-0.01089', '0.00210', '-0.05803', '0.00725']
Epoch 43: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00115 | Gamma1: ['2.32324', '2.35429', '2.32464', '2.27976', '2.31951', '2.33318', '2.36206', '2.35228', '2.33344', '2.30167', '2.31275', '2.27694', '2.33379'] | Gamma1 Grad: ['0.00835', '0.01879', '0.05146', '0.01075', '0.13559', '0.01229', '-0.01995', '0.02683', '-0.02680', '0.00476', '-0.00351', '0.00234', '0.01268']
Epoch 44: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['2.34228', '2.32350', '2.34506', '2.30113', '2.31506', '2.33301', '2.35903', '2.36016', '2.34560', '2.30351', '2.30616', '2.28567', '2.31515'] | Gamma1 Grad: ['0.07265', '-0.08264', '0.01510', '0.03667', '-0.09264', '-0.02275', '-0.03931', '0.04520', '0.01565', '0.01342', '0.00915', '-0.01865', '-0.06844']
Epoch 45: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00105 | Gamma1: ['2.33963', '2.32586', '2.33009', '2.33215', '2.27518', '2.36003', '2.36726', '2.36048', '2.32935', '2.31248', '2.31396', '2.28825', '2.32400'] | Gamma1 Grad: ['0.03402', '-0.06075', '0.03854', '-0.02643', '0.01486', '-0.02041', '0.01935', '-0.05366', '0.02361', '0.00272', '-0.01101', '0.00831', '0.03021']
Epoch 46: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.33753', '2.34579', '2.31915', '2.29751', '2.29250', '2.32082', '2.35770', '2.36222', '2.32687', '2.31010', '2.30820', '2.30021', '2.31168'] | Gamma1 Grad: ['-0.05758', '-0.01232', '0.03409', '0.02060', '-0.05752', '0.01996', '-0.02736', '0.01137', '-0.01410', '0.00081', '0.00924', '-0.00918', '0.01042']
Epoch 47: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00094 | Gamma1: ['2.32553', '2.33847', '2.29180', '2.28050', '2.29037', '2.32413', '2.36038', '2.35702', '2.33670', '2.30453', '2.30507', '2.27260', '2.30436'] | Gamma1 Grad: ['-0.06606', '0.01653', '0.03017', '-0.05834', '-0.03008', '0.00904', '-0.01204', '0.01683', '-0.00205', '0.00052', '0.00378', '0.02822', '-0.00414']
Epoch 48: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['2.32138', '2.33499', '2.30376', '2.26477', '2.26786', '2.33342', '2.36116', '2.37256', '2.33531', '2.30154', '2.29788', '2.28516', '2.31655'] | Gamma1 Grad: ['-0.05498', '-0.02548', '0.02084', '-0.00101', '0.06548', '0.03397', '-0.02062', '-0.01467', '0.02277', '0.00347', '0.01572', '-0.10981', '0.11022']
Epoch 49: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00083 | Gamma1: ['2.29691', '2.32208', '2.30020', '2.27401', '2.27825', '2.32554', '2.34648', '2.37954', '2.34359', '2.30782', '2.30356', '2.29514', '2.30897'] | Gamma1 Grad: ['-0.01040', '-0.06467', '-0.04596', '0.03871', '-0.05584', '0.01186', '0.00643', '0.02114', '0.02310', '0.00209', '0.01064', '0.00412', '0.00670']
Epoch 50: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31461', '2.32789', '2.31209', '2.28250', '2.28071', '2.31760', '2.34165', '2.35604', '2.32118', '2.30860', '2.30018', '2.30198', '2.30937'] | Gamma1 Grad: ['0.02545', '-0.02947', '-0.02771', '0.08208', '-0.04242', '0.05901', '-0.03606', '-0.03510', '0.00545', '-0.00028', '0.01006', '0.00831', '-0.05324']
Epoch 51: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00072 | Gamma1: ['2.32528', '2.32765', '2.29718', '2.29858', '2.27523', '2.32600', '2.35145', '2.35429', '2.30684', '2.30837', '2.29568', '2.28802', '2.30706'] | Gamma1 Grad: ['-0.02944', '-0.04619', '0.02991', '0.00544', '0.00561', '0.01652', '-0.00115', '-0.00724', '0.01772', '-0.01248', '-0.00109', '0.00242', '-0.04217']
Epoch 52: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['2.29547', '2.33227', '2.29612', '2.29858', '2.26872', '2.32218', '2.33890', '2.34768', '2.30743', '2.29401', '2.29925', '2.28243', '2.30012'] | Gamma1 Grad: ['-0.04654', '-0.02884', '-0.00551', '0.02103', '-0.00137', '-0.06803', '0.03314', '0.02942', '0.00326', '-0.00186', '-0.00830', '0.02237', '-0.00507']
Epoch 53: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00061 | Gamma1: ['2.31563', '2.31213', '2.29820', '2.27888', '2.28257', '2.29775', '2.32731', '2.34370', '2.32228', '2.29093', '2.29986', '2.28570', '2.29821'] | Gamma1 Grad: ['0.00967', '-0.00705', '0.07466', '0.03526', '-0.01816', '-0.05257', '-0.01000', '0.01475', '0.01047', '0.00218', '-0.00109', '0.00402', '-0.01872']
Epoch 54: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31478', '2.32263', '2.29383', '2.27864', '2.25816', '2.31492', '2.30510', '2.34633', '2.32910', '2.30425', '2.31279', '2.28426', '2.31472'] | Gamma1 Grad: ['-0.04439', '-0.02351', '-0.05651', '0.00736', '0.03957', '-0.00451', '-0.04526', '0.04126', '-0.01064', '-0.01835', '0.00452', '-0.02594', '-0.00257']
Epoch 55: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00050 | Gamma1: ['2.31296', '2.32707', '2.29677', '2.29740', '2.25149', '2.31012', '2.35351', '2.34709', '2.32554', '2.30515', '2.30252', '2.26535', '2.30420'] | Gamma1 Grad: ['-0.03696', '-0.03130', '-0.00597', '0.05385', '0.04312', '0.00790', '0.02873', '0.03851', '-0.00927', '-0.01010', '-0.00685', '0.01297', '-0.01909']
Epoch 56: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['2.31285', '2.30412', '2.31250', '2.28713', '2.26550', '2.31127', '2.35611', '2.35393', '2.32310', '2.30857', '2.31426', '2.27560', '2.28543'] | Gamma1 Grad: ['-0.09405', '-0.03274', '0.08151', '-0.07966', '0.00524', '0.01687', '0.02325', '-0.01894', '-0.01544', '-0.01194', '-0.00544', '0.01456', '0.10055']
Epoch 57: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00040 | Gamma1: ['2.32443', '2.33553', '2.30014', '2.28290', '2.26061', '2.28827', '2.35069', '2.35413', '2.32698', '2.30863', '2.29486', '2.27292', '2.29284'] | Gamma1 Grad: ['-0.01856', '0.01420', '0.00015', '-0.01968', '0.01031', '0.03365', '-0.00011', '0.00285', '-0.00982', '-0.00172', '0.00875', '0.00164', '0.03846']
Epoch 58: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.33162', '2.34255', '2.30107', '2.29059', '2.28237', '2.28305', '2.33416', '2.33324', '2.32520', '2.30347', '2.28717', '2.28510', '2.29839'] | Gamma1 Grad: ['-0.00292', '0.02273', '-0.06514', '0.00987', '0.01777', '0.00648', '-0.11245', '0.02641', '0.02141', '0.00046', '0.00664', '-0.00739', '0.02823']
Epoch 59: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00030 | Gamma1: ['2.32838', '2.35562', '2.29529', '2.29046', '2.25591', '2.27903', '2.33377', '2.34901', '2.33382', '2.29247', '2.29085', '2.28686', '2.29575'] | Gamma1 Grad: ['-0.02334', '-0.03091', '-0.09029', '0.07499', '0.03064', '-0.07770', '-0.07133', '0.05078', '-0.00297', '0.00577', '-0.00742', '-0.00505', '0.01391']
Epoch 60: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['2.32977', '2.36302', '2.29957', '2.27576', '2.28722', '2.29960', '2.35034', '2.36248', '2.35268', '2.29399', '2.28931', '2.27989', '2.27809'] | Gamma1 Grad: ['-0.06798', '-0.03339', '0.02229', '-0.04651', '-0.06672', '-0.03595', '-0.00269', '-0.01168', '-0.00301', '-0.00106', '-0.00091', '0.00321', '0.06017']
Epoch 61: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00022 | Gamma1: ['2.33338', '2.35686', '2.29556', '2.27392', '2.24966', '2.28770', '2.33705', '2.36734', '2.36706', '2.30324', '2.29438', '2.27749', '2.28001'] | Gamma1 Grad: ['-0.00088', '-0.00735', '0.02427', '0.00317', '-0.03482', '-0.02586', '-0.03008', '0.01460', '-0.00738', '0.01513', '0.00085', '-0.01773', '-0.02205']
Epoch 62: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.32363', '2.35478', '2.31044', '2.27556', '2.26337', '2.29105', '2.34086', '2.36833', '2.35390', '2.29264', '2.28723', '2.27884', '2.28138'] | Gamma1 Grad: ['-0.01681', '-0.02977', '-0.03146', '0.05971', '-0.09280', '0.03539', '-0.06153', '-0.05444', '0.01730', '-0.00910', '-0.00103', '0.00688', '-0.03345']
Epoch 63: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00016 | Gamma1: ['2.32619', '2.36293', '2.29083', '2.28556', '2.23874', '2.28911', '2.35190', '2.39095', '2.35101', '2.30064', '2.28575', '2.27779', '2.27525'] | Gamma1 Grad: ['-0.00712', '0.04316', '-0.04248', '-0.02763', '0.02632', '-0.02027', '-0.01346', '-0.04087', '0.00546', '-0.00339', '-0.00680', '0.02050', '0.00106']
Epoch 64: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['2.30500', '2.34044', '2.28898', '2.25254', '2.24541', '2.29479', '2.36859', '2.36134', '2.34000', '2.31249', '2.28933', '2.28113', '2.28382'] | Gamma1 Grad: ['0.00972', '-0.00838', '-0.06277', '0.07191', '-0.06269', '0.00050', '0.04332', '0.00615', '0.00319', '-0.00133', '0.00074', '-0.01065', '-0.01218']
Epoch 65: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00011 | Gamma1: ['2.33090', '2.35324', '2.30244', '2.26946', '2.26001', '2.27953', '2.36641', '2.38007', '2.33736', '2.30473', '2.29026', '2.27764', '2.28912'] | Gamma1 Grad: ['-0.05222', '-0.04169', '0.04358', '-0.03559', '0.18422', '-0.01040', '0.01587', '0.02117', '-0.01048', '0.00453', '-0.00994', '0.01000', '0.00006']
Epoch 66: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.34200', '2.34329', '2.29970', '2.25878', '2.24636', '2.28955', '2.37364', '2.37356', '2.33367', '2.31029', '2.28749', '2.28145', '2.28964'] | Gamma1 Grad: ['0.07740', '0.04556', '-0.02306', '-0.00198', '-0.02823', '-0.01777', '-0.00628', '0.00287', '-0.00082', '0.00998', '0.00417', '-0.00920', '0.01066']
Epoch 67: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00007 | Gamma1: ['2.32705', '2.33019', '2.31568', '2.25707', '2.25553', '2.28540', '2.34513', '2.36784', '2.34549', '2.30561', '2.29947', '2.27362', '2.27725'] | Gamma1 Grad: ['-0.00964', '0.01899', '0.02495', '0.04628', '0.03809', '0.00570', '0.01818', '-0.01477', '-0.01419', '-0.03288', '-0.00578', '0.07156', '0.03974']
Epoch 68: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['2.32709', '2.35894', '2.32287', '2.24284', '2.24981', '2.28553', '2.35296', '2.35879', '2.33154', '2.30777', '2.30261', '2.26805', '2.29578'] | Gamma1 Grad: ['0.01786', '0.01157', '0.01040', '-0.01725', '0.02633', '-0.00837', '0.02010', '-0.00997', '0.00723', '-0.00999', '-0.01520', '0.01874', '-0.00353']
Epoch 69: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00005 | Gamma1: ['2.33338', '2.35255', '2.31085', '2.26273', '2.23459', '2.26745', '2.35820', '2.34057', '2.34142', '2.31753', '2.30384', '2.27321', '2.29437'] | Gamma1 Grad: ['0.01480', '0.00783', '-0.00105', '-0.01918', '0.04099', '-0.01903', '0.01475', '0.01735', '-0.00680', '0.00185', '0.00614', '0.00590', '0.00108']
Epoch 70: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.32520', '2.34043', '2.31059', '2.25487', '2.25077', '2.29033', '2.36642', '2.35316', '2.35228', '2.31151', '2.30395', '2.28343', '2.29155'] | Gamma1 Grad: ['-0.03174', '0.05513', '0.07368', '-0.09294', '0.05093', '0.05266', '-0.05250', '0.04494', '-0.03416', '-0.00725', '0.00012', '-0.01906', '0.02179']
Epoch 71: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30038', '2.34673', '2.31822', '2.22509', '2.26279', '2.29643', '2.36332', '2.37763', '2.36082', '2.28051', '2.29412', '2.29241', '2.29935'] | Gamma1 Grad: ['-0.00179', '0.02014', '-0.02891', '-0.01788', '0.01228', '-0.00039', '0.00359', '0.00626', '-0.00003', '-0.00303', '-0.00724', '0.00191', '0.00610']
Epoch 72: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.31583', '2.34275', '2.30028', '2.24519', '2.24729', '2.29793', '2.37627', '2.35476', '2.31728', '2.30918', '2.29078', '2.26055', '2.29796'] | Gamma1 Grad: ['0.01579', '-0.03371', '-0.00638', '-0.01807', '0.01543', '-0.03250', '0.01788', '-0.02137', '-0.00561', '-0.00636', '0.00907', '0.00691', '0.07082']
Epoch 73: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.32879', '2.34249', '2.30264', '2.28714', '2.19476', '2.26755', '2.36014', '2.36931', '2.33766', '2.29467', '2.28160', '2.25403', '2.28584'] | Gamma1 Grad: ['0.01019', '0.05758', '-0.08747', '0.04074', '-0.13136', '0.01196', '0.05626', '-0.04442', '-0.01093', '0.01059', '0.01498', '-0.03781', '0.03332']
Epoch 74: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.33571', '2.33973', '2.27592', '2.28234', '2.23059', '2.24804', '2.35569', '2.37431', '2.33837', '2.28764', '2.28349', '2.25111', '2.28449'] | Gamma1 Grad: ['-0.00549', '0.01870', '0.00515', '-0.01438', '0.00435', '-0.00411', '0.00621', '0.02403', '-0.00841', '0.00429', '0.01115', '0.02039', '0.00305']
Epoch 75: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.33159', '2.34696', '2.31900', '2.30910', '2.21572', '2.26618', '2.35883', '2.34824', '2.34757', '2.29008', '2.29907', '2.28336', '2.28078'] | Gamma1 Grad: ['0.01342', '-0.01290', '-0.03780', '0.14875', '-0.14856', '0.08869', '-0.01371', '0.05324', '0.00838', '0.02340', '0.01484', '-0.02309', '-0.01613']
Epoch 76: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['2.32005', '2.34593', '2.26830', '2.27467', '2.21068', '2.26395', '2.37936', '2.37468', '2.34257', '2.31079', '2.31745', '2.27972', '2.28474'] | Gamma1 Grad: ['-0.01208', '0.00306', '0.02977', '0.01131', '0.11136', '-0.00502', '0.02156', '-0.01848', '0.00956', '0.00623', '-0.00558', '-0.03157', '0.03810']
Epoch 77: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00147 | Gamma1: ['2.31799', '2.33687', '2.26384', '2.24733', '2.23074', '2.24903', '2.32611', '2.35778', '2.33419', '2.29598', '2.32649', '2.28592', '2.26695'] | Gamma1 Grad: ['0.01389', '0.01429', '0.01851', '0.00474', '-0.04290', '-0.02214', '0.01024', '0.00757', '-0.00188', '-0.00000', '-0.00148', '0.00362', '-0.02136']
Epoch 78: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.32746', '2.32674', '2.26859', '2.20880', '2.21491', '2.25928', '2.32975', '2.37778', '2.34135', '2.28730', '2.28165', '2.27158', '2.27436'] | Gamma1 Grad: ['-0.00177', '-0.04151', '0.03572', '-0.10065', '0.04598', '0.02918', '-0.02210', '-0.04470', '-0.00054', '0.00743', '-0.00213', '0.02750', '0.02166']
Epoch 79: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00146 | Gamma1: ['2.31734', '2.34048', '2.28638', '2.24084', '2.24340', '2.25824', '2.33822', '2.35224', '2.32129', '2.30911', '2.28814', '2.30114', '2.26401'] | Gamma1 Grad: ['-0.00576', '0.02015', '-0.01787', '-0.03665', '0.12376', '-0.04281', '0.05933', '-0.02179', '-0.01159', '-0.00279', '-0.01174', '-0.01002', '-0.01007']
Epoch 80: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00144 | Gamma1: ['2.29770', '2.35972', '2.29096', '2.28272', '2.20835', '2.27749', '2.34224', '2.32246', '2.32608', '2.31931', '2.30229', '2.28545', '2.29725'] | Gamma1 Grad: ['-0.00720', '0.00845', '0.02535', '-0.02387', '-0.00221', '-0.01147', '0.01595', '0.04287', '-0.00309', '-0.00134', '0.00620', '0.00228', '0.01259']
Epoch 81: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00143 | Gamma1: ['2.31857', '2.33599', '2.29763', '2.26034', '2.21448', '2.28187', '2.31509', '2.31698', '2.32202', '2.31505', '2.30349', '2.28964', '2.30075'] | Gamma1 Grad: ['0.03726', '0.01397', '0.00951', '-0.00111', '0.13215', '0.04911', '0.00692', '0.05077', '0.00679', '0.01457', '0.02105', '0.00456', '-0.00844']
Epoch 82: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00142 | Gamma1: ['2.31702', '2.33087', '2.30353', '2.28110', '2.22656', '2.27739', '2.30904', '2.32510', '2.30181', '2.31820', '2.32434', '2.27456', '2.33456'] | Gamma1 Grad: ['-0.02129', '-0.00688', '0.05276', '0.00852', '0.05146', '0.05542', '-0.06120', '0.05149', '-0.00791', '-0.00724', '0.00288', '-0.01608', '-0.03944']
Epoch 83: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00141 | Gamma1: ['2.30847', '2.32361', '2.29545', '2.25723', '2.22519', '2.26497', '2.30683', '2.33027', '2.29945', '2.30474', '2.32395', '2.28073', '2.30478'] | Gamma1 Grad: ['0.02010', '0.00708', '0.06519', '0.03070', '-0.03491', '-0.01876', '-0.03146', '0.01413', '0.00381', '0.01060', '0.00434', '0.00850', '0.02810']
Epoch 84: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00139 | Gamma1: ['2.30368', '2.30738', '2.28053', '2.25535', '2.24440', '2.26485', '2.31653', '2.32349', '2.31722', '2.31834', '2.32639', '2.28449', '2.34184'] | Gamma1 Grad: ['-0.00425', '-0.04041', '-0.00348', '-0.00543', '-0.03103', '0.03845', '-0.00162', '-0.01855', '-0.00852', '-0.00812', '-0.00904', '0.00717', '0.00208']
Epoch 85: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00138 | Gamma1: ['2.30289', '2.30088', '2.27160', '2.25757', '2.23732', '2.25587', '2.29372', '2.30147', '2.31279', '2.30373', '2.31226', '2.31288', '2.33196'] | Gamma1 Grad: ['0.00577', '0.00102', '0.00949', '0.01161', '-0.00098', '0.01017', '-0.00850', '-0.00243', '0.00241', '-0.00220', '0.00261', '0.00306', '0.00500']
Epoch 86: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00136 | Gamma1: ['2.29281', '2.32725', '2.27269', '2.26162', '2.23766', '2.27752', '2.29088', '2.30912', '2.33040', '2.30666', '2.30695', '2.31230', '2.32090'] | Gamma1 Grad: ['0.00459', '-0.01081', '0.03419', '-0.00331', '0.01408', '0.00625', '0.05024', '-0.00443', '0.00493', '0.00243', '0.00020', '0.01891', '-0.00028']
Epoch 87: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00134 | Gamma1: ['2.28590', '2.34294', '2.28774', '2.27775', '2.23255', '2.24050', '2.29228', '2.30283', '2.31589', '2.30941', '2.31282', '2.30636', '2.31758'] | Gamma1 Grad: ['-0.07695', '-0.13703', '0.04202', '-0.04890', '0.10327', '-0.05885', '-0.07233', '0.05940', '0.00837', '-0.00506', '0.00292', '0.02481', '0.02955']
Epoch 88: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00133 | Gamma1: ['2.29100', '2.30964', '2.27982', '2.26329', '2.23399', '2.28104', '2.30989', '2.29369', '2.31075', '2.30066', '2.31629', '2.30462', '2.32205'] | Gamma1 Grad: ['0.02915', '-0.03200', '0.08891', '0.05708', '0.05303', '0.03112', '-0.05190', '-0.02546', '-0.00439', '-0.00392', '0.00179', '0.00040', '0.04160']
Epoch 89: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00131 | Gamma1: ['2.29494', '2.32273', '2.30471', '2.26221', '2.23685', '2.28613', '2.29620', '2.34189', '2.30069', '2.30786', '2.32786', '2.30387', '2.32917'] | Gamma1 Grad: ['-0.02424', '0.05975', '-0.01694', '-0.06712', '0.00722', '-0.05446', '-0.01568', '-0.02657', '-0.00285', '0.00856', '-0.00359', '0.00622', '-0.00962']
Epoch 90: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00129 | Gamma1: ['2.29001', '2.31124', '2.31417', '2.24670', '2.23417', '2.28746', '2.30437', '2.33658', '2.30639', '2.30744', '2.31934', '2.31639', '2.33557'] | Gamma1 Grad: ['-0.01932', '0.04573', '-0.06092', '0.01753', '-0.00749', '-0.01728', '0.00294', '-0.01640', '0.00064', '-0.00539', '-0.00288', '0.00596', '-0.00113']
Epoch 91: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00127 | Gamma1: ['2.28829', '2.30672', '2.29501', '2.26271', '2.25336', '2.27079', '2.29248', '2.31504', '2.31632', '2.31608', '2.30238', '2.31286', '2.33916'] | Gamma1 Grad: ['-0.00119', '0.00458', '0.01303', '-0.01157', '-0.00095', '-0.00535', '-0.00075', '0.00280', '0.00071', '-0.00208', '-0.00348', '-0.00379', '-0.00879']
Epoch 92: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00125 | Gamma1: ['2.28655', '2.30068', '2.27696', '2.25065', '2.25987', '2.27665', '2.29004', '2.33351', '2.30037', '2.29146', '2.30635', '2.31043', '2.32979'] | Gamma1 Grad: ['-0.02186', '0.01235', '-0.00104', '-0.01572', '-0.02732', '-0.00301', '-0.04555', '-0.00770', '-0.00603', '-0.00082', '0.01125', '0.03205', '-0.00031']
Epoch 93: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00122 | Gamma1: ['2.29016', '2.30787', '2.27949', '2.24037', '2.27041', '2.26940', '2.29466', '2.31536', '2.31020', '2.30406', '2.30233', '2.31251', '2.31790'] | Gamma1 Grad: ['-0.03090', '0.05578', '-0.05198', '0.04254', '0.07893', '0.03900', '-0.04415', '-0.02034', '-0.00979', '0.00745', '-0.01088', '-0.02972', '0.00966']
Epoch 94: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00120 | Gamma1: ['2.31161', '2.31016', '2.29296', '2.25417', '2.25954', '2.27970', '2.29793', '2.31260', '2.30396', '2.30307', '2.30011', '2.29863', '2.32420'] | Gamma1 Grad: ['-0.02240', '-0.01105', '-0.00340', '0.04166', '-0.01841', '0.00872', '0.00850', '-0.01203', '-0.00042', '-0.00203', '-0.00514', '0.01144', '-0.00934']
Epoch 95: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00118 | Gamma1: ['2.29273', '2.29875', '2.28732', '2.25771', '2.25998', '2.29208', '2.30324', '2.33376', '2.31304', '2.29683', '2.30204', '2.28906', '2.33385'] | Gamma1 Grad: ['-0.09003', '0.01883', '0.04028', '-0.05760', '-0.16130', '0.01313', '-0.04674', '0.01729', '-0.00151', '0.00540', '-0.00718', '0.01934', '-0.04785']
Epoch 96: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00115 | Gamma1: ['2.30912', '2.30633', '2.25320', '2.26011', '2.25519', '2.25782', '2.30472', '2.32519', '2.30907', '2.29656', '2.31860', '2.29444', '2.32733'] | Gamma1 Grad: ['-0.00052', '-0.00323', '0.00623', '-0.00902', '-0.00226', '-0.00200', '-0.00155', '0.00084', '-0.00105', '0.00036', '0.00047', '-0.00046', '-0.00660']
Epoch 97: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00113 | Gamma1: ['2.31724', '2.30759', '2.28135', '2.23477', '2.22368', '2.26529', '2.30234', '2.32334', '2.30746', '2.29969', '2.30579', '2.29523', '2.31705'] | Gamma1 Grad: ['0.00497', '0.00411', '0.00002', '0.00290', '-0.00122', '-0.00203', '-0.00174', '-0.00177', '-0.00138', '-0.00282', '-0.00130', '-0.00352', '-0.00015']
Epoch 98: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00110 | Gamma1: ['2.30778', '2.30148', '2.29498', '2.24262', '2.24316', '2.25494', '2.29370', '2.31775', '2.30600', '2.30221', '2.30551', '2.28980', '2.32788'] | Gamma1 Grad: ['0.00050', '0.00008', '0.00039', '-0.00037', '-0.00042', '-0.00194', '0.00066', '-0.00011', '0.00016', '0.00002', '0.00010', '-0.00031', '0.00029']
Epoch 99: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00108 | Gamma1: ['2.29823', '2.30086', '2.28992', '2.26504', '2.24489', '2.25708', '2.29362', '2.32109', '2.30482', '2.29977', '2.30650', '2.29355', '2.32101'] | Gamma1 Grad: ['0.01109', '0.00096', '0.00140', '0.00008', '0.01220', '-0.01551', '-0.00233', '0.00571', '0.00485', '-0.00150', '-0.00068', '-0.00349', '-0.00545']
