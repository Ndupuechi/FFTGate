Epoch 0: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000'] | Gamma1 Grad: ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']
Epoch 1: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['1.62149', '1.70355', '1.57857', '1.52780', '1.48826', '1.44972', '1.41787', '1.43428', '1.42900', '1.45857', '1.36140', '1.38568', '1.34046'] | Gamma1 Grad: ['0.02444', '-0.00401', '0.02007', '-0.00367', '-0.01653', '-0.01799', '-0.02253', '0.00090', '-0.02339', '-0.01909', '-0.00756', '-0.04755', '0.00403']
Epoch 2: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['1.79554', '1.95681', '1.77666', '1.58175', '1.52110', '1.38685', '1.33921', '1.41416', '1.38207', '1.41924', '1.23744', '1.42220', '1.16919'] | Gamma1 Grad: ['-0.02758', '-0.00124', '0.00605', '-0.01545', '-0.01844', '-0.01280', '-0.01697', '0.01768', '-0.02750', '-0.01356', '0.01835', '0.01467', '-0.05312']
Epoch 3: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['1.98998', '2.19797', '1.97166', '1.68982', '1.65595', '1.40768', '1.28233', '1.36814', '1.27393', '1.37339', '1.13249', '1.37989', '1.11099'] | Gamma1 Grad: ['0.01566', '0.01194', '-0.00829', '0.01546', '0.00996', '0.01476', '-0.01447', '0.00297', '-0.05540', '-0.04216', '-0.01724', '-0.17542', '-0.10998']
Epoch 4: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.17789', '2.40724', '2.14625', '1.80848', '1.80226', '1.53097', '1.26171', '1.39170', '1.19210', '1.34526', '1.02741', '1.33835', '1.14901'] | Gamma1 Grad: ['0.03058', '0.00198', '-0.00213', '-0.02517', '0.01158', '-0.01911', '0.01592', '-0.00796', '0.00381', '0.01257', '0.00933', '0.04534', '0.08607']
Epoch 5: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.34327', '2.59583', '2.31983', '1.92208', '1.95698', '1.69800', '1.25261', '1.41459', '1.15466', '1.33358', '0.89874', '1.30864', '1.19760'] | Gamma1 Grad: ['-0.00646', '0.01843', '0.01438', '-0.00480', '-0.00076', '-0.00936', '0.01222', '-0.00271', '-0.02449', '0.03784', '0.01240', '-0.07884', '-0.03202']
Epoch 6: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.51118', '2.73937', '2.44822', '2.03097', '2.08662', '1.83455', '1.31196', '1.47675', '1.15521', '1.35079', '0.79578', '1.28665', '1.24996'] | Gamma1 Grad: ['0.00132', '0.00088', '0.02162', '-0.00772', '-0.01046', '-0.00465', '-0.00631', '-0.01721', '-0.00557', '0.01068', '-0.02918', '-0.04410', '-0.01798']
Epoch 7: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.63288', '2.88112', '2.53680', '2.11542', '2.19710', '1.97022', '1.38450', '1.55277', '1.17680', '1.36931', '0.69881', '1.26194', '1.26744'] | Gamma1 Grad: ['-0.00348', '-0.00007', '0.00151', '0.00640', '0.00600', '0.01320', '0.00641', '0.02945', '0.00440', '0.01181', '0.00967', '-0.08904', '0.18284']
Epoch 8: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.71582', '3.01031', '2.62502', '2.17870', '2.30792', '2.09640', '1.43013', '1.65041', '1.20089', '1.38079', '0.62556', '1.24071', '1.29162'] | Gamma1 Grad: ['-0.01740', '-0.01904', '-0.00170', '0.02708', '0.00698', '-0.01434', '-0.00071', '0.00760', '0.05306', '0.00041', '-0.01943', '0.05678', '0.10057']
Epoch 9: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.81081', '3.10983', '2.69289', '2.22337', '2.36753', '2.19201', '1.47307', '1.74105', '1.25222', '1.41744', '0.57923', '1.21813', '1.32275'] | Gamma1 Grad: ['-0.00742', '-0.00904', '-0.00293', '-0.01577', '0.00607', '-0.00330', '0.00201', '0.00497', '-0.01490', '-0.03412', '-0.00932', '0.04972', '-0.01506']
Epoch 10: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.87993', '3.19554', '2.72793', '2.27331', '2.43190', '2.29007', '1.52145', '1.83977', '1.30461', '1.44345', '0.53229', '1.20637', '1.35982'] | Gamma1 Grad: ['-0.01120', '0.00121', '-0.00163', '-0.01004', '-0.00059', '0.01492', '0.01453', '0.01230', '-0.00273', '0.00275', '0.07143', '-0.02526', '-0.01813']
Epoch 11: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.94173', '3.29599', '2.79941', '2.33181', '2.49057', '2.36227', '1.61774', '1.97176', '1.37712', '1.45526', '0.46870', '1.17398', '1.41610'] | Gamma1 Grad: ['-0.00037', '0.00730', '0.00143', '0.00708', '-0.01718', '-0.02096', '-0.01886', '-0.00219', '0.01797', '0.00296', '0.05022', '-0.04067', '0.07288']
Epoch 12: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.98441', '3.37370', '2.83991', '2.36332', '2.53295', '2.43667', '1.66822', '2.08759', '1.46445', '1.48508', '0.42586', '1.16270', '1.48212'] | Gamma1 Grad: ['-0.00186', '0.00037', '0.00157', '0.01454', '0.00267', '-0.00226', '-0.01558', '0.00554', '-0.02023', '-0.01586', '-0.12027', '-0.00099', '0.06947']
Epoch 13: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['3.01684', '3.45958', '2.87923', '2.40646', '2.54742', '2.50267', '1.71780', '2.19468', '1.53983', '1.50625', '0.38384', '1.18592', '1.51702'] | Gamma1 Grad: ['0.01383', '0.00501', '-0.00845', '0.03141', '-0.01029', '-0.00894', '0.01002', '0.00286', '0.00289', '0.00713', '-0.02909', '0.02214', '0.00258']
Epoch 14: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['3.05984', '3.52052', '2.90401', '2.42693', '2.54027', '2.53394', '1.79440', '2.27656', '1.62018', '1.54787', '0.35863', '1.18288', '1.56097'] | Gamma1 Grad: ['0.00666', '-0.00389', '-0.00308', '-0.01727', '0.00519', '-0.00262', '-0.03260', '-0.00002', '-0.00186', '0.01085', '0.18642', '0.06651', '-0.00936']
Epoch 15: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['3.10797', '3.58664', '2.91219', '2.45189', '2.54910', '2.59964', '1.85563', '2.35986', '1.69490', '1.56052', '0.35532', '1.20508', '1.59035'] | Gamma1 Grad: ['-0.01891', '-0.01670', '-0.00476', '0.00758', '0.02060', '0.00584', '-0.02167', '0.01618', '-0.00477', '0.03195', '-0.03086', '0.00016', '0.06984']
Epoch 16: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['3.12622', '3.63200', '2.91253', '2.48339', '2.54134', '2.61995', '1.92237', '2.44876', '1.74505', '1.58521', '0.35891', '1.23598', '1.63257'] | Gamma1 Grad: ['0.02143', '-0.00187', '0.00160', '0.00590', '0.00603', '-0.00107', '0.02806', '-0.01707', '-0.01679', '-0.01159', '0.02687', '0.04127', '0.00272']
Epoch 17: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['3.14529', '3.67957', '2.90574', '2.48439', '2.55329', '2.62229', '2.00111', '2.51832', '1.79513', '1.60078', '0.35852', '1.21486', '1.68484'] | Gamma1 Grad: ['-0.00617', '0.00014', '-0.01229', '-0.00768', '0.00801', '0.00001', '-0.00289', '-0.00031', '-0.01128', '-0.01051', '-0.02158', '0.01175', '0.02582']
Epoch 18: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['3.16808', '3.76162', '2.90697', '2.52443', '2.58101', '2.68821', '2.06792', '2.58137', '1.88129', '1.64484', '0.35651', '1.22391', '1.72121'] | Gamma1 Grad: ['0.00942', '-0.00238', '-0.00074', '-0.03442', '-0.01568', '-0.02477', '0.01414', '0.00097', '-0.02059', '-0.00121', '-0.14750', '-0.01290', '0.05051']
Epoch 19: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['3.21191', '3.83626', '2.90408', '2.52689', '2.56174', '2.69046', '2.13569', '2.63530', '1.94031', '1.65760', '0.34417', '1.25123', '1.76555'] | Gamma1 Grad: ['-0.00458', '0.00606', '0.00375', '-0.01629', '0.00465', '-0.00139', '0.00954', '0.00086', '0.01176', '0.01039', '-0.11188', '-0.06681', '-0.02635']
Epoch 20: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['3.23686', '3.86610', '2.89735', '2.52831', '2.56946', '2.67710', '2.20830', '2.69031', '1.99576', '1.66842', '0.35650', '1.25216', '1.80690'] | Gamma1 Grad: ['-0.01396', '-0.00151', '-0.00813', '-0.00929', '-0.03625', '-0.01682', '-0.00774', '-0.00070', '-0.00106', '0.01728', '0.07743', '-0.08701', '-0.05905']
Epoch 21: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['3.24345', '3.89710', '2.88272', '2.53557', '2.54854', '2.69168', '2.24067', '2.72335', '2.06070', '1.72615', '0.38773', '1.25645', '1.83860'] | Gamma1 Grad: ['0.00760', '0.00885', '0.01693', '-0.00778', '-0.00664', '-0.00885', '-0.00800', '0.01061', '0.00409', '-0.01305', '-0.01505', '0.05259', '-0.02774']
Epoch 22: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['3.28556', '3.91931', '2.89387', '2.54609', '2.54772', '2.68712', '2.28966', '2.76416', '2.13388', '1.73541', '0.38108', '1.25172', '1.88369'] | Gamma1 Grad: ['0.00139', '0.00014', '0.00353', '0.01732', '-0.03087', '0.02328', '0.00722', '-0.00384', '-0.00705', '-0.01559', '-0.06061', '-0.03257', '0.05456']
Epoch 23: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['3.29438', '3.93033', '2.88228', '2.54166', '2.54652', '2.70253', '2.33307', '2.80691', '2.18108', '1.75748', '0.38380', '1.28165', '1.90723'] | Gamma1 Grad: ['-0.01679', '0.00423', '-0.05893', '0.06021', '-0.03858', '-0.03324', '0.00580', '-0.00449', '0.00670', '-0.00291', '-0.07097', '0.07024', '0.01619']
Epoch 24: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['3.31286', '3.94658', '2.88265', '2.54907', '2.53790', '2.70044', '2.36224', '2.83811', '2.24078', '1.78326', '0.39655', '1.29028', '1.93818'] | Gamma1 Grad: ['0.00937', '0.02735', '0.01278', '0.03766', '-0.00488', '0.02977', '0.00417', '-0.01178', '-0.00000', '0.00341', '-0.30653', '-0.21030', '-0.00123']
Epoch 25: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['3.34495', '3.94595', '2.87016', '2.54628', '2.54520', '2.69368', '2.42088', '2.86688', '2.31413', '1.80959', '0.39601', '1.30543', '1.95510'] | Gamma1 Grad: ['-0.00493', '-0.00438', '-0.01431', '0.02128', '-0.00565', '0.00776', '0.02571', '-0.00373', '0.00776', '0.00701', '0.08451', '0.00226', '-0.00472']
Epoch 26: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['3.33498', '3.95862', '2.87285', '2.53416', '2.54256', '2.70289', '2.45758', '2.88779', '2.36209', '1.81949', '0.41854', '1.29821', '1.96378'] | Gamma1 Grad: ['0.00263', '-0.00015', '0.01169', '-0.04433', '-0.01282', '-0.01439', '-0.01225', '-0.00559', '-0.00138', '-0.01950', '-0.03487', '0.00284', '0.00590']
Epoch 27: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['3.32699', '3.97549', '2.85815', '2.54207', '2.53882', '2.71608', '2.49047', '2.92665', '2.40656', '1.85973', '0.42064', '1.31247', '1.98419'] | Gamma1 Grad: ['0.01639', '-0.00944', '-0.00013', '0.01801', '-0.06104', '0.02047', '-0.00796', '0.00808', '0.00229', '0.00001', '0.07534', '-0.00914', '0.03084']
Epoch 28: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['3.33042', '3.97600', '2.85625', '2.53262', '2.51396', '2.71980', '2.50951', '2.94481', '2.45791', '1.87460', '0.42621', '1.31613', '2.01850'] | Gamma1 Grad: ['0.00559', '-0.00784', '0.03328', '-0.02747', '0.02340', '-0.00097', '0.00555', '-0.00105', '0.00502', '0.00068', '-0.05158', '0.03291', '-0.01717']
Epoch 29: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['3.31986', '3.97372', '2.84878', '2.54227', '2.48791', '2.69934', '2.55226', '2.96264', '2.50202', '1.90148', '0.44226', '1.30960', '2.03593'] | Gamma1 Grad: ['0.00935', '0.00946', '0.02367', '0.01375', '-0.01523', '-0.02270', '0.00953', '-0.00496', '-0.01554', '0.00610', '0.01821', '-0.11132', '0.05116']
Epoch 30: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['3.33174', '3.97986', '2.85578', '2.55807', '2.50599', '2.70014', '2.57989', '2.99134', '2.54607', '1.92635', '0.43993', '1.32367', '2.05137'] | Gamma1 Grad: ['0.00094', '0.00183', '0.00239', '0.00496', '0.00025', '0.01338', '0.00321', '0.00991', '-0.00184', '0.00054', '-0.10244', '-0.03437', '-0.01166']
Epoch 31: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['3.35502', '3.97695', '2.85620', '2.55965', '2.50849', '2.65284', '2.62175', '3.01838', '2.57715', '1.92672', '0.45652', '1.32746', '2.06242'] | Gamma1 Grad: ['0.00500', '0.00870', '0.01401', '0.00800', '0.05248', '-0.03327', '0.00844', '0.00531', '0.00675', '0.01393', '0.19961', '-0.04270', '-0.04440']
Epoch 32: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['3.35302', '3.99286', '2.81676', '2.53160', '2.50334', '2.60705', '2.65453', '3.01990', '2.61863', '1.95151', '0.46554', '1.33243', '2.07961'] | Gamma1 Grad: ['-0.00886', '-0.00075', '-0.03202', '0.02663', '-0.02993', '0.01010', '0.02270', '0.00351', '-0.00325', '-0.01913', '-0.10710', '-0.04733', '0.00912']
Epoch 33: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['3.39663', '4.00079', '2.84658', '2.52980', '2.47207', '2.63412', '2.68005', '3.02960', '2.64583', '1.98989', '0.49233', '1.34832', '2.09574'] | Gamma1 Grad: ['0.00507', '0.00884', '0.01479', '0.10740', '0.04043', '-0.02482', '0.01905', '-0.00975', '-0.00885', '0.00589', '0.04170', '-0.10663', '0.05920']
Epoch 34: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['3.41185', '4.01131', '2.85172', '2.52363', '2.49170', '2.62336', '2.70271', '3.05607', '2.68558', '2.01465', '0.46439', '1.35989', '2.09168'] | Gamma1 Grad: ['0.00619', '-0.02786', '-0.02766', '-0.07286', '0.02590', '0.04557', '-0.04255', '-0.04394', '-0.02079', '0.00790', '-0.04464', '-0.11099', '0.01139']
Epoch 35: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00144 | Gamma1: ['3.37518', '4.01065', '2.83749', '2.52645', '2.46342', '2.63958', '2.72019', '3.09433', '2.72427', '2.03766', '0.47404', '1.32835', '2.09531'] | Gamma1 Grad: ['0.01270', '0.00017', '-0.00732', '0.01555', '-0.03413', '0.02967', '0.02821', '-0.00312', '0.00247', '-0.01526', '-0.00361', '-0.02011', '0.04314']
Epoch 36: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['3.37826', '3.99024', '2.82350', '2.53584', '2.47213', '2.65286', '2.77480', '3.10909', '2.74843', '2.05810', '0.47801', '1.34169', '2.08493'] | Gamma1 Grad: ['0.01887', '0.00172', '0.02076', '0.01198', '0.08698', '-0.00008', '0.02682', '0.01997', '-0.00742', '0.01647', '-0.07478', '-0.00341', '0.09770']
Epoch 37: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00139 | Gamma1: ['3.38153', '3.98663', '2.78280', '2.49392', '2.43660', '2.65603', '2.77675', '3.12230', '2.79120', '2.04960', '0.49964', '1.30594', '2.09604'] | Gamma1 Grad: ['0.00756', '-0.01143', '0.02196', '0.04325', '-0.02195', '0.04353', '0.01908', '-0.00845', '-0.00577', '-0.00645', '0.02933', '-0.06873', '0.04795']
Epoch 38: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['3.39083', '3.97931', '2.76326', '2.47407', '2.42705', '2.66033', '2.78100', '3.13784', '2.84566', '2.05616', '0.51632', '1.33335', '2.13033'] | Gamma1 Grad: ['-0.00132', '-0.00275', '-0.00670', '0.02202', '0.07036', '-0.08933', '0.00182', '0.01000', '-0.00387', '-0.00114', '0.22430', '0.03868', '0.09167']
Epoch 39: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00133 | Gamma1: ['3.38307', '3.98728', '2.76600', '2.49266', '2.45397', '2.62998', '2.81264', '3.13918', '2.85326', '2.07192', '0.49048', '1.33921', '2.13434'] | Gamma1 Grad: ['-0.00271', '0.01483', '0.02331', '-0.03545', '-0.02545', '0.05053', '0.00262', '-0.00202', '-0.00186', '-0.01224', '0.02164', '-0.02991', '-0.02904']
Epoch 40: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['3.38645', '3.97962', '2.78247', '2.50473', '2.42266', '2.61386', '2.80603', '3.12641', '2.89035', '2.08719', '0.50097', '1.35073', '2.14928'] | Gamma1 Grad: ['-0.02638', '-0.02963', '-0.02580', '-0.06909', '0.07817', '-0.07445', '0.01805', '0.02317', '0.00119', '0.02065', '0.10635', '0.04116', '-0.06551']
Epoch 41: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00125 | Gamma1: ['3.37204', '4.00914', '2.76740', '2.47488', '2.37856', '2.58032', '2.81909', '3.14872', '2.92191', '2.10408', '0.50785', '1.32497', '2.14371'] | Gamma1 Grad: ['0.00513', '0.02534', '0.00763', '0.02280', '-0.03655', '-0.05441', '0.02543', '-0.00128', '0.00527', '0.03626', '0.13121', '-0.03585', '-0.03820']
Epoch 42: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['3.37546', '4.01573', '2.76148', '2.47039', '2.37221', '2.62876', '2.81982', '3.15826', '2.95672', '2.13609', '0.53738', '1.33857', '2.16906'] | Gamma1 Grad: ['0.01140', '-0.00206', '0.01889', '-0.00592', '0.00889', '-0.05855', '-0.00434', '0.01626', '-0.00173', '0.00697', '0.09443', '-0.08763', '-0.04585']
Epoch 43: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00115 | Gamma1: ['3.34494', '4.00799', '2.77597', '2.45724', '2.37144', '2.59783', '2.82344', '3.15538', '2.96738', '2.14304', '0.52247', '1.32967', '2.14154'] | Gamma1 Grad: ['0.01055', '-0.00515', '0.01759', '0.00392', '0.00814', '0.01051', '-0.00133', '-0.01259', '-0.00129', '-0.01001', '-0.09567', '-0.00866', '-0.02337']
Epoch 44: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['3.35436', '4.01042', '2.79597', '2.44314', '2.39595', '2.56847', '2.82903', '3.17736', '3.00355', '2.17625', '0.55205', '1.31766', '2.15779'] | Gamma1 Grad: ['-0.00071', '-0.02251', '-0.00833', '0.04351', '-0.02165', '-0.00304', '-0.01877', '0.00153', '0.00639', '0.00138', '0.12311', '-0.00464', '0.00174']
Epoch 45: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00105 | Gamma1: ['3.34645', '4.00041', '2.78989', '2.41927', '2.38980', '2.55471', '2.83360', '3.16867', '3.01912', '2.18189', '0.55931', '1.33892', '2.14481'] | Gamma1 Grad: ['0.03439', '-0.01466', '0.03753', '0.04806', '0.10101', '-0.00974', '0.02625', '-0.03513', '0.00387', '-0.00859', '0.02182', '-0.04359', '0.04319']
Epoch 46: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['3.39001', '4.00061', '2.79649', '2.42247', '2.35701', '2.54258', '2.84475', '3.17664', '3.05060', '2.20529', '0.53112', '1.34061', '2.14462'] | Gamma1 Grad: ['-0.00215', '0.00070', '0.00804', '0.01584', '-0.00701', '-0.01116', '-0.00234', '-0.00235', '-0.00420', '0.00094', '-0.05333', '-0.03124', '0.01135']
Epoch 47: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00094 | Gamma1: ['3.41713', '3.98984', '2.76416', '2.41705', '2.35704', '2.56947', '2.85688', '3.17139', '3.06108', '2.21432', '0.54344', '1.36538', '2.15308'] | Gamma1 Grad: ['-0.00253', '-0.00685', '0.00783', '0.00595', '-0.06914', '-0.04464', '-0.00304', '0.02020', '-0.00590', '-0.01499', '-0.08909', '0.01957', '0.04130']
Epoch 48: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['3.41497', '4.01256', '2.73787', '2.40420', '2.30980', '2.57059', '2.86414', '3.15433', '3.08597', '2.20408', '0.53221', '1.34357', '2.12708'] | Gamma1 Grad: ['0.03945', '-0.02293', '-0.03530', '0.09562', '0.02232', '-0.07954', '-0.03464', '-0.05371', '0.01008', '-0.03180', '0.00645', '-0.06419', '0.12036']
Epoch 49: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00083 | Gamma1: ['3.42084', '4.01910', '2.73321', '2.38678', '2.31055', '2.56297', '2.85452', '3.13868', '3.11375', '2.21730', '0.57399', '1.36653', '2.13993'] | Gamma1 Grad: ['-0.01008', '-0.01084', '-0.04788', '-0.04945', '-0.10279', '-0.07200', '-0.01248', '-0.01433', '-0.00070', '0.00409', '0.06814', '-0.00221', '0.04369']
Epoch 50: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['3.39921', '4.04446', '2.74464', '2.40976', '2.31762', '2.52983', '2.85290', '3.12945', '3.12727', '2.24028', '0.55511', '1.35592', '2.14058'] | Gamma1 Grad: ['0.01050', '0.01116', '0.00252', '0.02786', '-0.07737', '0.09045', '-0.01707', '0.01863', '-0.00895', '-0.00173', '0.03029', '0.08586', '0.01829']
Epoch 51: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00072 | Gamma1: ['3.38293', '4.02959', '2.72781', '2.38651', '2.33429', '2.54608', '2.84688', '3.13664', '3.14556', '2.22871', '0.54624', '1.34583', '2.13327'] | Gamma1 Grad: ['0.01580', '-0.00162', '-0.03065', '-0.02223', '-0.02520', '0.03162', '-0.01484', '-0.01701', '-0.00115', '-0.00617', '-0.01575', '-0.03515', '-0.01431']
Epoch 52: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['3.39391', '4.02229', '2.71090', '2.37852', '2.30544', '2.54837', '2.84396', '3.13081', '3.16926', '2.24773', '0.57456', '1.31586', '2.12381'] | Gamma1 Grad: ['-0.00512', '-0.00479', '-0.03147', '0.05441', '-0.03718', '0.02003', '0.02855', '-0.00323', '-0.00184', '-0.00392', '-0.09950', '-0.00515', '-0.02663']
Epoch 53: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00061 | Gamma1: ['3.40320', '4.02943', '2.68093', '2.38873', '2.26649', '2.52908', '2.82625', '3.13046', '3.18114', '2.25670', '0.58396', '1.33140', '2.11930'] | Gamma1 Grad: ['0.00128', '-0.00569', '-0.05931', '0.05553', '0.01246', '-0.00478', '-0.02631', '0.01871', '0.00252', '0.01187', '0.21217', '0.08115', '0.04649']
Epoch 54: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['3.40419', '4.03626', '2.66452', '2.35605', '2.26348', '2.48308', '2.81429', '3.11427', '3.18356', '2.27045', '0.59772', '1.32576', '2.08905'] | Gamma1 Grad: ['0.02487', '-0.01751', '-0.03117', '0.05331', '0.06495', '0.09222', '-0.00032', '0.00031', '-0.01484', '0.00098', '0.10074', '-0.07172', '-0.06802']
Epoch 55: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00050 | Gamma1: ['3.41482', '4.03783', '2.66247', '2.35458', '2.28011', '2.47039', '2.81754', '3.11700', '3.19238', '2.29678', '0.60448', '1.32739', '2.08196'] | Gamma1 Grad: ['0.01058', '-0.00084', '-0.00614', '0.02394', '-0.02406', '0.00061', '-0.00215', '0.02791', '-0.00506', '0.00656', '-0.01899', '0.07098', '0.01739']
Epoch 56: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['3.40016', '4.03878', '2.63259', '2.32572', '2.27445', '2.47127', '2.81290', '3.09241', '3.21623', '2.31149', '0.61456', '1.31634', '2.05774'] | Gamma1 Grad: ['-0.01718', '0.01545', '0.03180', '-0.02227', '-0.03645', '-0.01570', '0.00832', '0.00706', '0.00241', '0.01314', '-0.00732', '0.01818', '-0.04966']
Epoch 57: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00040 | Gamma1: ['3.40324', '4.04237', '2.65129', '2.30630', '2.26814', '2.48332', '2.80535', '3.09490', '3.22298', '2.33165', '0.60494', '1.29376', '2.04968'] | Gamma1 Grad: ['0.00362', '0.00987', '0.00377', '0.03230', '0.00906', '0.00183', '0.00252', '0.00852', '-0.00235', '-0.00185', '0.01087', '0.02811', '-0.00444']
Epoch 58: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['3.39468', '4.05422', '2.65297', '2.31168', '2.26565', '2.45791', '2.81389', '3.09208', '3.23905', '2.34537', '0.61241', '1.27128', '2.03583'] | Gamma1 Grad: ['-0.00435', '0.01679', '0.00065', '0.00493', '-0.03482', '0.00311', '0.01247', '-0.00809', '-0.00124', '0.01143', '-0.08065', '0.07711', '-0.00439']
Epoch 59: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00030 | Gamma1: ['3.39289', '4.05604', '2.64988', '2.30977', '2.26134', '2.47203', '2.78643', '3.09101', '3.24896', '2.37353', '0.60294', '1.29202', '2.03736'] | Gamma1 Grad: ['0.00208', '-0.00000', '-0.00082', '0.00230', '0.01764', '-0.05321', '0.02129', '-0.00614', '0.00831', '0.00143', '0.00560', '0.01689', '0.02726']
Epoch 60: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['3.38551', '4.05299', '2.64471', '2.30742', '2.23655', '2.50035', '2.77266', '3.09871', '3.26109', '2.36817', '0.61643', '1.29995', '2.03653'] | Gamma1 Grad: ['0.00235', '-0.00459', '-0.00034', '0.00989', '-0.00901', '-0.00416', '-0.00049', '-0.00612', '0.00098', '0.00124', '0.03415', '-0.03476', '0.00068']
Epoch 61: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00022 | Gamma1: ['3.40107', '4.04883', '2.63498', '2.28696', '2.24994', '2.47199', '2.77772', '3.09034', '3.27105', '2.36796', '0.59993', '1.28143', '2.02084'] | Gamma1 Grad: ['-0.00432', '0.01443', '-0.06305', '-0.03180', '0.05391', '-0.02454', '0.05954', '-0.00274', '-0.00468', '0.00462', '0.07127', '-0.03836', '-0.03707']
Epoch 62: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['3.38062', '4.05471', '2.63737', '2.27039', '2.23329', '2.44637', '2.76778', '3.10168', '3.27158', '2.38834', '0.60145', '1.27474', '2.01588'] | Gamma1 Grad: ['0.00080', '-0.00225', '0.06258', '-0.03104', '0.03277', '-0.03306', '0.02381', '-0.08860', '-0.00368', '-0.00715', '-0.01947', '-0.03253', '-0.02978']
Epoch 63: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00016 | Gamma1: ['3.36369', '4.02680', '2.64240', '2.27634', '2.23415', '2.42140', '2.75349', '3.10088', '3.27579', '2.40313', '0.61175', '1.30702', '2.00171'] | Gamma1 Grad: ['0.00513', '0.00305', '0.01089', '-0.03634', '-0.00290', '0.04624', '-0.03637', '-0.01070', '-0.00481', '-0.00057', '0.03811', '0.04155', '-0.07289']
Epoch 64: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['3.35870', '4.02426', '2.62514', '2.27316', '2.23664', '2.44151', '2.73454', '3.10333', '3.28717', '2.42120', '0.61495', '1.30273', '1.99685'] | Gamma1 Grad: ['-0.00909', '-0.00778', '0.02408', '-0.08339', '0.01815', '0.05412', '-0.10372', '0.00082', '0.00242', '0.01315', '0.14014', '0.07394', '-0.00207']
Epoch 65: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00011 | Gamma1: ['3.36500', '4.02536', '2.62229', '2.25575', '2.21495', '2.43100', '2.73795', '3.07654', '3.29412', '2.43903', '0.62171', '1.28891', '1.98680'] | Gamma1 Grad: ['0.00667', '-0.01352', '-0.03149', '0.06172', '-0.08088', '0.00308', '-0.00440', '0.00855', '0.00014', '-0.00744', '-0.05936', '-0.06358', '0.01009']
Epoch 66: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['3.39906', '4.02509', '2.62883', '2.28707', '2.24814', '2.42524', '2.73145', '3.05814', '3.30475', '2.44638', '0.63267', '1.29181', '1.99386'] | Gamma1 Grad: ['0.00072', '-0.00490', '-0.00199', '-0.01991', '0.00634', '0.01333', '-0.02451', '-0.01881', '-0.00057', '-0.00513', '-0.00465', '-0.01260', '-0.00326']
Epoch 67: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00007 | Gamma1: ['3.40063', '4.00984', '2.60084', '2.27333', '2.21610', '2.40642', '2.73644', '3.04957', '3.32422', '2.45451', '0.62851', '1.29101', '1.99237'] | Gamma1 Grad: ['-0.01831', '0.00794', '-0.01664', '-0.01083', '0.00562', '0.00944', '-0.01776', '-0.01822', '0.00188', '-0.00935', '0.00048', '0.06215', '-0.01079']
Epoch 68: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['3.38823', '4.02082', '2.58111', '2.26826', '2.21685', '2.40554', '2.76208', '3.04389', '3.32499', '2.47382', '0.64240', '1.28979', '1.96661'] | Gamma1 Grad: ['-0.00479', '0.00281', '-0.00158', '0.00152', '0.00310', '0.01825', '0.00270', '-0.00497', '0.00001', '0.00080', '-0.01123', '0.01251', '0.00594']
Epoch 69: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00005 | Gamma1: ['3.39172', '4.02174', '2.59843', '2.28186', '2.21652', '2.40807', '2.75605', '3.02068', '3.32940', '2.48334', '0.64057', '1.29593', '1.95913'] | Gamma1 Grad: ['0.00828', '-0.00151', '0.02519', '-0.01904', '0.02658', '0.04311', '-0.02296', '0.02977', '-0.00387', '0.02251', '0.06103', '0.05809', '-0.02324']
Epoch 70: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['3.37321', '4.02603', '2.58456', '2.27493', '2.21331', '2.42403', '2.73791', '3.02444', '3.33850', '2.49198', '0.65213', '1.29675', '1.95277'] | Gamma1 Grad: ['-0.00417', '-0.02229', '-0.03367', '-0.05036', '0.08923', '0.03690', '-0.02196', '-0.03364', '-0.00055', '0.00159', '-0.06519', '-0.03635', '-0.05643']
Epoch 71: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['3.39223', '3.99927', '2.56177', '2.26515', '2.23720', '2.38641', '2.74017', '2.99965', '3.35725', '2.50487', '0.63610', '1.27223', '1.95255'] | Gamma1 Grad: ['-0.00120', '-0.00822', '0.00865', '0.02016', '0.04340', '-0.05291', '0.00677', '0.00580', '0.00253', '0.01041', '0.16892', '-0.04174', '0.01239']
Epoch 72: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['3.39388', '4.01239', '2.58683', '2.22400', '2.21411', '2.40926', '2.70797', '2.98800', '3.37397', '2.50518', '0.61938', '1.25336', '1.92738'] | Gamma1 Grad: ['-0.00414', '0.00474', '0.03637', '-0.07826', '0.04618', '0.01509', '-0.01793', '0.00375', '0.00124', '0.00239', '0.14909', '0.00154', '0.08259']
Epoch 73: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['3.38730', '4.02413', '2.52321', '2.22525', '2.20926', '2.37463', '2.72462', '2.97602', '3.39309', '2.49826', '0.62799', '1.24355', '1.92916'] | Gamma1 Grad: ['-0.00498', '0.02117', '0.02726', '0.05660', '-0.01666', '0.03341', '-0.01135', '-0.00608', '-0.00305', '0.00014', '-0.04188', '-0.08093', '0.03509']
Epoch 74: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['3.39487', '4.00212', '2.54214', '2.22805', '2.19296', '2.38922', '2.69456', '2.95693', '3.40318', '2.51178', '0.63262', '1.25246', '1.92346'] | Gamma1 Grad: ['0.00975', '0.00296', '0.00125', '-0.01484', '0.04507', '-0.02873', '0.00202', '-0.00960', '0.00119', '0.00354', '-0.05673', '0.00206', '-0.02743']
Epoch 75: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['3.39310', '4.00175', '2.58615', '2.24155', '2.19987', '2.38506', '2.70221', '2.94356', '3.42419', '2.51207', '0.63847', '1.25234', '1.90649'] | Gamma1 Grad: ['-0.01173', '0.02439', '-0.05564', '-0.04707', '-0.14774', '-0.02054', '-0.05518', '0.01325', '-0.00369', '0.02281', '0.32080', '-0.01572', '-0.07484']
Epoch 76: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['3.37959', '3.97575', '2.58728', '2.20313', '2.20028', '2.40534', '2.68850', '2.93571', '3.42239', '2.52180', '0.65636', '1.22429', '1.91389'] | Gamma1 Grad: ['-0.00215', '0.00281', '-0.05069', '-0.03383', '0.01486', '0.04453', '-0.10233', '0.00288', '-0.00014', '0.00941', '0.17048', '-0.00231', '0.00787']
Epoch 77: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00147 | Gamma1: ['3.39428', '3.96752', '2.57433', '2.24262', '2.19126', '2.36026', '2.66935', '2.96324', '3.41268', '2.53624', '0.63003', '1.21861', '1.92457'] | Gamma1 Grad: ['-0.00654', '0.00295', '-0.02067', '-0.00413', '0.07233', '0.03214', '-0.00499', '-0.06213', '0.00676', '0.00387', '0.02435', '0.09253', '0.00621']
Epoch 78: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['3.39606', '3.96584', '2.56949', '2.23825', '2.18073', '2.36598', '2.65555', '2.97784', '3.42229', '2.54248', '0.66058', '1.21480', '1.88472'] | Gamma1 Grad: ['-0.00604', '0.00089', '-0.00348', '-0.02035', '0.10167', '0.06196', '0.00072', '0.01440', '-0.00220', '0.00235', '-0.14793', '0.10805', '0.01538']
Epoch 79: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00146 | Gamma1: ['3.39406', '3.98772', '2.53189', '2.22219', '2.18904', '2.33099', '2.64119', '2.96809', '3.43028', '2.55202', '0.67428', '1.21746', '1.89669'] | Gamma1 Grad: ['0.00378', '-0.04268', '-0.11488', '-0.01867', '-0.02715', '-0.02277', '0.01536', '-0.04067', '0.00715', '0.00043', '0.13803', '-0.02493', '0.07302']
Epoch 80: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00144 | Gamma1: ['3.41144', '3.98775', '2.57520', '2.21182', '2.12993', '2.37457', '2.62933', '2.97727', '3.42178', '2.58193', '0.74816', '1.21159', '1.90158'] | Gamma1 Grad: ['0.01254', '0.01230', '-0.04635', '-0.03579', '-0.03246', '0.05486', '-0.02946', '0.02553', '-0.00580', '0.00740', '0.06430', '-0.15339', '0.00145']
Epoch 81: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00143 | Gamma1: ['3.40790', '3.99476', '2.59052', '2.22234', '2.12973', '2.33249', '2.63722', '2.96554', '3.42015', '2.60374', '0.80222', '1.21360', '1.92399'] | Gamma1 Grad: ['-0.00124', '0.00255', '0.01069', '-0.04101', '0.03824', '-0.02155', '-0.02339', '0.03161', '0.00289', '0.01011', '0.05796', '-0.08457', '-0.00653']
Epoch 82: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00142 | Gamma1: ['3.41697', '4.00076', '2.60782', '2.21105', '2.12711', '2.31651', '2.64563', '2.97215', '3.41600', '2.62922', '0.87124', '1.22428', '1.95759'] | Gamma1 Grad: ['-0.01400', '-0.00167', '-0.00851', '0.00809', '-0.03960', '0.05483', '-0.03193', '0.01008', '0.00230', '0.00427', '0.03434', '0.01467', '-0.01971']
Epoch 83: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00141 | Gamma1: ['3.41606', '3.98045', '2.58111', '2.16916', '2.12503', '2.32234', '2.64802', '2.98185', '3.42542', '2.64412', '0.88705', '1.20761', '1.96767'] | Gamma1 Grad: ['-0.01354', '0.00235', '-0.03902', '0.07582', '0.02580', '-0.06787', '0.03790', '-0.02533', '0.00005', '-0.00562', '-0.06265', '0.02477', '-0.00288']
Epoch 84: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00139 | Gamma1: ['3.40582', '3.96921', '2.59170', '2.17674', '2.11229', '2.33529', '2.63870', '2.97331', '3.43061', '2.63577', '0.89065', '1.21895', '2.00511'] | Gamma1 Grad: ['0.00462', '0.01200', '0.04883', '0.00644', '0.06555', '0.03116', '0.03362', '-0.01254', '-0.00081', '0.00134', '0.04098', '-0.02979', '0.00388']
Epoch 85: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00138 | Gamma1: ['3.40510', '3.95804', '2.60447', '2.15908', '2.10794', '2.32542', '2.66011', '2.97173', '3.42761', '2.63188', '0.90554', '1.23340', '2.01239'] | Gamma1 Grad: ['-0.00062', '-0.00011', '-0.00055', '-0.00335', '0.00169', '-0.00040', '-0.00139', '0.00296', '-0.00028', '-0.00009', '0.00102', '0.00050', '-0.00084']
Epoch 86: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00136 | Gamma1: ['3.42192', '3.94660', '2.59046', '2.12978', '2.10654', '2.36153', '2.64697', '2.98962', '3.43642', '2.64456', '0.94842', '1.23515', '2.04504'] | Gamma1 Grad: ['0.00528', '-0.00956', '0.00293', '0.10475', '-0.11901', '-0.06838', '0.01086', '-0.01073', '0.01356', '0.00518', '-0.01295', '0.01465', '0.01289']
Epoch 87: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00134 | Gamma1: ['3.41427', '3.92736', '2.56717', '2.13988', '2.08694', '2.36595', '2.64233', '2.96753', '3.43431', '2.66134', '0.95124', '1.27798', '2.06222'] | Gamma1 Grad: ['0.01103', '0.00700', '0.01804', '-0.05925', '0.02625', '0.05356', '-0.02431', '0.01745', '0.00234', '-0.01014', '-0.07650', '-0.01973', '-0.01444']
Epoch 88: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00133 | Gamma1: ['3.41365', '3.92014', '2.59007', '2.08992', '2.10058', '2.37234', '2.65189', '2.95984', '3.42755', '2.66770', '0.98851', '1.28809', '2.09774'] | Gamma1 Grad: ['0.00066', '0.00904', '0.02996', '0.03602', '0.01340', '-0.00110', '0.01060', '-0.01730', '0.00205', '-0.00280', '0.05066', '-0.00273', '-0.00522']
Epoch 89: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00131 | Gamma1: ['3.42899', '3.92114', '2.57628', '2.08959', '2.13290', '2.34234', '2.65811', '2.94490', '3.43499', '2.67155', '1.01589', '1.28124', '2.14302'] | Gamma1 Grad: ['-0.04586', '0.00961', '0.04076', '-0.12574', '0.13913', '0.00474', '0.09113', '-0.09367', '-0.00021', '-0.01407', '-0.06960', '0.03419', '-0.04705']
Epoch 90: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00129 | Gamma1: ['3.45653', '3.93762', '2.57189', '2.08674', '2.10104', '2.31663', '2.64745', '2.97203', '3.42646', '2.68237', '1.02847', '1.28576', '2.17688'] | Gamma1 Grad: ['-0.00433', '0.00043', '-0.01368', '0.01659', '0.00753', '-0.01073', '-0.00580', '0.00327', '-0.00211', '-0.00025', '0.00390', '-0.00076', '0.00771']
Epoch 91: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00127 | Gamma1: ['3.45236', '3.94304', '2.55328', '2.09504', '2.10442', '2.29523', '2.65370', '2.97775', '3.43318', '2.68725', '1.02518', '1.29501', '2.20712'] | Gamma1 Grad: ['-0.01796', '0.01657', '0.01765', '-0.00146', '0.11292', '-0.00363', '-0.01845', '-0.02197', '-0.00123', '-0.00255', '-0.00449', '0.01724', '-0.01632']
Epoch 92: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00125 | Gamma1: ['3.45064', '3.93983', '2.54911', '2.07858', '2.08602', '2.32481', '2.63515', '2.96232', '3.43053', '2.69884', '1.06248', '1.28077', '2.22244'] | Gamma1 Grad: ['0.01274', '0.00315', '0.01191', '0.07541', '-0.01992', '0.00077', '0.02719', '0.00352', '-0.00234', '0.00090', '-0.01419', '-0.01762', '0.01288']
Epoch 93: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00122 | Gamma1: ['3.45038', '3.91509', '2.55644', '2.04600', '2.06765', '2.31724', '2.62083', '2.96927', '3.42838', '2.70573', '1.07106', '1.31007', '2.24753'] | Gamma1 Grad: ['-0.03414', '0.03507', '-0.11294', '0.06516', '-0.21673', '-0.21953', '0.08125', '-0.04039', '0.00024', '0.00652', '-0.00493', '-0.01987', '0.02944']
Epoch 94: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00120 | Gamma1: ['3.45244', '3.90901', '2.56776', '2.02168', '2.09417', '2.30510', '2.64086', '2.96420', '3.42079', '2.70914', '1.06903', '1.29637', '2.25852'] | Gamma1 Grad: ['0.00869', '-0.00124', '0.00353', '0.01610', '-0.02919', '-0.07895', '-0.02832', '0.01528', '-0.00452', '-0.00083', '-0.01104', '-0.00519', '0.00429']
Epoch 95: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00118 | Gamma1: ['3.46045', '3.90981', '2.53996', '2.04334', '2.07458', '2.28659', '2.64703', '2.95837', '3.42064', '2.72154', '1.08339', '1.25246', '2.29822'] | Gamma1 Grad: ['-0.01621', '-0.01085', '-0.00677', '-0.00125', '0.00366', '-0.02351', '0.00538', '-0.00212', '-0.00392', '-0.00229', '-0.06615', '0.04677', '-0.01808']
Epoch 96: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00115 | Gamma1: ['3.46456', '3.90053', '2.52867', '2.05709', '2.07393', '2.28674', '2.62296', '2.94535', '3.42760', '2.72235', '1.07308', '1.26004', '2.32403'] | Gamma1 Grad: ['0.00201', '0.00044', '-0.00224', '-0.00630', '-0.02523', '-0.00521', '-0.00980', '-0.00962', '0.00142', '0.00291', '0.00199', '0.01010', '0.00694']
Epoch 97: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00113 | Gamma1: ['3.47309', '3.89512', '2.54214', '2.06177', '2.08899', '2.29569', '2.57807', '2.94711', '3.41533', '2.73543', '1.07790', '1.26598', '2.34408'] | Gamma1 Grad: ['-0.01666', '0.02491', '0.04444', '0.03957', '0.13755', '-0.05443', '0.00333', '-0.00698', '-0.00438', '-0.01662', '-0.03334', '-0.07790', '0.02924']
Epoch 98: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00110 | Gamma1: ['3.47299', '3.90853', '2.52306', '2.05397', '2.07067', '2.27877', '2.57051', '2.94711', '3.41449', '2.73930', '1.07791', '1.29379', '2.37715'] | Gamma1 Grad: ['0.00114', '-0.00099', '0.00241', '-0.00227', '0.00257', '0.00105', '0.00238', '-0.00342', '0.00008', '0.00024', '-0.01733', '-0.01215', '-0.00451']
Epoch 99: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00108 | Gamma1: ['3.46820', '3.90800', '2.50372', '2.06050', '2.09645', '2.27976', '2.59132', '2.94043', '3.39435', '2.74794', '1.09239', '1.31506', '2.38171'] | Gamma1 Grad: ['-0.00559', '-0.00764', '-0.00367', '0.03671', '0.02483', '-0.00781', '-0.01637', '-0.00812', '0.00588', '-0.00134', '-0.01668', '0.01879', '-0.00332']
