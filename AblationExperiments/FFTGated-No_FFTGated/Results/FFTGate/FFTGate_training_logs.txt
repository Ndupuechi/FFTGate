Epoch 0: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000'] | Gamma1 Grad: ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']
Epoch 1: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.22877', '2.23382', '2.23213', '2.22852', '2.22703', '2.22764', '2.22539', '2.22260', '2.22283', '2.22699', '2.22155', '2.22091', '2.21137'] | Gamma1 Grad: ['0.00442', '-0.00031', '-0.00601', '-0.00122', '-0.00444', '-0.00393', '-0.00143', '-0.00565', '-0.01676', '-0.00943', '-0.01106', '-0.01930', '-0.02150']
Epoch 2: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.29320', '2.30092', '2.29607', '2.28499', '2.28320', '2.28398', '2.28155', '2.28344', '2.27965', '2.28457', '2.28107', '2.27690', '2.27087'] | Gamma1 Grad: ['-0.01173', '-0.01529', '-0.00073', '-0.01383', '-0.01073', '-0.00367', '-0.01074', '-0.00466', '-0.00627', '-0.00891', '-0.00441', '0.01163', '-0.01404']
Epoch 3: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.30761', '2.31503', '2.31461', '2.29196', '2.29241', '2.29127', '2.28944', '2.29018', '2.28880', '2.28579', '2.28810', '2.27643', '2.27499'] | Gamma1 Grad: ['-0.02470', '-0.00262', '-0.01795', '0.00095', '-0.00718', '-0.01034', '-0.00493', '-0.00758', '-0.00279', '-0.01305', '-0.00201', '0.00554', '-0.03750']
Epoch 4: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.30896', '2.31813', '2.30743', '2.29942', '2.29603', '2.29561', '2.29270', '2.29644', '2.29247', '2.29027', '2.28864', '2.27553', '2.28516'] | Gamma1 Grad: ['0.00192', '-0.00707', '0.00721', '0.00287', '-0.00142', '0.00004', '0.00448', '0.00080', '0.00184', '0.00738', '-0.00110', '-0.03998', '0.02662']
Epoch 5: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31167', '2.31957', '2.31564', '2.29846', '2.30505', '2.29974', '2.29377', '2.29588', '2.28806', '2.29550', '2.28758', '2.28642', '2.27936'] | Gamma1 Grad: ['0.00696', '0.02171', '0.01513', '-0.00012', '0.00105', '0.00495', '0.00697', '0.00279', '0.00228', '-0.00478', '-0.00473', '0.01472', '-0.00225']
Epoch 6: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31508', '2.32317', '2.31695', '2.29950', '2.30213', '2.30099', '2.28620', '2.29653', '2.29807', '2.28988', '2.28725', '2.28044', '2.28505'] | Gamma1 Grad: ['-0.01144', '0.01072', '-0.00742', '-0.01138', '0.00491', '0.01069', '-0.00212', '-0.00420', '0.00324', '0.00780', '-0.00252', '-0.00909', '0.00882']
Epoch 7: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.31498', '2.31607', '2.31566', '2.29386', '2.29918', '2.29948', '2.29108', '2.29317', '2.28997', '2.29180', '2.28833', '2.28624', '2.29180'] | Gamma1 Grad: ['0.00919', '0.01570', '-0.00514', '-0.01033', '0.01654', '0.00360', '-0.01058', '-0.00949', '-0.02399', '-0.00957', '-0.00002', '-0.00090', '0.12610']
Epoch 8: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.31022', '2.32869', '2.31153', '2.29181', '2.30458', '2.29838', '2.29108', '2.30158', '2.29821', '2.29700', '2.29426', '2.29021', '2.29550'] | Gamma1 Grad: ['0.00438', '-0.02609', '-0.01039', '0.00291', '0.01131', '0.01196', '0.00581', '0.00208', '0.01564', '0.00617', '-0.00617', '0.02199', '0.03064']
Epoch 9: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.31566', '2.31471', '2.31294', '2.29928', '2.29572', '2.30051', '2.28819', '2.30080', '2.29587', '2.29657', '2.29141', '2.27693', '2.29508'] | Gamma1 Grad: ['-0.04175', '-0.04704', '-0.03737', '-0.01007', '-0.00688', '0.02193', '0.00762', '0.01339', '0.00923', '0.00490', '-0.00008', '-0.02298', '-0.01488']
Epoch 10: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.31809', '2.32098', '2.31772', '2.29889', '2.30761', '2.30122', '2.29015', '2.29590', '2.29794', '2.29514', '2.29578', '2.28582', '2.29722'] | Gamma1 Grad: ['-0.01337', '-0.00727', '0.00701', '-0.00371', '0.02967', '-0.00682', '0.01550', '0.00237', '0.00791', '0.00018', '0.00081', '-0.00705', '0.01443']
Epoch 11: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.31535', '2.31008', '2.32053', '2.29365', '2.30869', '2.30200', '2.29387', '2.29996', '2.29809', '2.29872', '2.29450', '2.28994', '2.29690'] | Gamma1 Grad: ['0.00820', '0.02291', '-0.01461', '0.02158', '0.00235', '-0.00313', '0.00409', '-0.00401', '0.02313', '0.01083', '0.00454', '-0.01280', '0.02064']
Epoch 12: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.30407', '2.32064', '2.30559', '2.29297', '2.31286', '2.30362', '2.28884', '2.28635', '2.29119', '2.28017', '2.28468', '2.29578', '2.29920'] | Gamma1 Grad: ['-0.00384', '0.00882', '0.02202', '-0.00644', '0.00819', '-0.00439', '0.00262', '-0.00731', '0.00233', '0.00864', '-0.00152', '-0.00260', '0.10529']
Epoch 13: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['2.32410', '2.32293', '2.31034', '2.29536', '2.30655', '2.29437', '2.30599', '2.30473', '2.28360', '2.29426', '2.28544', '2.28838', '2.31053'] | Gamma1 Grad: ['0.01494', '-0.00837', '-0.01471', '0.00552', '-0.02092', '-0.01073', '-0.00119', '-0.00703', '-0.00235', '0.00779', '-0.00896', '-0.01000', '0.04530']
Epoch 14: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.31527', '2.32061', '2.31157', '2.29230', '2.31047', '2.30462', '2.29330', '2.31132', '2.27970', '2.29465', '2.29701', '2.28503', '2.29096'] | Gamma1 Grad: ['0.01208', '-0.00884', '0.02105', '-0.00675', '-0.01744', '0.00113', '0.00426', '-0.00672', '0.01520', '-0.00118', '0.00099', '0.02754', '-0.03027']
Epoch 15: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['2.29775', '2.30002', '2.29914', '2.31162', '2.29994', '2.30861', '2.29755', '2.31056', '2.31011', '2.29397', '2.30375', '2.28505', '2.29822'] | Gamma1 Grad: ['0.03626', '0.02230', '0.04040', '0.02568', '-0.06498', '-0.00087', '-0.01722', '-0.00759', '0.01631', '-0.00106', '-0.00031', '-0.05171', '0.05531']
Epoch 16: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.31081', '2.31299', '2.30185', '2.28863', '2.29562', '2.30863', '2.28945', '2.29356', '2.29471', '2.28345', '2.29191', '2.27354', '2.29966'] | Gamma1 Grad: ['0.02188', '-0.00524', '0.05281', '0.02713', '-0.01936', '0.02876', '0.00056', '-0.02003', '0.02719', '0.00350', '0.00038', '0.02431', '0.00373']
Epoch 17: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['2.31932', '2.31875', '2.29767', '2.30314', '2.31674', '2.31613', '2.29178', '2.30679', '2.29660', '2.28990', '2.28156', '2.28827', '2.31070'] | Gamma1 Grad: ['-0.00203', '0.03661', '-0.00815', '-0.00925', '0.01773', '-0.01003', '-0.00306', '0.00018', '0.00144', '-0.00779', '-0.00290', '0.01063', '0.01282']
Epoch 18: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.31258', '2.31803', '2.30115', '2.29991', '2.30655', '2.32124', '2.30689', '2.30871', '2.29767', '2.29539', '2.29078', '2.29414', '2.30943'] | Gamma1 Grad: ['0.00203', '-0.00627', '-0.02548', '-0.01025', '-0.03078', '0.01931', '-0.01621', '-0.00527', '-0.02892', '-0.01247', '0.00820', '-0.01083', '0.04274']
Epoch 19: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['2.31569', '2.32302', '2.29661', '2.30004', '2.30470', '2.31113', '2.30210', '2.30001', '2.29899', '2.29230', '2.29409', '2.29644', '2.30474'] | Gamma1 Grad: ['-0.02667', '0.01245', '-0.00081', '0.00796', '0.00105', '-0.00987', '-0.00521', '0.00579', '-0.00608', '-0.00616', '0.00751', '-0.01921', '-0.03911']
Epoch 20: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.30786', '2.31187', '2.30417', '2.28776', '2.28895', '2.31373', '2.28999', '2.29183', '2.29287', '2.28434', '2.29186', '2.28658', '2.31402'] | Gamma1 Grad: ['-0.06440', '-0.03173', '-0.07868', '0.00197', '-0.04235', '0.01584', '0.03076', '0.00192', '0.01964', '0.00345', '0.00881', '-0.04458', '-0.00018']
Epoch 21: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['2.31042', '2.31675', '2.30996', '2.29392', '2.29375', '2.31928', '2.30552', '2.30609', '2.30017', '2.28981', '2.29047', '2.29086', '2.29900'] | Gamma1 Grad: ['-0.02719', '0.02569', '0.00794', '-0.02657', '0.01992', '0.01331', '-0.01984', '-0.00506', '-0.00491', '0.00428', '-0.00056', '0.00042', '-0.02695']
Epoch 22: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.31575', '2.31610', '2.30371', '2.30202', '2.29583', '2.32363', '2.30733', '2.30175', '2.29294', '2.29400', '2.28871', '2.28730', '2.30984'] | Gamma1 Grad: ['-0.02321', '0.01022', '0.03109', '-0.00536', '0.01303', '0.00824', '0.01354', '0.00689', '0.01409', '0.00248', '0.00024', '0.01451', '-0.02497']
Epoch 23: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['2.30508', '2.30164', '2.29607', '2.29432', '2.29948', '2.30491', '2.30158', '2.30887', '2.29441', '2.29518', '2.29694', '2.29000', '2.31092'] | Gamma1 Grad: ['-0.03196', '0.01455', '-0.04484', '-0.00025', '-0.03860', '0.02745', '-0.00929', '0.00759', '0.01144', '-0.01413', '-0.01134', '0.02373', '0.05744']
Epoch 24: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.30573', '2.29875', '2.30393', '2.29033', '2.31577', '2.30695', '2.30069', '2.30334', '2.30289', '2.29678', '2.29136', '2.29737', '2.30733'] | Gamma1 Grad: ['-0.02773', '0.03910', '0.01885', '0.03611', '-0.02893', '-0.01952', '0.00572', '-0.00201', '-0.00881', '0.01671', '0.00783', '0.00020', '-0.04427']
Epoch 25: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['2.30718', '2.29869', '2.30204', '2.28848', '2.29947', '2.31334', '2.30978', '2.30423', '2.29957', '2.29402', '2.29256', '2.29000', '2.31315'] | Gamma1 Grad: ['-0.02446', '-0.01319', '0.00027', '-0.02855', '0.01689', '-0.00952', '0.00595', '0.00833', '-0.00239', '-0.00367', '-0.00525', '0.01162', '-0.02228']
Epoch 26: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.30309', '2.31285', '2.30964', '2.29989', '2.30650', '2.31822', '2.31572', '2.30363', '2.30773', '2.28877', '2.29814', '2.29080', '2.30100'] | Gamma1 Grad: ['-0.01041', '-0.07157', '0.03981', '-0.07144', '0.03320', '-0.01182', '0.00737', '0.02518', '-0.01402', '0.00517', '-0.01987', '0.01016', '-0.00222']
Epoch 27: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['2.30051', '2.31606', '2.29880', '2.30090', '2.30251', '2.31270', '2.30165', '2.30809', '2.30023', '2.29901', '2.29256', '2.28280', '2.29936'] | Gamma1 Grad: ['-0.04575', '0.01591', '-0.06942', '0.01374', '-0.08315', '0.00896', '-0.01899', '-0.01877', '0.05307', '0.00863', '0.01763', '-0.00657', '0.13379']
Epoch 28: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.30556', '2.31292', '2.30365', '2.29208', '2.29914', '2.31002', '2.31012', '2.31253', '2.29217', '2.29744', '2.29464', '2.29188', '2.30555'] | Gamma1 Grad: ['-0.02336', '0.03035', '0.02815', '-0.03653', '0.05443', '-0.03503', '-0.00158', '-0.00638', '0.01121', '-0.01273', '0.00133', '0.00622', '-0.06304']
Epoch 29: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['2.31016', '2.30820', '2.29825', '2.29184', '2.29502', '2.30520', '2.30488', '2.30560', '2.30160', '2.29228', '2.29472', '2.29107', '2.31011'] | Gamma1 Grad: ['0.01533', '0.02881', '0.04916', '0.00920', '-0.00105', '0.03036', '0.02472', '0.00713', '0.00313', '-0.00422', '-0.00949', '-0.00576', '0.08816']
Epoch 30: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.30490', '2.30814', '2.30368', '2.30003', '2.30043', '2.31612', '2.30773', '2.31355', '2.29725', '2.29657', '2.29578', '2.28859', '2.30802'] | Gamma1 Grad: ['0.00817', '0.02264', '0.00920', '-0.02320', '0.01774', '0.02445', '0.02159', '0.01085', '0.00855', '-0.00683', '-0.00027', '-0.01273', '-0.01526']
Epoch 31: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.32049', '2.31780', '2.31554', '2.30566', '2.29761', '2.30536', '2.30398', '2.30721', '2.29613', '2.29486', '2.29877', '2.29939', '2.30667'] | Gamma1 Grad: ['0.04494', '0.02016', '0.02623', '-0.00649', '0.01235', '-0.00328', '-0.00730', '-0.01351', '0.02052', '0.00198', '-0.00003', '0.03247', '-0.06993']
Epoch 32: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.30813', '2.31271', '2.30729', '2.30077', '2.28975', '2.31114', '2.30035', '2.29996', '2.29930', '2.29355', '2.29389', '2.28590', '2.30326'] | Gamma1 Grad: ['-0.00148', '-0.03438', '0.00859', '-0.04080', '0.00528', '0.05615', '-0.02555', '0.01840', '-0.00148', '0.00306', '-0.00553', '-0.04073', '-0.00783']
Epoch 33: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['2.30465', '2.31290', '2.31425', '2.29115', '2.30211', '2.29747', '2.29687', '2.31025', '2.29505', '2.30016', '2.29150', '2.29065', '2.31425'] | Gamma1 Grad: ['-0.01055', '0.00308', '0.00066', '0.00102', '0.00026', '-0.01814', '0.02389', '0.00365', '-0.01105', '0.01103', '-0.00365', '-0.00827', '-0.04519']
Epoch 34: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.31175', '2.31876', '2.29083', '2.28511', '2.30022', '2.30901', '2.30092', '2.30242', '2.30845', '2.29868', '2.28827', '2.29867', '2.29330'] | Gamma1 Grad: ['0.07630', '0.02733', '0.01170', '-0.02188', '-0.03262', '-0.01399', '-0.00435', '0.01424', '0.00960', '-0.00776', '0.00672', '-0.01475', '0.06522']
Epoch 35: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00144 | Gamma1: ['2.30284', '2.30503', '2.29330', '2.29703', '2.29418', '2.31734', '2.30170', '2.30608', '2.29214', '2.29224', '2.30216', '2.29081', '2.30006'] | Gamma1 Grad: ['-0.04689', '-0.01781', '0.01913', '-0.01929', '-0.08062', '0.03843', '-0.05005', '-0.03316', '-0.01885', '0.00347', '-0.00176', '0.00477', '-0.00289']
Epoch 36: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['2.31515', '2.29723', '2.29724', '2.28982', '2.30414', '2.31009', '2.30750', '2.29614', '2.30500', '2.30408', '2.30026', '2.29973', '2.28940'] | Gamma1 Grad: ['0.04803', '0.04748', '0.09816', '0.00548', '0.00062', '0.01342', '0.03545', '-0.03249', '0.01322', '-0.00536', '0.00447', '0.00114', '0.02916']
Epoch 37: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00139 | Gamma1: ['2.31436', '2.29728', '2.28842', '2.30489', '2.29967', '2.30014', '2.30298', '2.29088', '2.29737', '2.28174', '2.28052', '2.29362', '2.30880'] | Gamma1 Grad: ['-0.00343', '0.00578', '-0.03733', '-0.02059', '0.08476', '0.03713', '0.01115', '0.01894', '-0.00613', '0.00650', '-0.02883', '0.02524', '0.04715']
Epoch 38: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.29453', '2.29513', '2.30542', '2.29308', '2.29725', '2.30645', '2.30436', '2.31470', '2.29401', '2.29077', '2.28488', '2.29132', '2.29885'] | Gamma1 Grad: ['-0.01781', '-0.00449', '-0.06520', '-0.00104', '-0.03136', '0.04518', '-0.01485', '-0.03332', '0.02054', '-0.00650', '-0.00786', '-0.00239', '0.01366']
Epoch 39: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00133 | Gamma1: ['2.30473', '2.30717', '2.29355', '2.28937', '2.29181', '2.31773', '2.31749', '2.31386', '2.29906', '2.29690', '2.28101', '2.28262', '2.30961'] | Gamma1 Grad: ['-0.06198', '0.03808', '0.02772', '0.00154', '0.01899', '0.07700', '0.02467', '0.01074', '0.00098', '0.00023', '-0.00227', '0.01018', '-0.03548']
Epoch 40: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00129 | Gamma1: ['2.34117', '2.35805', '2.30417', '2.27981', '2.29807', '2.31448', '2.35321', '2.33380', '2.31810', '2.29351', '2.28419', '2.27448', '2.34114'] | Gamma1 Grad: ['0.04095', '0.02620', '0.12174', '-0.01632', '0.06049', '0.05993', '0.00134', '-0.01816', '0.03011', '0.01570', '-0.00910', '-0.02133', '-0.04844']
Epoch 41: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00125 | Gamma1: ['2.33923', '2.36121', '2.33363', '2.28297', '2.31389', '2.31547', '2.34129', '2.35175', '2.31125', '2.29694', '2.29801', '2.29180', '2.32063'] | Gamma1 Grad: ['0.02166', '0.07146', '0.12552', '-0.00871', '0.02045', '-0.03148', '0.03809', '-0.02828', '0.03569', '-0.02794', '0.00749', '-0.04767', '0.05959']
Epoch 42: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00120 | Gamma1: ['2.32771', '2.35460', '2.31542', '2.30899', '2.28782', '2.30955', '2.34086', '2.35767', '2.32604', '2.29434', '2.29194', '2.27130', '2.33089'] | Gamma1 Grad: ['-0.03199', '0.02717', '-0.05233', '0.02892', '0.04859', '-0.04047', '0.02644', '0.00503', '-0.00956', '-0.00737', '-0.00383', '-0.02874', '0.01886']
Epoch 43: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00115 | Gamma1: ['2.32529', '2.35516', '2.32753', '2.29172', '2.27393', '2.29887', '2.35644', '2.34317', '2.33514', '2.30598', '2.29428', '2.29147', '2.32565'] | Gamma1 Grad: ['0.01941', '-0.01098', '0.02024', '-0.02444', '0.06838', '0.03175', '0.00688', '-0.00405', '-0.00845', '-0.00321', '-0.01063', '-0.00326', '-0.04621']
Epoch 44: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00110 | Gamma1: ['2.33360', '2.33705', '2.32463', '2.28211', '2.27641', '2.32110', '2.35031', '2.35190', '2.33794', '2.31135', '2.30013', '2.28443', '2.31945'] | Gamma1 Grad: ['0.00729', '-0.05581', '0.10657', '-0.07997', '0.05906', '0.02878', '0.01186', '-0.00188', '0.01794', '0.00565', '-0.01697', '-0.02228', '-0.03728']
Epoch 45: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00105 | Gamma1: ['2.31474', '2.31698', '2.29962', '2.31305', '2.26395', '2.32893', '2.36495', '2.36154', '2.31191', '2.31296', '2.29755', '2.29926', '2.31971'] | Gamma1 Grad: ['0.02806', '0.00252', '-0.00085', '0.06908', '-0.04240', '-0.05382', '0.04449', '-0.01851', '-0.01455', '0.00100', '-0.00297', '0.01387', '0.02491']
Epoch 46: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.34874', '2.34329', '2.33060', '2.28017', '2.28696', '2.33607', '2.35460', '2.36522', '2.32363', '2.29763', '2.29644', '2.29726', '2.32120'] | Gamma1 Grad: ['-0.00703', '-0.02114', '0.01851', '0.03007', '-0.04983', '-0.04919', '0.00129', '0.01967', '0.01022', '-0.00247', '-0.01504', '-0.01192', '-0.00970']
Epoch 47: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00094 | Gamma1: ['2.32676', '2.33436', '2.31832', '2.25168', '2.28850', '2.30164', '2.35885', '2.34705', '2.31486', '2.31014', '2.30148', '2.28172', '2.33168'] | Gamma1 Grad: ['-0.02659', '0.01722', '0.01523', '0.02544', '-0.01362', '-0.00664', '0.00568', '-0.00562', '0.00078', '-0.00210', '0.00561', '-0.00109', '0.03766']
Epoch 48: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00089 | Gamma1: ['2.30848', '2.36174', '2.30472', '2.28124', '2.28603', '2.28857', '2.36112', '2.35861', '2.31654', '2.30250', '2.30829', '2.30089', '2.31581'] | Gamma1 Grad: ['0.00394', '-0.11931', '-0.13521', '0.12442', '0.16975', '-0.08876', '0.11501', '0.02008', '-0.00619', '-0.01246', '-0.01191', '0.00332', '0.05882']
Epoch 49: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00083 | Gamma1: ['2.32803', '2.33664', '2.29372', '2.28055', '2.26542', '2.28627', '2.37541', '2.35677', '2.32184', '2.31196', '2.29976', '2.28857', '2.30548'] | Gamma1 Grad: ['-0.00613', '-0.06029', '-0.02681', '0.03359', '-0.15164', '0.07242', '0.01812', '0.03733', '-0.00490', '-0.00587', '0.00435', '0.01100', '-0.04494']
Epoch 50: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.31009', '2.34863', '2.31558', '2.27222', '2.25430', '2.30050', '2.37485', '2.36522', '2.31039', '2.30323', '2.28544', '2.28292', '2.30861'] | Gamma1 Grad: ['-0.00018', '-0.05812', '0.01706', '0.00606', '-0.01224', '-0.04583', '-0.02026', '-0.00547', '-0.00415', '-0.00224', '-0.00755', '-0.01145', '-0.03510']
Epoch 51: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00072 | Gamma1: ['2.33342', '2.33150', '2.29703', '2.26367', '2.26232', '2.28109', '2.35704', '2.35027', '2.32525', '2.29811', '2.30374', '2.30234', '2.31589'] | Gamma1 Grad: ['0.03652', '0.00999', '-0.01148', '-0.01658', '0.00912', '-0.03975', '-0.01529', '-0.02292', '-0.01509', '-0.00182', '-0.01481', '-0.01933', '-0.03622']
Epoch 52: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00066 | Gamma1: ['2.29852', '2.33411', '2.31594', '2.29442', '2.25319', '2.28778', '2.35362', '2.35507', '2.32558', '2.30455', '2.31121', '2.28918', '2.32173'] | Gamma1 Grad: ['0.03750', '0.04198', '-0.01577', '-0.02626', '-0.00678', '0.03947', '-0.00267', '-0.01251', '0.01071', '0.00183', '0.00491', '-0.01104', '0.00291']
Epoch 53: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00061 | Gamma1: ['2.31945', '2.34066', '2.30952', '2.28232', '2.25397', '2.29487', '2.34165', '2.34975', '2.32449', '2.29974', '2.29206', '2.27706', '2.32557'] | Gamma1 Grad: ['-0.00342', '-0.00680', '0.19565', '0.01325', '-0.03166', '0.03544', '-0.01534', '-0.02330', '-0.00635', '0.00893', '0.01116', '0.00966', '-0.06349']
Epoch 54: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00055 | Gamma1: ['2.33798', '2.35112', '2.30520', '2.27946', '2.25233', '2.27521', '2.32720', '2.33884', '2.32285', '2.27539', '2.28272', '2.28155', '2.30604'] | Gamma1 Grad: ['-0.00642', '-0.04282', '0.10941', '-0.07703', '0.10203', '0.00752', '0.07962', '0.10416', '0.00070', '-0.02004', '-0.00864', '-0.03926', '0.04968']
Epoch 55: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00050 | Gamma1: ['2.31951', '2.34174', '2.30536', '2.29056', '2.25195', '2.26838', '2.35054', '2.34789', '2.33662', '2.27969', '2.28545', '2.29226', '2.30340'] | Gamma1 Grad: ['-0.02096', '-0.02307', '-0.01119', '0.02035', '0.02316', '0.06200', '-0.00022', '-0.01090', '-0.03571', '-0.01038', '0.00453', '-0.00021', '0.06056']
Epoch 56: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00045 | Gamma1: ['2.31293', '2.33317', '2.30598', '2.29442', '2.25918', '2.28596', '2.32807', '2.36431', '2.33795', '2.29396', '2.29156', '2.27665', '2.29796'] | Gamma1 Grad: ['0.02745', '0.00010', '-0.00252', '0.06018', '-0.02608', '-0.02983', '0.07507', '-0.00173', '-0.04747', '0.01289', '0.01904', '0.04129', '0.09058']
Epoch 57: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00040 | Gamma1: ['2.33104', '2.33744', '2.29908', '2.28917', '2.24390', '2.26494', '2.31857', '2.36423', '2.32558', '2.29387', '2.29144', '2.28779', '2.30970'] | Gamma1 Grad: ['-0.06061', '-0.07110', '-0.03597', '0.06505', '-0.00467', '0.07882', '-0.03837', '-0.02452', '0.02282', '-0.00498', '-0.01030', '-0.00335', '-0.00655']
Epoch 58: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00035 | Gamma1: ['2.32208', '2.32381', '2.31080', '2.28870', '2.24135', '2.27956', '2.33205', '2.34236', '2.32318', '2.29428', '2.28431', '2.28367', '2.30048'] | Gamma1 Grad: ['-0.01188', '0.04525', '-0.06325', '0.01862', '-0.10686', '0.01737', '0.01334', '-0.07251', '0.01257', '-0.00269', '0.02216', '0.02402', '0.03488']
Epoch 59: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00030 | Gamma1: ['2.32502', '2.33230', '2.31194', '2.28217', '2.24290', '2.28157', '2.33780', '2.35811', '2.31544', '2.29804', '2.28664', '2.28597', '2.32029'] | Gamma1 Grad: ['-0.01264', '0.01269', '-0.03020', '0.16085', '-0.01422', '-0.07486', '-0.01623', '-0.02731', '-0.01991', '0.01239', '0.00596', '0.00223', '-0.04689']
Epoch 60: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00026 | Gamma1: ['2.34948', '2.31912', '2.30931', '2.26949', '2.23876', '2.26781', '2.32484', '2.35377', '2.34185', '2.30121', '2.29061', '2.30086', '2.31512'] | Gamma1 Grad: ['0.00417', '-0.01051', '0.03303', '0.00863', '-0.00786', '-0.01355', '-0.00144', '-0.01134', '0.00806', '-0.00851', '0.00458', '-0.00029', '0.03621']
Epoch 61: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00022 | Gamma1: ['2.33857', '2.34055', '2.28702', '2.24603', '2.23391', '2.26970', '2.37845', '2.36966', '2.35223', '2.29771', '2.29528', '2.28340', '2.31058'] | Gamma1 Grad: ['-0.00414', '-0.00074', '-0.01869', '-0.00852', '0.05319', '-0.04707', '-0.00233', '0.02550', '0.00529', '-0.00061', '-0.00647', '0.03132', '-0.00420']
Epoch 62: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.34689', '2.34250', '2.30075', '2.25139', '2.25678', '2.28545', '2.36842', '2.37818', '2.35887', '2.29621', '2.29584', '2.27423', '2.29856'] | Gamma1 Grad: ['0.01984', '-0.03955', '-0.02869', '0.00159', '0.14788', '-0.05236', '0.02613', '-0.02359', '-0.00831', '0.01929', '-0.00103', '-0.05846', '-0.01518']
Epoch 63: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00016 | Gamma1: ['2.33990', '2.34350', '2.32178', '2.25339', '2.24122', '2.25888', '2.35595', '2.38423', '2.35898', '2.29478', '2.29964', '2.26824', '2.30398'] | Gamma1 Grad: ['-0.05173', '0.00127', '-0.01433', '-0.05521', '-0.01880', '0.08955', '-0.04075', '-0.02581', '-0.01138', '0.00972', '-0.00574', '-0.00369', '-0.01270']
Epoch 64: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00013 | Gamma1: ['2.36239', '2.34344', '2.30480', '2.25617', '2.24407', '2.26227', '2.37481', '2.38173', '2.34888', '2.29209', '2.28331', '2.27403', '2.29530'] | Gamma1 Grad: ['-0.03379', '-0.04780', '0.00077', '0.02907', '0.05266', '-0.02713', '0.07532', '0.00110', '-0.01085', '0.00910', '0.02147', '-0.01228', '0.01050']
Epoch 65: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00011 | Gamma1: ['2.34448', '2.34145', '2.32335', '2.25233', '2.22603', '2.23835', '2.33929', '2.37354', '2.35637', '2.28946', '2.29015', '2.28408', '2.31383'] | Gamma1 Grad: ['-0.02060', '-0.01134', '0.01301', '-0.05510', '-0.02321', '0.04956', '0.02987', '0.01277', '-0.00728', '-0.00220', '-0.00696', '-0.00144', '0.01373']
Epoch 66: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['2.34705', '2.34525', '2.32242', '2.26399', '2.20505', '2.24021', '2.33403', '2.36447', '2.35226', '2.29685', '2.29216', '2.28370', '2.29557'] | Gamma1 Grad: ['-0.03565', '-0.00484', '0.02399', '0.04628', '-0.00125', '0.15093', '-0.02599', '-0.04741', '0.00022', '0.00168', '0.00648', '-0.03109', '0.02247']
Epoch 67: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00007 | Gamma1: ['2.34853', '2.35157', '2.30901', '2.24620', '2.19939', '2.25282', '2.33075', '2.37826', '2.35849', '2.30701', '2.29856', '2.29668', '2.30730'] | Gamma1 Grad: ['0.00602', '-0.01909', '0.04110', '-0.02152', '-0.11516', '0.02759', '0.04663', '-0.02437', '-0.03166', '0.00946', '-0.00113', '-0.03146', '-0.02115']
Epoch 68: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00006 | Gamma1: ['2.35617', '2.34625', '2.30484', '2.24818', '2.21115', '2.24077', '2.34615', '2.37601', '2.34002', '2.29357', '2.30842', '2.28527', '2.29965'] | Gamma1 Grad: ['-0.01673', '-0.02216', '-0.01945', '-0.00879', '0.03962', '-0.02339', '0.02227', '-0.00039', '0.01927', '-0.01043', '-0.00089', '-0.02501', '-0.01900']
Epoch 69: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00005 | Gamma1: ['2.34374', '2.36230', '2.30274', '2.26290', '2.21722', '2.23889', '2.34185', '2.36637', '2.34707', '2.30254', '2.29897', '2.28783', '2.29481'] | Gamma1 Grad: ['0.02291', '0.01991', '-0.00269', '0.01775', '0.06837', '0.00902', '-0.05792', '-0.03055', '0.01820', '0.00697', '0.00976', '0.02784', '0.05155']
Epoch 70: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.33040', '2.35568', '2.29845', '2.25524', '2.21173', '2.24485', '2.34255', '2.37894', '2.35169', '2.30371', '2.30128', '2.28317', '2.29449'] | Gamma1 Grad: ['-0.00673', '-0.00504', '0.01475', '0.02202', '0.02480', '0.03630', '-0.03202', '0.00934', '-0.01754', '-0.01312', '-0.01848', '-0.02131', '-0.05221']
Epoch 71: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.33650', '2.35785', '2.31703', '2.23784', '2.21087', '2.21964', '2.35259', '2.37041', '2.34343', '2.31342', '2.29734', '2.28849', '2.32315'] | Gamma1 Grad: ['-0.03382', '-0.05392', '0.02174', '0.10180', '0.17945', '0.02444', '-0.00269', '0.01242', '-0.01637', '0.00081', '0.02905', '-0.00123', '0.04090']
Epoch 72: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['2.32705', '2.35701', '2.29162', '2.23719', '2.20097', '2.21225', '2.35788', '2.34405', '2.33679', '2.31208', '2.30366', '2.30532', '2.31172'] | Gamma1 Grad: ['-0.01483', '0.01953', '0.00344', '-0.00641', '-0.01195', '0.03780', '-0.06904', '0.03133', '-0.00951', '0.00625', '0.00422', '-0.01244', '0.00811']
Epoch 73: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.34055', '2.33178', '2.27949', '2.21739', '2.20429', '2.18472', '2.33770', '2.33604', '2.34406', '2.29172', '2.28754', '2.28271', '2.28282'] | Gamma1 Grad: ['0.02220', '0.04089', '-0.00863', '-0.02758', '0.06600', '-0.02789', '0.02314', '-0.01992', '-0.00068', '-0.00804', '-0.00210', '0.00270', '0.02976']
Epoch 74: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.32486', '2.31235', '2.25484', '2.26100', '2.20161', '2.21188', '2.32719', '2.34586', '2.34715', '2.30347', '2.30255', '2.28386', '2.30532'] | Gamma1 Grad: ['0.02230', '-0.01328', '0.00595', '0.02938', '-0.03463', '0.03049', '-0.00900', '-0.01465', '0.01751', '-0.00382', '0.00903', '0.02014', '-0.02451']
Epoch 75: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['2.33243', '2.37862', '2.28675', '2.25819', '2.22310', '2.20693', '2.36660', '2.37430', '2.31969', '2.31439', '2.28751', '2.27317', '2.30387'] | Gamma1 Grad: ['0.02394', '0.04803', '-0.03397', '-0.05781', '0.04181', '0.05367', '0.02485', '-0.07534', '-0.01711', '-0.00222', '0.00044', '-0.01912', '-0.07301']
Epoch 76: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['2.32411', '2.36590', '2.30808', '2.27412', '2.22297', '2.21886', '2.34437', '2.35856', '2.34479', '2.31267', '2.27119', '2.29319', '2.28895'] | Gamma1 Grad: ['0.02780', '0.03366', '-0.06936', '-0.18437', '0.05413', '-0.20879', '-0.02655', '-0.01266', '0.01236', '0.01206', '0.02092', '0.02600', '-0.03893']
Epoch 77: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00147 | Gamma1: ['2.32947', '2.34059', '2.30118', '2.25471', '2.18798', '2.20290', '2.31187', '2.37009', '2.32777', '2.30963', '2.28350', '2.28460', '2.28846'] | Gamma1 Grad: ['0.00628', '0.00476', '-0.00401', '-0.02345', '0.04983', '-0.00104', '0.00379', '0.01137', '-0.00029', '-0.00137', '0.00210', '0.00722', '0.02729']
Epoch 78: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['2.32930', '2.34869', '2.30166', '2.24094', '2.20193', '2.19221', '2.32163', '2.37681', '2.33441', '2.30188', '2.28336', '2.27995', '2.27768'] | Gamma1 Grad: ['0.00183', '-0.01371', '0.00209', '-0.03568', '-0.04127', '-0.00333', '0.01648', '0.01322', '-0.00352', '0.00452', '-0.00332', '-0.00310', '0.01067']
Epoch 79: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00146 | Gamma1: ['2.35246', '2.32160', '2.29338', '2.29473', '2.18088', '2.20979', '2.36053', '2.37027', '2.32511', '2.29780', '2.29553', '2.28830', '2.30632'] | Gamma1 Grad: ['0.05242', '-0.07424', '-0.09218', '0.11534', '0.09418', '0.02635', '0.06489', '0.04835', '-0.02299', '0.00217', '0.01198', '-0.00658', '0.04265']
Epoch 80: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00144 | Gamma1: ['2.33499', '2.32864', '2.30297', '2.24798', '2.21001', '2.20044', '2.31897', '2.35524', '2.32230', '2.32375', '2.31563', '2.28656', '2.27338'] | Gamma1 Grad: ['-0.01135', '-0.01974', '0.01239', '-0.02979', '-0.01178', '-0.00157', '0.02593', '0.02431', '-0.00710', '-0.00139', '0.00189', '-0.00732', '0.01869']
Epoch 81: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00143 | Gamma1: ['2.33428', '2.32692', '2.31261', '2.21155', '2.20703', '2.19318', '2.31448', '2.30818', '2.30671', '2.32962', '2.32443', '2.27475', '2.25773'] | Gamma1 Grad: ['-0.00345', '0.01262', '0.01063', '0.00097', '0.06173', '-0.01821', '-0.00851', '0.04681', '-0.00371', '0.01184', '0.00197', '0.01366', '0.03480']
Epoch 82: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00142 | Gamma1: ['2.30934', '2.32389', '2.30535', '2.21426', '2.20921', '2.21711', '2.30243', '2.34092', '2.30618', '2.31484', '2.32774', '2.28517', '2.28796'] | Gamma1 Grad: ['-0.06974', '0.02232', '0.03015', '-0.01033', '0.15344', '-0.05574', '-0.00826', '0.01039', '-0.00567', '0.00827', '0.00776', '-0.01170', '0.03589']
Epoch 83: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00141 | Gamma1: ['2.32146', '2.32338', '2.31360', '2.20806', '2.21245', '2.24527', '2.32177', '2.33423', '2.32225', '2.30729', '2.31951', '2.27086', '2.28730'] | Gamma1 Grad: ['0.00479', '0.04230', '-0.00525', '-0.00101', '0.03077', '-0.01864', '0.03900', '0.01035', '-0.00678', '0.00510', '-0.00032', '-0.00000', '0.00529']
Epoch 84: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00139 | Gamma1: ['2.29505', '2.29977', '2.30234', '2.25000', '2.20127', '2.24628', '2.30390', '2.31463', '2.32155', '2.31423', '2.31712', '2.29424', '2.30950'] | Gamma1 Grad: ['-0.01214', '0.00424', '0.06620', '0.09155', '0.04289', '0.06797', '0.06087', '-0.01479', '-0.00079', '-0.00283', '0.00442', '-0.00849', '0.00366']
Epoch 85: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00138 | Gamma1: ['2.33041', '2.31472', '2.31387', '2.23855', '2.20843', '2.26316', '2.28767', '2.30444', '2.31586', '2.30584', '2.32355', '2.28080', '2.29124'] | Gamma1 Grad: ['0.00044', '-0.02454', '0.03787', '0.01538', '-0.02382', '0.01349', '0.02722', '0.01075', '-0.01553', '0.00758', '0.00994', '0.01975', '0.05498']
Epoch 86: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00136 | Gamma1: ['2.32195', '2.31119', '2.29008', '2.23608', '2.22518', '2.24438', '2.29117', '2.31137', '2.30694', '2.31649', '2.31846', '2.28819', '2.31627'] | Gamma1 Grad: ['-0.02943', '-0.04010', '0.00113', '0.16187', '-0.10894', '-0.03956', '0.00558', '0.02125', '-0.03108', '0.03364', '0.01695', '0.00879', '0.10241']
Epoch 87: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00134 | Gamma1: ['2.31204', '2.30759', '2.30864', '2.23419', '2.21386', '2.19735', '2.31278', '2.30115', '2.30977', '2.30717', '2.31321', '2.28518', '2.29324'] | Gamma1 Grad: ['0.04784', '0.00325', '-0.00459', '-0.00794', '-0.07778', '0.00698', '-0.02019', '-0.02109', '0.01251', '0.00291', '0.00808', '-0.00375', '0.00747']
Epoch 88: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00133 | Gamma1: ['2.30982', '2.31458', '2.29469', '2.25588', '2.22774', '2.23544', '2.28456', '2.31175', '2.31335', '2.29385', '2.30183', '2.27872', '2.30096'] | Gamma1 Grad: ['0.00240', '0.00207', '-0.00031', '-0.00411', '-0.02655', '0.00522', '-0.00897', '-0.00845', '0.00546', '0.00115', '0.00119', '0.00503', '-0.00582']
Epoch 89: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00131 | Gamma1: ['2.31031', '2.30138', '2.30030', '2.23392', '2.25108', '2.23548', '2.28383', '2.30395', '2.32497', '2.30542', '2.32977', '2.27554', '2.28972'] | Gamma1 Grad: ['0.00163', '-0.03560', '-0.01398', '0.05603', '-0.02279', '-0.04844', '-0.00876', '-0.01001', '-0.01212', '0.00548', '0.01025', '-0.01819', '0.01129']
Epoch 90: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00129 | Gamma1: ['2.32180', '2.30420', '2.30250', '2.22995', '2.22675', '2.24873', '2.29140', '2.32095', '2.31854', '2.30678', '2.31433', '2.29561', '2.32905'] | Gamma1 Grad: ['0.01791', '-0.06773', '-0.04110', '-0.04439', '-0.17373', '-0.03317', '-0.11779', '-0.09724', '0.08825', '-0.01275', '-0.01339', '-0.03157', '0.01689']
Epoch 91: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00127 | Gamma1: ['2.32365', '2.31863', '2.30394', '2.22895', '2.22960', '2.26024', '2.27550', '2.32195', '2.30740', '2.30367', '2.31543', '2.30378', '2.31526'] | Gamma1 Grad: ['-0.00936', '-0.00467', '0.02166', '-0.06407', '-0.05552', '-0.07595', '-0.01093', '-0.01847', '-0.01317', '-0.00170', '0.00400', '-0.01983', '0.01126']
Epoch 92: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00125 | Gamma1: ['2.30658', '2.32551', '2.27149', '2.25128', '2.22924', '2.24928', '2.31069', '2.31717', '2.31256', '2.30834', '2.31218', '2.29844', '2.30099'] | Gamma1 Grad: ['-0.01543', '-0.05524', '0.08265', '-0.11562', '0.09623', '0.01825', '-0.18824', '-0.06490', '-0.01972', '-0.00271', '0.02352', '0.00316', '0.04389']
Epoch 93: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00122 | Gamma1: ['2.31317', '2.31647', '2.28347', '2.26543', '2.23113', '2.23756', '2.27434', '2.29305', '2.31454', '2.29568', '2.30738', '2.29669', '2.30091'] | Gamma1 Grad: ['-0.02247', '0.00063', '-0.00640', '-0.00118', '-0.12566', '0.01559', '0.00547', '0.00726', '0.02023', '0.00436', '-0.00508', '-0.00007', '0.02656']
Epoch 94: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00120 | Gamma1: ['2.29776', '2.31196', '2.27702', '2.26324', '2.22435', '2.24529', '2.28613', '2.31841', '2.31366', '2.29318', '2.30451', '2.29276', '2.30367'] | Gamma1 Grad: ['0.00210', '-0.00327', '0.00189', '-0.01208', '0.01262', '0.00361', '0.00202', '0.00367', '-0.00164', '0.00067', '-0.00025', '0.00275', '-0.00079']
Epoch 95: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00118 | Gamma1: ['2.29891', '2.31636', '2.27354', '2.23902', '2.22547', '2.25799', '2.25819', '2.30480', '2.30770', '2.28727', '2.30301', '2.28746', '2.29918'] | Gamma1 Grad: ['0.02423', '0.00801', '-0.03469', '-0.01647', '-0.03442', '0.03597', '-0.02485', '-0.04785', '0.00914', '0.00015', '0.00463', '0.01998', '0.00251']
Epoch 96: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00115 | Gamma1: ['2.30064', '2.30912', '2.28862', '2.25084', '2.23403', '2.24406', '2.27509', '2.29544', '2.32214', '2.29390', '2.29963', '2.29528', '2.29763'] | Gamma1 Grad: ['0.00496', '-0.00576', '-0.00057', '-0.01999', '-0.01196', '0.01385', '0.00883', '-0.00822', '-0.00384', '0.00063', '-0.00132', '-0.00286', '0.00332']
Epoch 97: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00113 | Gamma1: ['2.29583', '2.30514', '2.28704', '2.25465', '2.22568', '2.26580', '2.29857', '2.30728', '2.30846', '2.29740', '2.30294', '2.28799', '2.30820'] | Gamma1 Grad: ['-0.00580', '0.00144', '-0.01729', '0.03262', '-0.01940', '0.04562', '-0.00211', '0.00990', '-0.00832', '0.01570', '-0.00354', '-0.00419', '-0.01571']
Epoch 98: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00110 | Gamma1: ['2.28631', '2.28372', '2.31354', '2.23033', '2.22959', '2.28134', '2.28235', '2.31838', '2.29211', '2.30131', '2.30895', '2.28490', '2.30001'] | Gamma1 Grad: ['0.02487', '0.00915', '0.01722', '0.01382', '0.02878', '0.03465', '0.00319', '-0.01148', '-0.00968', '0.00278', '0.00521', '-0.00032', '-0.00678']
Epoch 99: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00108 | Gamma1: ['2.30138', '2.28910', '2.29034', '2.25392', '2.25188', '2.25556', '2.28232', '2.30297', '2.30385', '2.30087', '2.31053', '2.30251', '2.31550'] | Gamma1 Grad: ['-0.04949', '0.01305', '0.00887', '0.02251', '0.10676', '-0.05104', '-0.02615', '0.01612', '0.01918', '-0.00524', '-0.00654', '-0.02511', '0.00051']
