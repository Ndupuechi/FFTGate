Epoch 0: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['1.50000', '1.50000'] | Gamma1 Grad: ['None', 'None']
Epoch 1: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['1.78499', '1.78503'] | Gamma1 Grad: ['-0.70698', '-0.70717']
Epoch 2: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['2.06584', '2.06588'] | Gamma1 Grad: ['-0.70709', '-0.70706']
Epoch 3: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00119 | Gamma1: ['2.33461', '2.33467'] | Gamma1 Grad: ['-0.70710', '-0.70699']
Epoch 4: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00099 | Gamma1: ['2.58459', '2.58465'] | Gamma1 Grad: ['-0.70715', '-0.70699']
Epoch 5: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00076 | Gamma1: ['2.81089', '2.81095'] | Gamma1 Grad: ['-0.70714', '-0.70703']
Epoch 6: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00052 | Gamma1: ['3.01096', '3.01102'] | Gamma1 Grad: ['-0.70711', '-0.70695']
Epoch 7: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00032 | Gamma1: ['3.18478', '3.18483'] | Gamma1 Grad: ['-0.70710', '-0.70704']
Epoch 8: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00015 | Gamma1: ['3.33492', '3.33497'] | Gamma1 Grad: ['-0.70701', '-0.70702']
Epoch 9: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00005 | Gamma1: ['3.46628', '3.46633'] | Gamma1 Grad: ['-0.70695', '-0.70706']
Epoch 10: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['3.58557', '3.58562'] | Gamma1 Grad: ['-0.70703', '-0.70703']
Epoch 11: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['3.87055', '3.87061'] | Gamma1 Grad: ['-0.70704', '-0.70702']
Epoch 12: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['4.15448', '4.15455'] | Gamma1 Grad: ['-0.70709', '-0.70706']
Epoch 13: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['4.43530', '4.43538'] | Gamma1 Grad: ['-0.70707', '-0.70706']
Epoch 14: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['4.71101', '4.71109'] | Gamma1 Grad: ['-0.70706', '-0.70706']
Epoch 15: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00128 | Gamma1: ['4.97976', '4.97984'] | Gamma1 Grad: ['-0.70706', '-0.70701']
Epoch 16: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00119 | Gamma1: ['5.23987', '5.23995'] | Gamma1 Grad: ['-0.70703', '-0.70704']
Epoch 17: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00109 | Gamma1: ['5.48987', '5.48995'] | Gamma1 Grad: ['-0.70702', '-0.70707']
Epoch 18: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00099 | Gamma1: ['5.72851', '5.72859'] | Gamma1 Grad: ['-0.70695', '-0.70689']
Epoch 19: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00087 | Gamma1: ['5.95481', '5.95489'] | Gamma1 Grad: ['-0.70698', '-0.70697']
Epoch 20: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00076 | Gamma1: ['6.16769', '6.16777'] | Gamma1 Grad: ['-0.70518', '-0.70518']
Epoch 21: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00064 | Gamma1: ['6.36750', '6.36758'] | Gamma1 Grad: ['-0.70599', '-0.70599']
Epoch 22: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00052 | Gamma1: ['6.55411', '6.55420'] | Gamma1 Grad: ['-0.70592', '-0.70592']
Epoch 23: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00042 | Gamma1: ['6.72779', '6.72788'] | Gamma1 Grad: ['-0.70504', '-0.70504']
Epoch 24: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00032 | Gamma1: ['6.88920', '6.88929'] | Gamma1 Grad: ['-0.70625', '-0.70625']
Epoch 25: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00023 | Gamma1: ['7.03928', '7.03937'] | Gamma1 Grad: ['-0.70608', '-0.70608']
Epoch 26: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00015 | Gamma1: ['7.17920', '7.17929'] | Gamma1 Grad: ['-0.70629', '-0.70629']
Epoch 27: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00009 | Gamma1: ['7.31048', '7.31057'] | Gamma1 Grad: ['-0.70384', '-0.70384']
Epoch 28: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00005 | Gamma1: ['7.43481', '7.43490'] | Gamma1 Grad: ['-0.70607', '-0.70607']
Epoch 29: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00002 | Gamma1: ['7.55404', '7.55413'] | Gamma1 Grad: ['-0.70567', '-0.70567']
Epoch 30: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['7.67017', '7.67026'] | Gamma1 Grad: ['-0.70609', '-0.70609']
Epoch 31: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00150 | Gamma1: ['7.95509', '7.95518'] | Gamma1 Grad: ['-0.70615', '-0.70615']
Epoch 32: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00149 | Gamma1: ['8.23971', '8.23981'] | Gamma1 Grad: ['-0.70619', '-0.70618']
Epoch 33: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00148 | Gamma1: ['8.52358', '8.52368'] | Gamma1 Grad: ['-0.70602', '-0.70602']
Epoch 34: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00146 | Gamma1: ['8.80614', '8.80624'] | Gamma1 Grad: ['-0.70271', '-0.70271']
Epoch 35: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00144 | Gamma1: ['9.08566', '9.08576'] | Gamma1 Grad: ['-0.69449', '-0.69449']
Epoch 36: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00142 | Gamma1: ['9.36301', '9.36311'] | Gamma1 Grad: ['-0.70128', '-0.70128']
Epoch 37: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00139 | Gamma1: ['9.63776', '9.63785'] | Gamma1 Grad: ['-0.70231', '-0.70231']
Epoch 38: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00136 | Gamma1: ['9.90940', '9.90950'] | Gamma1 Grad: ['-0.70341', '-0.70341']
Epoch 39: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00132 | Gamma1: ['10.17746', '10.17756'] | Gamma1 Grad: ['-0.68915', '-0.68914']
Epoch 40: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00128 | Gamma1: ['10.44150', '10.44160'] | Gamma1 Grad: ['-0.69309', '-0.69309']
Epoch 41: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00124 | Gamma1: ['10.70102', '10.70112'] | Gamma1 Grad: ['-0.70277', '-0.70277']
Epoch 42: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00119 | Gamma1: ['10.95571', '10.95581'] | Gamma1 Grad: ['-0.70246', '-0.70246']
Epoch 43: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00114 | Gamma1: ['11.20528', '11.20538'] | Gamma1 Grad: ['-0.70286', '-0.70286']
Epoch 44: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00109 | Gamma1: ['11.44936', '11.44946'] | Gamma1 Grad: ['-0.68798', '-0.68798']
Epoch 45: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00104 | Gamma1: ['11.68768', '11.68778'] | Gamma1 Grad: ['-0.70332', '-0.70332']
Epoch 46: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00099 | Gamma1: ['11.92000', '11.92009'] | Gamma1 Grad: ['-0.70287', '-0.70287']
Epoch 47: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00093 | Gamma1: ['12.14601', '12.14610'] | Gamma1 Grad: ['-0.70281', '-0.70281']
Epoch 48: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00087 | Gamma1: ['12.36569', '12.36578'] | Gamma1 Grad: ['-0.70341', '-0.70341']
Epoch 49: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00081 | Gamma1: ['12.57886', '12.57895'] | Gamma1 Grad: ['-0.69204', '-0.69204']
