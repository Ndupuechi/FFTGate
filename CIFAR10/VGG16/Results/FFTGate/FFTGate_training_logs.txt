Epoch 0: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.01000 | Gamma1: ['1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000', '1.50000'] | Gamma1 Grad: ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']
Epoch 1: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00976 | Gamma1: ['2.23929', '2.24499', '2.23718', '2.22377', '2.22358', '2.22272', '2.21742', '2.21697', '2.21839', '2.21551', '2.21691', '2.21540', '2.21192'] | Gamma1 Grad: ['0.00104', '0.00616', '0.00995', '0.00185', '0.00072', '-0.00042', '-0.00106', '-0.00287', '-0.00052', '-0.00293', '-0.00061', '-0.00274', '-0.00899']
Epoch 2: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00905 | Gamma1: ['2.28412', '2.30163', '2.29018', '2.28077', '2.28458', '2.27740', '2.27620', '2.27581', '2.27600', '2.27829', '2.27139', '2.27247', '2.27573'] | Gamma1 Grad: ['-0.00144', '-0.00050', '-0.00648', '-0.00230', '0.00079', '-0.00303', '-0.00483', '-0.00327', '-0.00347', '-0.00312', '-0.00382', '-0.00753', '0.00212']
Epoch 3: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00795 | Gamma1: ['2.28339', '2.28740', '2.29057', '2.27466', '2.28516', '2.27751', '2.27494', '2.27825', '2.27501', '2.27121', '2.27623', '2.26493', '2.26345'] | Gamma1 Grad: ['-0.00343', '-0.00691', '0.00523', '0.00296', '0.00168', '0.00093', '-0.00014', '0.00192', '-0.00292', '-0.00038', '-0.00450', '-0.00033', '0.00285']
Epoch 4: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00656 | Gamma1: ['2.28471', '2.29016', '2.27998', '2.27208', '2.28532', '2.28494', '2.28152', '2.28050', '2.27952', '2.28014', '2.28328', '2.27162', '2.27345'] | Gamma1 Grad: ['0.00756', '-0.00230', '0.00973', '-0.00226', '0.00248', '0.00353', '0.00190', '0.00171', '0.00153', '0.00113', '0.00556', '0.00240', '0.00523']
Epoch 5: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00502 | Gamma1: ['2.30000', '2.30059', '2.30005', '2.27606', '2.28274', '2.28153', '2.27943', '2.28083', '2.27522', '2.27576', '2.26973', '2.27940', '2.28085'] | Gamma1 Grad: ['0.00405', '0.00170', '0.00332', '0.00560', '-0.00217', '0.00132', '0.00147', '0.00228', '0.00279', '-0.00014', '0.00272', '0.00605', '0.00131']
Epoch 6: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00349 | Gamma1: ['2.28999', '2.28538', '2.29299', '2.26775', '2.28476', '2.28907', '2.27970', '2.28545', '2.29000', '2.28449', '2.28505', '2.28111', '2.28207'] | Gamma1 Grad: ['0.00170', '0.00490', '0.00726', '-0.00141', '-0.00430', '-0.00129', '0.00314', '0.00048', '0.00686', '0.00737', '0.00842', '0.00463', '0.00888']
Epoch 7: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00210 | Gamma1: ['2.29661', '2.29196', '2.29221', '2.27847', '2.28183', '2.28100', '2.28341', '2.28909', '2.29170', '2.29160', '2.29362', '2.28245', '2.28442'] | Gamma1 Grad: ['0.00300', '0.00182', '-0.00552', '0.00160', '0.00040', '0.00020', '0.00489', '0.00172', '0.00255', '0.00605', '0.00379', '0.00217', '-0.00257']
Epoch 8: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.29796', '2.28723', '2.28225', '2.28066', '2.28457', '2.28626', '2.27569', '2.28159', '2.27763', '2.27513', '2.27722', '2.27504', '2.27042'] | Gamma1 Grad: ['0.00149', '0.00182', '-0.00134', '0.00016', '0.00039', '0.00091', '0.00075', '-0.00187', '-0.00236', '-0.00355', '-0.00400', '0.00219', '-0.00097']
Epoch 9: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00029 | Gamma1: ['2.29892', '2.29850', '2.29736', '2.28052', '2.28679', '2.28824', '2.28078', '2.28509', '2.28391', '2.28190', '2.28176', '2.27702', '2.27809'] | Gamma1 Grad: ['-0.00146', '0.00259', '0.00323', '0.00430', '0.00249', '0.00290', '0.00232', '0.00223', '0.00220', '0.00384', '-0.00004', '-0.00690', '0.00402']
Epoch 10: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.01000 | Gamma1: ['2.29837', '2.29581', '2.29413', '2.28124', '2.29052', '2.28624', '2.28000', '2.28531', '2.28313', '2.28335', '2.27830', '2.27671', '2.28085'] | Gamma1 Grad: ['-0.00002', '-0.00201', '0.00043', '-0.00166', '-0.00273', '-0.00073', '-0.00007', '-0.00210', '0.00114', '0.00029', '0.00328', '-0.00218', '0.00305']
Epoch 11: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00994 | Gamma1: ['2.29054', '2.31543', '2.30688', '2.28251', '2.27536', '2.29133', '2.27824', '2.28132', '2.28289', '2.27163', '2.27425', '2.27694', '2.27770'] | Gamma1 Grad: ['-0.00164', '0.00004', '0.00538', '0.00063', '-0.00194', '0.00514', '-0.00065', '-0.00063', '-0.00031', '-0.00241', '-0.00287', '-0.00187', '0.00069']
Epoch 12: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00976 | Gamma1: ['2.29609', '2.28253', '2.30168', '2.28415', '2.28792', '2.28390', '2.29294', '2.28482', '2.27736', '2.28036', '2.27931', '2.28809', '2.27099'] | Gamma1 Grad: ['0.00332', '0.00756', '0.00233', '0.00026', '-0.00341', '0.00110', '-0.00106', '-0.00240', '-0.00094', '-0.00248', '-0.00305', '0.00090', '0.00189']
Epoch 13: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00946 | Gamma1: ['2.30475', '2.28611', '2.30716', '2.28693', '2.29307', '2.27492', '2.26376', '2.27672', '2.29359', '2.28302', '2.28798', '2.28480', '2.27159'] | Gamma1 Grad: ['0.00129', '0.00654', '0.00110', '-0.00153', '0.00114', '-0.00079', '-0.00146', '0.00392', '0.00645', '0.00429', '0.01021', '0.00733', '-0.00557']
Epoch 14: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00905 | Gamma1: ['2.30356', '2.29496', '2.27607', '2.27977', '2.27379', '2.28018', '2.27066', '2.26466', '2.26454', '2.27818', '2.26510', '2.26767', '2.29347'] | Gamma1 Grad: ['0.00436', '0.00632', '-0.00943', '0.00190', '0.00042', '-0.00356', '0.00033', '0.00093', '0.00296', '0.00168', '0.01026', '-0.00260', '-0.00149']
Epoch 15: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00854 | Gamma1: ['2.30352', '2.28919', '2.28711', '2.27915', '2.26762', '2.28766', '2.28045', '2.28728', '2.27898', '2.28522', '2.29764', '2.28604', '2.28186'] | Gamma1 Grad: ['0.01117', '-0.00142', '0.00457', '0.00177', '0.00398', '0.00224', '-0.00087', '-0.00181', '-0.00202', '-0.00111', '-0.00451', '0.00212', '0.00329']
Epoch 16: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00795 | Gamma1: ['2.28958', '2.29009', '2.28285', '2.28060', '2.27534', '2.27985', '2.28321', '2.28235', '2.28198', '2.27699', '2.26158', '2.27410', '2.29369'] | Gamma1 Grad: ['-0.00517', '0.00001', '0.00813', '-0.00759', '0.00263', '0.00337', '-0.00095', '0.00166', '0.00001', '-0.00189', '-0.00599', '-0.00042', '0.00362']
Epoch 17: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00728 | Gamma1: ['2.27575', '2.30923', '2.27699', '2.28019', '2.28184', '2.30487', '2.27745', '2.27880', '2.28803', '2.27626', '2.29326', '2.26731', '2.29436'] | Gamma1 Grad: ['-0.00084', '0.00778', '-0.00572', '-0.00115', '0.00065', '0.00668', '-0.00211', '-0.00235', '-0.00253', '-0.00341', '-0.00157', '0.00115', '0.00565']
Epoch 18: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00656 | Gamma1: ['2.27218', '2.30420', '2.28056', '2.28193', '2.28557', '2.30591', '2.28088', '2.26902', '2.27702', '2.27936', '2.27709', '2.27241', '2.29591'] | Gamma1 Grad: ['0.00220', '0.00437', '-0.00231', '-0.00213', '0.00226', '-0.00041', '0.00095', '0.00007', '-0.00582', '-0.00000', '-0.00527', '-0.00204', '0.00636']
Epoch 19: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00580 | Gamma1: ['2.29105', '2.27951', '2.28475', '2.28006', '2.29124', '2.28405', '2.28645', '2.29687', '2.29648', '2.28694', '2.28727', '2.28064', '2.27865'] | Gamma1 Grad: ['0.01165', '0.00380', '-0.00267', '0.00497', '-0.00323', '-0.00176', '0.00741', '0.00340', '0.00274', '0.00186', '-0.00485', '0.00004', '0.00130']
Epoch 20: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00502 | Gamma1: ['2.29659', '2.28035', '2.28790', '2.26881', '2.29584', '2.28085', '2.27313', '2.28387', '2.27772', '2.28192', '2.27043', '2.27719', '2.27839'] | Gamma1 Grad: ['-0.00269', '-0.00094', '-0.00694', '-0.00274', '0.00191', '0.00224', '-0.00331', '-0.00287', '-0.00563', '-0.00352', '-0.01150', '0.00148', '0.00125']
Epoch 21: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00425 | Gamma1: ['2.26811', '2.27696', '2.26759', '2.28074', '2.32221', '2.27548', '2.27618', '2.28314', '2.26655', '2.27325', '2.26505', '2.27127', '2.27487'] | Gamma1 Grad: ['0.00263', '0.00042', '-0.00497', '0.00190', '0.00681', '-0.00216', '0.00051', '-0.00155', '-0.00356', '-0.00480', '-0.00796', '-0.00150', '-0.00389']
Epoch 22: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00349 | Gamma1: ['2.27892', '2.29473', '2.28677', '2.28717', '2.29322', '2.27794', '2.27098', '2.28126', '2.27430', '2.27495', '2.27639', '2.27489', '2.27938'] | Gamma1 Grad: ['-0.00379', '0.00268', '-0.01307', '0.00656', '-0.00394', '-0.00525', '-0.00014', '0.00213', '0.00101', '0.00268', '-0.00052', '-0.00127', '0.00583']
Epoch 23: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00277 | Gamma1: ['2.28114', '2.29497', '2.29241', '2.28641', '2.28759', '2.28569', '2.28066', '2.27798', '2.28168', '2.28223', '2.27641', '2.27764', '2.27970'] | Gamma1 Grad: ['-0.00529', '-0.00668', '-0.00467', '0.00911', '0.00324', '-0.00319', '-0.00171', '0.00167', '0.00262', '0.00208', '0.00527', '0.00090', '0.00385']
Epoch 24: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00210 | Gamma1: ['2.28235', '2.27853', '2.29391', '2.28164', '2.28495', '2.29138', '2.28343', '2.28250', '2.28288', '2.28006', '2.27229', '2.27788', '2.28533'] | Gamma1 Grad: ['-0.00377', '0.01510', '-0.04433', '0.00115', '-0.00636', '-0.01806', '0.00502', '0.00615', '0.01111', '0.00322', '0.00384', '0.00203', '-0.00743']
Epoch 25: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00151 | Gamma1: ['2.29336', '2.28815', '2.29051', '2.28518', '2.28967', '2.27896', '2.28546', '2.29248', '2.28862', '2.28639', '2.26956', '2.28067', '2.28448'] | Gamma1 Grad: ['0.00901', '0.00303', '0.01173', '0.00013', '-0.01284', '-0.00444', '-0.00048', '0.00236', '0.00456', '0.00099', '0.00632', '-0.00689', '0.00287']
Epoch 26: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.27933', '2.28768', '2.28302', '2.29111', '2.29084', '2.28286', '2.28278', '2.28806', '2.28170', '2.27851', '2.27834', '2.28024', '2.28361'] | Gamma1 Grad: ['-0.01546', '-0.00749', '-0.00170', '0.00462', '0.00158', '-0.00383', '0.00523', '0.00113', '-0.00015', '0.00340', '0.00052', '0.00227', '-0.00138']
Epoch 27: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00059 | Gamma1: ['2.28585', '2.28906', '2.29096', '2.28367', '2.28893', '2.28609', '2.28289', '2.28271', '2.28260', '2.27880', '2.27932', '2.27771', '2.27909'] | Gamma1 Grad: ['-0.01218', '-0.00456', '-0.00340', '-0.00437', '-0.00133', '-0.00303', '0.00223', '0.00234', '0.00168', '0.00267', '0.00301', '0.00095', '0.00089']
Epoch 28: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00029 | Gamma1: ['2.28787', '2.29815', '2.28533', '2.28654', '2.28703', '2.28093', '2.28256', '2.28239', '2.27941', '2.28177', '2.27890', '2.28044', '2.28043'] | Gamma1 Grad: ['-0.00419', '0.00029', '-0.01629', '0.00526', '0.00029', '0.00406', '-0.00186', '-0.00133', '-0.00306', '-0.00215', '-0.00350', '-0.00647', '0.00364']
Epoch 29: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00011 | Gamma1: ['2.28968', '2.28363', '2.28456', '2.28180', '2.28377', '2.28731', '2.28511', '2.28973', '2.28573', '2.28417', '2.28381', '2.27986', '2.27582'] | Gamma1 Grad: ['0.00497', '-0.00139', '-0.00296', '0.00120', '0.00186', '-0.00468', '0.00113', '0.00242', '0.00174', '0.00223', '-0.00068', '0.00206', '-0.00344']
Epoch 30: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.01000 | Gamma1: ['2.28222', '2.28600', '2.28304', '2.28504', '2.28042', '2.28330', '2.28150', '2.28207', '2.28008', '2.27981', '2.28091', '2.27957', '2.27891'] | Gamma1 Grad: ['0.00728', '0.01140', '0.01581', '-0.00412', '0.00094', '-0.00238', '0.00469', '0.00263', '-0.00048', '0.00219', '0.00917', '-0.00027', '-0.00202']
Epoch 31: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00998 | Gamma1: ['2.27152', '2.31508', '2.29364', '2.30977', '2.28689', '2.30741', '2.30961', '2.28659', '2.29416', '2.29165', '2.26241', '2.28830', '2.28961'] | Gamma1 Grad: ['-0.00051', '0.00856', '0.00898', '-0.00563', '0.01403', '0.00676', '0.00218', '0.00293', '0.00170', '-0.00061', '-0.00143', '-0.00027', '0.00091']
Epoch 32: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00994 | Gamma1: ['2.28487', '2.27453', '2.26242', '2.28009', '2.28210', '2.29617', '2.29143', '2.28407', '2.28066', '2.28291', '2.26873', '2.27922', '2.30167'] | Gamma1 Grad: ['0.00631', '0.00333', '-0.01913', '-0.00182', '0.00605', '-0.00898', '0.00154', '0.00280', '0.00312', '0.00304', '0.00116', '0.00655', '-0.00353']
Epoch 33: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00986 | Gamma1: ['2.28592', '2.28783', '2.26635', '2.30077', '2.29367', '2.29921', '2.27922', '2.29119', '2.28678', '2.27946', '2.26620', '2.27870', '2.28508'] | Gamma1 Grad: ['0.00272', '-0.00029', '0.00367', '-0.00032', '0.00644', '0.00080', '-0.00067', '0.00259', '0.00304', '0.00099', '0.00387', '0.00145', '0.00275']
Epoch 34: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00976 | Gamma1: ['2.29818', '2.28293', '2.28744', '2.28785', '2.30844', '2.30801', '2.27579', '2.28150', '2.26648', '2.27126', '2.29016', '2.27707', '2.29067'] | Gamma1 Grad: ['-0.00092', '-0.00492', '-0.01059', '-0.00751', '0.00592', '-0.00414', '-0.00164', '0.00224', '-0.00076', '-0.00145', '0.00061', '0.00098', '-0.00180']
Epoch 35: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00962 | Gamma1: ['2.26623', '2.30513', '2.26298', '2.28011', '2.28965', '2.28806', '2.28429', '2.28091', '2.28531', '2.28002', '2.27582', '2.27344', '2.27999'] | Gamma1 Grad: ['-0.00162', '0.01228', '-0.00974', '0.00503', '0.00522', '-0.00412', '0.00146', '0.00270', '0.00342', '-0.00020', '0.00414', '-0.00117', '0.00154']
Epoch 36: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00946 | Gamma1: ['2.29251', '2.29328', '2.26412', '2.30619', '2.27900', '2.27279', '2.28910', '2.28447', '2.29048', '2.28847', '2.29726', '2.28763', '2.29671'] | Gamma1 Grad: ['0.00027', '-0.01316', '-0.00040', '0.00233', '-0.02235', '0.00169', '0.00288', '-0.00003', '-0.00202', '-0.00006', '-0.00275', '-0.00043', '0.00418']
Epoch 37: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00927 | Gamma1: ['2.28846', '2.30621', '2.27465', '2.27553', '2.26990', '2.28917', '2.26767', '2.27299', '2.28293', '2.27681', '2.28731', '2.27346', '2.26726'] | Gamma1 Grad: ['-0.00236', '-0.00919', '-0.00823', '-0.00296', '-0.00700', '0.00661', '-0.00431', '-0.00295', '-0.00167', '-0.00008', '0.00138', '-0.00272', '-0.00346']
Epoch 38: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00905 | Gamma1: ['2.28271', '2.30672', '2.29256', '2.29413', '2.26587', '2.28458', '2.27670', '2.28835', '2.28039', '2.27853', '2.30004', '2.27318', '2.26244'] | Gamma1 Grad: ['-0.00020', '0.00729', '0.00811', '0.00933', '-0.01572', '0.00706', '-0.00636', '-0.00041', '0.00023', '0.00351', '0.00604', '0.00126', '-0.00095']
Epoch 39: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00881 | Gamma1: ['2.28498', '2.29815', '2.26828', '2.28016', '2.28817', '2.30114', '2.28221', '2.28814', '2.28975', '2.29087', '2.28495', '2.28472', '2.26909'] | Gamma1 Grad: ['-0.00295', '-0.00119', '0.00027', '-0.01067', '-0.00045', '-0.00502', '-0.00352', '0.00173', '0.00104', '0.00074', '-0.00204', '0.00247', '-0.00096']
Epoch 40: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00854 | Gamma1: ['2.31387', '2.31580', '2.35217', '2.27127', '2.29276', '2.30209', '2.27471', '2.31124', '2.30332', '2.30054', '2.29132', '2.29658', '2.27100'] | Gamma1 Grad: ['0.00303', '0.00094', '0.00635', '-0.00066', '0.00646', '-0.00047', '-0.00227', '0.00383', '-0.00050', '0.00045', '-0.00161', '0.00288', '0.00111']
Epoch 41: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00826 | Gamma1: ['2.28669', '2.29058', '2.30358', '2.24882', '2.31282', '2.29130', '2.30667', '2.30756', '2.28373', '2.28635', '2.27284', '2.30472', '2.28438'] | Gamma1 Grad: ['-0.00073', '-0.00103', '-0.00113', '-0.00474', '0.00774', '0.00018', '-0.00086', '0.00020', '-0.00249', '-0.00004', '-0.00066', '0.00132', '0.00006']
Epoch 42: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00795 | Gamma1: ['2.30862', '2.27972', '2.27975', '2.27774', '2.29630', '2.31064', '2.30392', '2.29925', '2.29646', '2.28668', '2.27240', '2.29671', '2.31507'] | Gamma1 Grad: ['-0.00156', '0.00566', '-0.00172', '0.01094', '0.00595', '0.00268', '-0.00314', '-0.00306', '-0.00301', '-0.00199', '-0.00679', '-0.00228', '0.00368']
Epoch 43: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00762 | Gamma1: ['2.31053', '2.26225', '2.30379', '2.30220', '2.29590', '2.28852', '2.30111', '2.27317', '2.28647', '2.28769', '2.28116', '2.26082', '2.28615'] | Gamma1 Grad: ['-0.00463', '0.00161', '0.00171', '0.00052', '-0.00249', '0.00715', '-0.00671', '-0.00301', '-0.00683', '-0.00193', '-0.00776', '-0.00189', '0.00079']
Epoch 44: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00728 | Gamma1: ['2.33412', '2.29386', '2.29782', '2.29081', '2.31307', '2.27895', '2.28848', '2.29278', '2.28097', '2.28718', '2.29233', '2.28418', '2.27429'] | Gamma1 Grad: ['0.00375', '0.00052', '0.00141', '-0.00321', '0.00484', '0.00696', '0.00034', '0.00002', '-0.00322', '-0.00153', '-0.00053', '0.00093', '-0.00118']
Epoch 45: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00693 | Gamma1: ['2.30914', '2.31318', '2.28268', '2.29842', '2.30666', '2.29988', '2.29709', '2.29654', '2.29187', '2.28079', '2.29288', '2.28558', '2.27896'] | Gamma1 Grad: ['0.00286', '0.00585', '0.00223', '0.00140', '-0.00284', '0.00407', '0.00060', '-0.00037', '0.00058', '-0.00112', '-0.00085', '-0.00165', '0.00145']
Epoch 46: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00656 | Gamma1: ['2.29140', '2.30473', '2.31655', '2.29939', '2.29372', '2.30778', '2.29751', '2.28991', '2.27142', '2.28073', '2.30211', '2.26725', '2.27189'] | Gamma1 Grad: ['0.00282', '-0.00307', '0.01428', '-0.00169', '0.00838', '-0.00113', '-0.00286', '0.00207', '0.00381', '0.00212', '0.00743', '0.00051', '-0.00224']
Epoch 47: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00619 | Gamma1: ['2.30743', '2.32938', '2.29504', '2.29914', '2.29508', '2.29498', '2.29746', '2.27548', '2.27113', '2.27604', '2.28387', '2.27097', '2.28733'] | Gamma1 Grad: ['0.00434', '-0.00200', '0.00056', '-0.00190', '0.00308', '0.00722', '0.00170', '-0.00164', '-0.00215', '-0.00122', '-0.00327', '-0.00167', '0.00212']
Epoch 48: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00580 | Gamma1: ['2.30438', '2.29457', '2.28696', '2.29871', '2.29032', '2.26938', '2.29910', '2.29569', '2.28860', '2.29424', '2.29094', '2.29209', '2.28389'] | Gamma1 Grad: ['0.00202', '-0.00344', '0.00219', '-0.00119', '0.00176', '-0.00304', '-0.00054', '0.00160', '-0.00025', '0.00019', '0.00154', '0.00008', '-0.00055']
Epoch 49: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00542 | Gamma1: ['2.31020', '2.29208', '2.30108', '2.27583', '2.31162', '2.29670', '2.28229', '2.28863', '2.29294', '2.28778', '2.27900', '2.27628', '2.27769'] | Gamma1 Grad: ['0.00313', '-0.00120', '-0.00104', '0.00386', '-0.01231', '-0.00068', '0.00033', '-0.00039', '0.00183', '0.00094', '-0.00001', '-0.00027', '-0.00156']
Epoch 50: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00502 | Gamma1: ['2.27009', '2.27047', '2.31696', '2.28041', '2.27724', '2.29380', '2.29423', '2.28611', '2.30513', '2.29464', '2.29352', '2.28608', '2.28676'] | Gamma1 Grad: ['0.00071', '-0.00722', '0.00319', '0.00579', '-0.01526', '0.00526', '-0.00003', '-0.00204', '0.00043', '-0.00033', '-0.00168', '-0.00068', '-0.00092']
Epoch 51: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00463 | Gamma1: ['2.28086', '2.29521', '2.27677', '2.29271', '2.28829', '2.30364', '2.29197', '2.30166', '2.29211', '2.28698', '2.28277', '2.26813', '2.28481'] | Gamma1 Grad: ['0.00392', '0.00533', '-0.01263', '0.01554', '-0.01987', '-0.01632', '0.00616', '0.00022', '-0.00327', '0.00113', '-0.00084', '-0.00212', '0.00100']
Epoch 52: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00425 | Gamma1: ['2.29605', '2.29384', '2.28311', '2.30646', '2.27949', '2.30366', '2.29584', '2.29029', '2.29140', '2.28188', '2.27713', '2.27103', '2.29500'] | Gamma1 Grad: ['0.00159', '0.00291', '-0.01151', '-0.00589', '-0.01029', '-0.00505', '0.00454', '-0.00034', '-0.00024', '0.00117', '0.00447', '-0.00039', '0.00321']
Epoch 53: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00386 | Gamma1: ['2.32287', '2.32173', '2.28330', '2.27514', '2.28272', '2.30983', '2.29274', '2.29561', '2.29993', '2.28182', '2.28030', '2.29368', '2.26744'] | Gamma1 Grad: ['0.00342', '0.00424', '-0.00188', '0.00412', '-0.00332', '0.00116', '0.00247', '-0.00050', '-0.00029', '-0.00041', '-0.00167', '-0.00218', '0.00205']
Epoch 54: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00349 | Gamma1: ['2.30229', '2.30575', '2.29111', '2.29599', '2.27544', '2.31776', '2.28346', '2.30168', '2.27753', '2.27372', '2.26667', '2.28616', '2.27161'] | Gamma1 Grad: ['-0.00598', '-0.00113', '-0.00807', '0.00330', '-0.02634', '0.00533', '-0.00278', '0.00132', '-0.00005', '-0.00000', '0.00678', '-0.00151', '-0.00161']
Epoch 55: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00312 | Gamma1: ['2.29357', '2.28105', '2.27768', '2.30084', '2.28891', '2.28997', '2.30473', '2.30330', '2.28221', '2.27709', '2.27218', '2.28755', '2.27814'] | Gamma1 Grad: ['0.00180', '-0.00012', '0.00053', '-0.00107', '-0.00064', '-0.00137', '-0.00024', '0.00050', '0.00001', '0.00014', '-0.00067', '-0.00064', '-0.00044']
Epoch 56: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00277 | Gamma1: ['2.27586', '2.30816', '2.26536', '2.27368', '2.27945', '2.29582', '2.31013', '2.30252', '2.28609', '2.28542', '2.28319', '2.29004', '2.28518'] | Gamma1 Grad: ['-0.00503', '-0.01734', '-0.03020', '-0.00687', '0.00256', '0.02019', '-0.00923', '0.00362', '0.00557', '0.00361', '0.00095', '0.00542', '-0.00307']
Epoch 57: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00243 | Gamma1: ['2.28186', '2.28567', '2.27951', '2.29207', '2.24454', '2.29204', '2.30353', '2.28843', '2.29131', '2.27925', '2.27585', '2.27309', '2.29640'] | Gamma1 Grad: ['-0.01430', '-0.00057', '-0.00962', '0.00932', '-0.00043', '-0.00235', '-0.00067', '-0.00225', '0.00473', '0.00203', '0.00084', '0.00078', '-0.00195']
Epoch 58: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00210 | Gamma1: ['2.30475', '2.28741', '2.28880', '2.31364', '2.25573', '2.28554', '2.28445', '2.28206', '2.27958', '2.27378', '2.28115', '2.27912', '2.28563'] | Gamma1 Grad: ['0.00225', '-0.00163', '0.00161', '0.00067', '-0.00110', '0.00080', '-0.00135', '-0.00025', '-0.00047', '-0.00060', '-0.00071', '-0.00083', '0.00101']
Epoch 59: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00179 | Gamma1: ['2.30298', '2.28570', '2.26904', '2.30052', '2.28459', '2.29861', '2.29369', '2.29042', '2.28419', '2.28293', '2.29186', '2.27908', '2.28467'] | Gamma1 Grad: ['0.00042', '-0.00000', '-0.00111', '0.00071', '-0.00054', '0.00005', '-0.00001', '-0.00039', '-0.00062', '-0.00054', '-0.00053', '-0.00059', '-0.00037']
Epoch 60: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00151 | Gamma1: ['2.28356', '2.31469', '2.29034', '2.33374', '2.28946', '2.30183', '2.30587', '2.29177', '2.28485', '2.28241', '2.27958', '2.27779', '2.28228'] | Gamma1 Grad: ['-0.00315', '0.00454', '0.00157', '0.00037', '0.00681', '0.00048', '-0.00004', '0.00025', '-0.00348', '-0.00087', '0.00197', '0.00213', '0.00045']
Epoch 61: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00124 | Gamma1: ['2.30096', '2.32145', '2.31468', '2.29960', '2.27401', '2.29651', '2.29763', '2.29068', '2.28976', '2.28107', '2.27965', '2.27976', '2.28296'] | Gamma1 Grad: ['0.00030', '0.00278', '-0.00368', '0.00840', '-0.00612', '0.00063', '-0.00169', '-0.00024', '0.00182', '0.00056', '0.00376', '-0.00271', '-0.00137']
Epoch 62: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00100 | Gamma1: ['2.30157', '2.32237', '2.29800', '2.29357', '2.27147', '2.27509', '2.31040', '2.27875', '2.29047', '2.28143', '2.27712', '2.28012', '2.28767'] | Gamma1 Grad: ['0.00085', '0.00079', '0.00128', '0.00175', '-0.00345', '0.00406', '-0.00175', '-0.00129', '0.00017', '0.00068', '0.00076', '-0.00108', '-0.00022']
Epoch 63: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00078 | Gamma1: ['2.28843', '2.31276', '2.29999', '2.28872', '2.27935', '2.28548', '2.30608', '2.30073', '2.29259', '2.27725', '2.28068', '2.27962', '2.28430'] | Gamma1 Grad: ['0.00129', '-0.00159', '-0.00007', '-0.00229', '-0.00192', '0.00270', '-0.00111', '0.00007', '0.00224', '0.00066', '0.00102', '-0.00147', '0.00051']
Epoch 64: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00059 | Gamma1: ['2.29307', '2.30171', '2.30490', '2.29449', '2.27320', '2.28678', '2.30567', '2.29772', '2.29402', '2.28237', '2.28431', '2.28228', '2.28393'] | Gamma1 Grad: ['0.00052', '-0.00835', '-0.00427', '0.00531', '-0.00131', '0.00308', '0.00337', '0.00217', '0.00264', '0.00197', '0.00461', '0.00091', '-0.00022']
Epoch 65: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00043 | Gamma1: ['2.29109', '2.29680', '2.29378', '2.28843', '2.28802', '2.29750', '2.30790', '2.29339', '2.28349', '2.27533', '2.27505', '2.28535', '2.28390'] | Gamma1 Grad: ['-0.00164', '-0.00230', '-0.00042', '-0.00434', '0.00570', '-0.00350', '-0.00154', '-0.00053', '0.00222', '0.00119', '0.00204', '0.00235', '0.00111']
Epoch 66: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00029 | Gamma1: ['2.28990', '2.30325', '2.28951', '2.28585', '2.28322', '2.28986', '2.31016', '2.30421', '2.29018', '2.28246', '2.28314', '2.28630', '2.28687'] | Gamma1 Grad: ['-0.00000', '0.00038', '-0.00027', '0.00323', '0.00385', '-0.00564', '0.00208', '-0.00036', '-0.00047', '-0.00006', '-0.00135', '0.00069', '0.00015']
Epoch 67: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00019 | Gamma1: ['2.29022', '2.31551', '2.29332', '2.26559', '2.28856', '2.30520', '2.30835', '2.30265', '2.29427', '2.27984', '2.27833', '2.28108', '2.28012'] | Gamma1 Grad: ['-0.00051', '-0.00000', '0.00098', '-0.00183', '-0.00141', '0.00326', '-0.00063', '0.00028', '-0.00059', '-0.00059', '-0.00100', '-0.00161', '0.00080']
Epoch 68: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00011 | Gamma1: ['2.29972', '2.31971', '2.29823', '2.26157', '2.29235', '2.29514', '2.30477', '2.30577', '2.29104', '2.27938', '2.28037', '2.28045', '2.28035'] | Gamma1 Grad: ['0.00140', '-0.00115', '0.00015', '-0.00274', '0.00327', '0.00086', '-0.00134', '0.00027', '0.00038', '0.00048', '0.00182', '0.00116', '0.00027']
Epoch 69: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00007 | Gamma1: ['2.30448', '2.30936', '2.29907', '2.26850', '2.29396', '2.29692', '2.29902', '2.29632', '2.28732', '2.28326', '2.28328', '2.28141', '2.28002'] | Gamma1 Grad: ['0.00030', '-0.00182', '0.00178', '-0.00526', '0.00094', '0.00236', '-0.00281', '0.00004', '0.00154', '0.00053', '-0.01085', '-0.00207', '-0.00162']
Epoch 70: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.01000 | Gamma1: ['2.29716', '2.29821', '2.29351', '2.27639', '2.29380', '2.30643', '2.30495', '2.29796', '2.28749', '2.28305', '2.28650', '2.28677', '2.27807'] | Gamma1 Grad: ['-0.00043', '-0.00112', '-0.00018', '-0.00072', '0.00044', '-0.00083', '0.00023', '-0.00002', '-0.00013', '-0.00004', '-0.00004', '0.00013', '-0.00029']
Epoch 71: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.01000 | Gamma1: ['2.30699', '2.30374', '2.33009', '2.31581', '2.28961', '2.25458', '2.25249', '2.27359', '2.30680', '2.29429', '2.30434', '2.28194', '2.28701'] | Gamma1 Grad: ['0.00131', '-0.00167', '-0.00083', '-0.00467', '-0.00077', '0.00162', '-0.00094', '-0.00185', '0.00016', '0.00052', '0.00205', '-0.00264', '0.00008']
Epoch 72: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00998 | Gamma1: ['2.26188', '2.32419', '2.28395', '2.30219', '2.28076', '2.27935', '2.25811', '2.27927', '2.30260', '2.29831', '2.31542', '2.32066', '2.27596'] | Gamma1 Grad: ['0.00167', '0.00096', '0.00131', '-0.00274', '0.00378', '-0.00446', '-0.00004', '0.00274', '-0.00203', '-0.00085', '-0.00165', '0.00150', '-0.00072']
Epoch 73: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00997 | Gamma1: ['2.29292', '2.29899', '2.27116', '2.30859', '2.28803', '2.26969', '2.30112', '2.28886', '2.29538', '2.28492', '2.30665', '2.28444', '2.29239'] | Gamma1 Grad: ['-0.00070', '0.00180', '0.00377', '0.01302', '-0.01755', '0.00927', '0.00416', '0.00009', '0.00203', '0.00069', '-0.00005', '0.00023', '-0.00066']
Epoch 74: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00994 | Gamma1: ['2.25935', '2.30424', '2.27264', '2.27431', '2.27517', '2.24546', '2.27903', '2.30113', '2.31367', '2.29309', '2.28003', '2.29925', '2.30040'] | Gamma1 Grad: ['-0.00882', '-0.00702', '-0.03047', '0.00899', '-0.01605', '0.00289', '-0.00366', '-0.00105', '0.00020', '0.00075', '0.00251', '-0.00675', '0.00072']
Epoch 75: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00990 | Gamma1: ['2.26306', '2.30194', '2.31162', '2.25839', '2.28781', '2.22519', '2.26804', '2.29621', '2.33468', '2.30861', '2.30621', '2.31549', '2.28463'] | Gamma1 Grad: ['0.00246', '0.00474', '-0.02231', '0.01142', '-0.01154', '0.00247', '-0.00136', '-0.00046', '0.00421', '0.00281', '0.00129', '0.00050', '-0.00125']
Epoch 76: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00986 | Gamma1: ['2.31816', '2.30431', '2.34049', '2.27618', '2.29784', '2.24146', '2.30866', '2.29761', '2.29651', '2.28755', '2.27110', '2.29001', '2.28301'] | Gamma1 Grad: ['0.00380', '0.00267', '-0.00087', '0.00257', '0.00304', '-0.00248', '-0.00151', '0.00027', '0.00063', '0.00016', '-0.00001', '-0.00077', '0.00032']
Epoch 77: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00981 | Gamma1: ['2.31946', '2.27836', '2.29769', '2.26564', '2.27396', '2.27607', '2.27632', '2.30978', '2.27793', '2.29713', '2.28515', '2.30503', '2.31772'] | Gamma1 Grad: ['-0.00034', '-0.00035', '0.00028', '-0.00048', '0.00002', '0.00068', '-0.00076', '0.00072', '-0.00097', '-0.00022', '-0.00082', '-0.00067', '0.00073']
Epoch 78: M_Optimizer LR => 0.00100 | Gamma1 LR => 0.00976 | Gamma1: ['2.27713', '2.26344', '2.25431', '2.28079', '2.27761', '2.27095', '2.29519', '2.30508', '2.26512', '2.29836', '2.30264', '2.27150', '2.28985'] | Gamma1 Grad: ['0.00851', '0.00658', '-0.00825', '0.01284', '0.00025', '0.01853', '-0.00650', '0.00100', '0.00745', '0.00099', '-0.00947', '-0.00098', '0.00245']
Epoch 79: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00969 | Gamma1: ['2.31825', '2.27129', '2.27163', '2.29819', '2.27512', '2.24687', '2.26505', '2.31787', '2.30752', '2.30141', '2.32520', '2.29642', '2.29770'] | Gamma1 Grad: ['0.00130', '0.00806', '-0.00535', '-0.00444', '-0.00858', '0.00579', '-0.00182', '0.00125', '-0.00119', '0.00088', '0.00201', '-0.00089', '0.00140']
Epoch 80: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00962 | Gamma1: ['2.30513', '2.29382', '2.26138', '2.30602', '2.26214', '2.24790', '2.28926', '2.31335', '2.29279', '2.29020', '2.30259', '2.29229', '2.28781'] | Gamma1 Grad: ['0.00263', '-0.00144', '0.00074', '-0.00455', '0.00132', '-0.00115', '0.00107', '0.00109', '0.00214', '-0.00094', '0.00011', '-0.00026', '0.00084']
Epoch 81: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00954 | Gamma1: ['2.30167', '2.29495', '2.27265', '2.28109', '2.27722', '2.27311', '2.29603', '2.30215', '2.28749', '2.28571', '2.28822', '2.28532', '2.28555'] | Gamma1 Grad: ['-0.00027', '0.00157', '0.00424', '0.00154', '-0.01160', '0.00078', '-0.00179', '-0.00116', '-0.00356', '-0.00096', '-0.00064', '-0.00021', '0.00015']
Epoch 82: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00946 | Gamma1: ['2.29603', '2.27877', '2.30475', '2.27377', '2.28233', '2.28463', '2.28628', '2.28600', '2.28767', '2.29384', '2.28470', '2.28832', '2.27924'] | Gamma1 Grad: ['0.00135', '-0.00236', '0.00004', '0.00178', '0.00205', '-0.00010', '0.00009', '-0.00038', '-0.00035', '0.00001', '-0.00035', '-0.00115', '-0.00018']
Epoch 83: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00937 | Gamma1: ['2.29697', '2.26276', '2.33388', '2.29310', '2.27539', '2.33044', '2.31220', '2.28965', '2.29770', '2.28206', '2.29043', '2.29072', '2.28554'] | Gamma1 Grad: ['0.00036', '-0.00038', '0.00088', '0.00038', '-0.00020', '0.00127', '0.00066', '0.00017', '0.00039', '-0.00006', '0.00009', '0.00031', '0.00016']
Epoch 84: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00927 | Gamma1: ['2.28432', '2.26764', '2.30860', '2.26619', '2.27181', '2.30732', '2.30361', '2.29875', '2.29672', '2.29101', '2.29492', '2.29384', '2.28249'] | Gamma1 Grad: ['-0.00008', '0.00002', '-0.00023', '-0.00031', '-0.00048', '0.00000', '0.00047', '0.00021', '-0.00007', '0.00005', '-0.00029', '-0.00038', '-0.00012']
Epoch 85: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00916 | Gamma1: ['2.30499', '2.30551', '2.28155', '2.22874', '2.27458', '2.26067', '2.32620', '2.29002', '2.28782', '2.29056', '2.27963', '2.31254', '2.27476'] | Gamma1 Grad: ['0.00039', '0.00054', '-0.00034', '-0.00115', '-0.00004', '-0.00081', '0.00069', '-0.00011', '-0.00016', '0.00006', '-0.00009', '0.00083', '-0.00021']
Epoch 86: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00905 | Gamma1: ['2.33330', '2.32229', '2.32359', '2.25580', '2.33410', '2.26362', '2.31253', '2.29154', '2.29289', '2.29516', '2.29898', '2.31045', '2.27425'] | Gamma1 Grad: ['0.00095', '0.00075', '0.00093', '0.00001', '0.00128', '-0.00025', '0.00029', '0.00014', '0.00017', '0.00025', '0.00052', '0.00064', '-0.00005']
Epoch 87: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00893 | Gamma1: ['2.30890', '2.30591', '2.30398', '2.27790', '2.35336', '2.24331', '2.29679', '2.29539', '2.28247', '2.28622', '2.28348', '2.30102', '2.28594'] | Gamma1 Grad: ['0.00002', '-0.00017', '0.00023', '-0.00005', '0.00105', '-0.00055', '-0.00010', '-0.00009', '-0.00034', '-0.00023', '-0.00024', '0.00024', '-0.00002']
Epoch 88: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00881 | Gamma1: ['2.29030', '2.30226', '2.29557', '2.28758', '2.30184', '2.27038', '2.29721', '2.28158', '2.28737', '2.28671', '2.29259', '2.30259', '2.28464'] | Gamma1 Grad: ['0.00024', '0.00047', '0.00011', '0.00026', '-0.00003', '0.00013', '0.00027', '-0.00004', '0.00021', '0.00017', '0.00024', '0.00020', '0.00011']
Epoch 89: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00868 | Gamma1: ['2.27142', '2.30802', '2.25833', '2.29055', '2.28745', '2.26263', '2.28234', '2.29464', '2.29103', '2.29864', '2.30563', '2.29683', '2.27998'] | Gamma1 Grad: ['-0.00005', '0.00027', '-0.00062', '0.00039', '-0.00000', '-0.00041', '-0.00027', '0.00026', '0.00010', '0.00022', '0.00009', '-0.00034', '-0.00006']
Epoch 90: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00854 | Gamma1: ['2.26577', '2.26313', '2.26194', '2.27740', '2.27554', '2.29234', '2.29344', '2.27975', '2.27884', '2.27942', '2.27967', '2.27276', '2.27276'] | Gamma1 Grad: ['-0.00110', '-0.00099', '-0.00082', '0.00063', '0.00093', '0.00137', '0.00085', '-0.00004', '-0.00021', '-0.00009', '-0.00032', '-0.00022', '-0.00024']
Epoch 91: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00840 | Gamma1: ['2.26204', '2.23872', '2.25859', '2.26805', '2.30484', '2.28544', '2.28950', '2.28670', '2.26352', '2.27507', '2.27418', '2.27430', '2.27699'] | Gamma1 Grad: ['-0.00083', '-0.00070', '-0.00029', '0.00005', '0.00028', '-0.00067', '-0.00050', '0.00016', '-0.00043', '-0.00025', '-0.00066', '-0.00060', '-0.00017']
Epoch 92: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00826 | Gamma1: ['2.26296', '2.26642', '2.26787', '2.27570', '2.29816', '2.28978', '2.28881', '2.29667', '2.28107', '2.29037', '2.29820', '2.27845', '2.28162'] | Gamma1 Grad: ['-0.00016', '0.00018', '0.00001', '0.00007', '0.00016', '0.00028', '0.00015', '0.00035', '0.00018', '0.00034', '0.00051', '0.00005', '0.00013']
Epoch 93: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00810 | Gamma1: ['2.25619', '2.26134', '2.26758', '2.30174', '2.28461', '2.27302', '2.30009', '2.30401', '2.30809', '2.30336', '2.29383', '2.27058', '2.26959'] | Gamma1 Grad: ['0.00039', '-0.00034', '-0.00069', '0.00052', '-0.00196', '0.00021', '0.00031', '-0.00002', '0.00042', '0.00015', '0.00016', '-0.00023', '-0.00041']
Epoch 94: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00795 | Gamma1: ['2.26676', '2.26879', '2.27381', '2.26002', '2.31685', '2.28443', '2.27696', '2.28669', '2.28330', '2.28426', '2.26294', '2.25604', '2.27292'] | Gamma1 Grad: ['-0.00010', '-0.00007', '0.00001', '-0.00070', '0.00074', '0.00016', '-0.00030', '-0.00013', '-0.00026', '-0.00020', '-0.00051', '-0.00032', '-0.00010']
Epoch 95: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00779 | Gamma1: ['2.28684', '2.28221', '2.26842', '2.31546', '2.27752', '2.27733', '2.27739', '2.27848', '2.29688', '2.28407', '2.25826', '2.25768', '2.28575'] | Gamma1 Grad: ['0.00039', '0.00021', '-0.00015', '0.00099', '-0.00027', '-0.00016', '0.00002', '-0.00011', '0.00038', '0.00004', '-0.00032', '-0.00041', '0.00022']
Epoch 96: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00762 | Gamma1: ['2.27853', '2.28010', '2.26896', '2.30111', '2.28154', '2.27135', '2.28401', '2.28228', '2.29952', '2.28214', '2.27557', '2.28302', '2.27853'] | Gamma1 Grad: ['0.00172', '0.00154', '-0.00162', '-0.00188', '0.00312', '-0.00466', '0.00093', '0.00265', '0.00046', '-0.00016', '0.00198', '-0.00045', '-0.00020']
Epoch 97: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00746 | Gamma1: ['2.29279', '2.28032', '2.27853', '2.27566', '2.27943', '2.30041', '2.27455', '2.27082', '2.29081', '2.26875', '2.28892', '2.28773', '2.27451'] | Gamma1 Grad: ['0.00034', '0.00003', '0.00007', '-0.00024', '0.00000', '0.00057', '-0.00010', '-0.00018', '0.00006', '-0.00027', '0.00012', '-0.00025', '-0.00007']
Epoch 98: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00728 | Gamma1: ['2.27833', '2.27336', '2.26064', '2.28220', '2.27787', '2.27453', '2.27152', '2.28362', '2.28688', '2.27552', '2.27946', '2.27877', '2.27778'] | Gamma1 Grad: ['-0.00020', '-0.00021', '-0.00039', '0.00008', '-0.00004', '-0.00044', '-0.00021', '0.00016', '0.00000', '-0.00005', '-0.00028', '-0.00054', '-0.00001']
Epoch 99: M_Optimizer LR => 0.00010 | Gamma1 LR => 0.00711 | Gamma1: ['2.28013', '2.27533', '2.27799', '2.27627', '2.28548', '2.29631', '2.29200', '2.29091', '2.27912', '2.27862', '2.26184', '2.28905', '2.27682'] | Gamma1 Grad: ['0.00016', '0.00013', '0.00028', '0.00003', '0.00025', '0.00058', '0.00055', '0.00036', '0.00002', '0.00011', '-0.00035', '0.00038', '0.00011']
